// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs).
// git: intragroup-mmm @ 92992b5 (Thu Dec 19 12:05:18 2024 +0100) [modified]
// Compiled with GHC 9.4.8.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f16_2d;
struct futhark_f16_2d *futhark_new_f16_2d(struct futhark_context *ctx, const uint16_t *data, int64_t dim0, int64_t dim1);
struct futhark_f16_2d *futhark_new_raw_f16_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1);
int futhark_free_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr);
int futhark_values_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr, uint16_t *data);
int futhark_index_f16_2d(struct futhark_context *ctx, uint16_t *out, struct futhark_f16_2d *arr, int64_t i0, int64_t i1);
CUdeviceptr futhark_values_raw_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr);
const int64_t *futhark_shape_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr);
struct futhark_f16_3d;
struct futhark_f16_3d *futhark_new_f16_3d(struct futhark_context *ctx, const uint16_t *data, int64_t dim0, int64_t dim1, int64_t dim2);
struct futhark_f16_3d *futhark_new_raw_f16_3d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1, int64_t dim2);
int futhark_free_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr);
int futhark_values_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr, uint16_t *data);
int futhark_index_f16_3d(struct futhark_context *ctx, uint16_t *out, struct futhark_f16_3d *arr, int64_t i0, int64_t i1, int64_t i2);
CUdeviceptr futhark_values_raw_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr);
const int64_t *futhark_shape_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr);

// Opaque values



// Entry points
int futhark_entry_mk_input(struct futhark_context *ctx, struct futhark_f16_3d **out0, struct futhark_f16_2d **out1, struct futhark_f16_2d **out2, const int64_t in0, const int64_t in1);
int futhark_entry_run128(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2);
int futhark_entry_run16(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2);
int futhark_entry_run32(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2);
int futhark_entry_run64(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cudatc
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
static const char *entry_point = "main";
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret = 1;
  int expect_elem = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);
    if (strcmp(buf, "]") == 0) {
      expect_elem = 0;
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (!expect_elem && strcmp(buf, ",") == 0) {
      expect_elem = 1;
    } else if (expect_elem) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        expect_elem = 0;
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.*ff16", FLT_DIG, x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.*ff32", FLT_DIG, x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.*ff64", DBL_DIG, x);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

// Start of server.h.

// Forward declarations of things that we technically don't know until
// the application header file is included, but which we need.
struct futhark_context_config;
struct futhark_context;
char *futhark_context_get_error(struct futhark_context *ctx);
int futhark_context_sync(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value);
int futhark_get_tuning_param_count(void);
const char* futhark_get_tuning_param_name(int i);
const char* futhark_get_tuning_param_class(int i);

typedef int (*restore_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef void (*store_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef int (*free_fn)(const void*, struct futhark_context*, void*);
typedef int (*project_fn)(struct futhark_context*, void*, const void*);
typedef int (*new_fn)(struct futhark_context*, void**, const void*[]);

struct field {
  const char *name;
  const struct type *type;
  project_fn project;
};

struct record {
  int num_fields;
  const struct field* fields;
  new_fn new;
};

struct type {
  const char *name;
  restore_fn restore;
  store_fn store;
  free_fn free;
  const void *aux;
  const struct record *record;
};

int free_scalar(const void *aux, struct futhark_context *ctx, void *p) {
  (void)aux;
  (void)ctx;
  (void)p;
  // Nothing to do.
  return 0;
}

#define DEF_SCALAR_TYPE(T)                                      \
  int restore_##T(const void *aux, FILE *f,                     \
                  struct futhark_context *ctx, void *p) {       \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    return read_scalar(f, &T##_info, p);                        \
  }                                                             \
                                                                \
  void store_##T(const void *aux, FILE *f,                      \
                 struct futhark_context *ctx, void *p) {        \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    write_scalar(f, 1, &T##_info, p);                           \
  }                                                             \
                                                                \
  struct type type_##T =                                        \
    { .name = #T,                                               \
      .restore = restore_##T,                                   \
      .store = store_##T,                                       \
      .free = free_scalar                                       \
    }                                                           \

DEF_SCALAR_TYPE(i8);
DEF_SCALAR_TYPE(i16);
DEF_SCALAR_TYPE(i32);
DEF_SCALAR_TYPE(i64);
DEF_SCALAR_TYPE(u8);
DEF_SCALAR_TYPE(u16);
DEF_SCALAR_TYPE(u32);
DEF_SCALAR_TYPE(u64);
DEF_SCALAR_TYPE(f16);
DEF_SCALAR_TYPE(f32);
DEF_SCALAR_TYPE(f64);
DEF_SCALAR_TYPE(bool);

struct value {
  const struct type *type;
  union {
    void *v_ptr;
    int8_t  v_i8;
    int16_t v_i16;
    int32_t v_i32;
    int64_t v_i64;

    uint8_t  v_u8;
    uint16_t v_u16;
    uint32_t v_u32;
    uint64_t v_u64;

    uint16_t v_f16;
    float v_f32;
    double v_f64;

    bool v_bool;
  } value;
};

void* value_ptr(struct value *v) {
  if (v->type == &type_i8) {
    return &v->value.v_i8;
  }
  if (v->type == &type_i16) {
    return &v->value.v_i16;
  }
  if (v->type == &type_i32) {
    return &v->value.v_i32;
  }
  if (v->type == &type_i64) {
    return &v->value.v_i64;
  }
  if (v->type == &type_u8) {
    return &v->value.v_u8;
  }
  if (v->type == &type_u16) {
    return &v->value.v_u16;
  }
  if (v->type == &type_u32) {
    return &v->value.v_u32;
  }
  if (v->type == &type_u64) {
    return &v->value.v_u64;
  }
  if (v->type == &type_f16) {
    return &v->value.v_f16;
  }
  if (v->type == &type_f32) {
    return &v->value.v_f32;
  }
  if (v->type == &type_f64) {
    return &v->value.v_f64;
  }
  if (v->type == &type_bool) {
    return &v->value.v_bool;
  }
  return &v->value.v_ptr;
}

struct variable {
  // NULL name indicates free slot.  Name is owned by this struct.
  char *name;
  struct value value;
};

typedef int (*entry_point_fn)(struct futhark_context*, void**, void**);

struct entry_point {
  const char *name;
  entry_point_fn f;
  const char** tuning_params;
  const struct type **out_types;
  bool *out_unique;
  const struct type **in_types;
  bool *in_unique;
};

int entry_num_ins(struct entry_point *e) {
  int count = 0;
  while (e->in_types[count]) {
    count++;
  }
  return count;
}

int entry_num_outs(struct entry_point *e) {
  int count = 0;
  while (e->out_types[count]) {
    count++;
  }
  return count;
}

struct futhark_prog {
  // Last entry point identified by NULL name.
  struct entry_point *entry_points;
  // Last type identified by NULL name.
  const struct type **types;
};

struct server_state {
  struct futhark_prog prog;
  struct futhark_context_config *cfg;
  struct futhark_context *ctx;
  int variables_capacity;
  struct variable *variables;
};

struct variable* get_variable(struct server_state *s,
                              const char *name) {
  for (int i = 0; i < s->variables_capacity; i++) {
    if (s->variables[i].name != NULL &&
        strcmp(s->variables[i].name, name) == 0) {
      return &s->variables[i];
    }
  }

  return NULL;
}

struct variable* create_variable(struct server_state *s,
                                 const char *name,
                                 const struct type *type) {
  int found = -1;
  for (int i = 0; i < s->variables_capacity; i++) {
    if (found == -1 && s->variables[i].name == NULL) {
      found = i;
    } else if (s->variables[i].name != NULL &&
               strcmp(s->variables[i].name, name) == 0) {
      return NULL;
    }
  }

  if (found != -1) {
    // Found a free spot.
    s->variables[found].name = strdup(name);
    s->variables[found].value.type = type;
    return &s->variables[found];
  }

  // Need to grow the buffer.
  found = s->variables_capacity;
  s->variables_capacity *= 2;
  s->variables = realloc(s->variables,
                         s->variables_capacity * sizeof(struct variable));

  s->variables[found].name = strdup(name);
  s->variables[found].value.type = type;

  for (int i = found+1; i < s->variables_capacity; i++) {
    s->variables[i].name = NULL;
  }

  return &s->variables[found];
}

void drop_variable(struct variable *v) {
  free(v->name);
  v->name = NULL;
}

int arg_exists(const char *args[], int i) {
  return args[i] != NULL;
}

const char* get_arg(const char *args[], int i) {
  if (!arg_exists(args, i)) {
    futhark_panic(1, "Insufficient command args.\n");
  }
  return args[i];
}

const struct type* get_type(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.types[i]; i++) {
    if (strcmp(s->prog.types[i]->name, name) == 0) {
      return s->prog.types[i];
    }
  }

  futhark_panic(1, "Unknown type %s\n", name);
  return NULL;
}

struct entry_point* get_entry_point(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    if (strcmp(s->prog.entry_points[i].name, name) == 0) {
      return &s->prog.entry_points[i];
    }
  }

  return NULL;
}

// Print the command-done marker, indicating that we are ready for
// more input.
void ok(void) {
  printf("%%%%%% OK\n");
  fflush(stdout);
}

// Print the failure marker.  Output is now an error message until the
// next ok().
void failure(void) {
  printf("%%%%%% FAILURE\n");
}

void error_check(struct server_state *s, int err) {
  if (err != 0) {
    failure();
    char *error = futhark_context_get_error(s->ctx);
    if (error != NULL) {
      puts(error);
    }
    free(error);
  }
}

void cmd_call(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);

  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  int num_ins = entry_num_ins(e);
  // +1 to avoid zero-size arrays, which is UB.
  void* outs[num_outs+1];
  void* ins[num_ins+1];

  for (int i = 0; i < num_ins; i++) {
    const char *in_name = get_arg(args, 1+num_outs+i);
    struct variable *v = get_variable(s, in_name);
    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", in_name);
      return;
    }
    if (v->value.type != e->in_types[i]) {
      failure();
      printf("Wrong input type.  Expected %s, got %s.\n",
             e->in_types[i]->name, v->value.type->name);
      return;
    }
    ins[i] = value_ptr(&v->value);
  }

  for (int i = 0; i < num_outs; i++) {
    const char *out_name = get_arg(args, 1+i);
    struct variable *v = create_variable(s, out_name, e->out_types[i]);
    if (v == NULL) {
      failure();
      printf("Variable already exists: %s\n", out_name);
      return;
    }
    outs[i] = value_ptr(&v->value);
  }

  int64_t t_start = get_wall_time();
  int err = e->f(s->ctx, outs, ins);
  err |= futhark_context_sync(s->ctx);
  int64_t t_end = get_wall_time();
  long long int elapsed_usec = t_end - t_start;
  printf("runtime: %lld\n", elapsed_usec);

  error_check(s, err);
  if (err != 0) {
    // Need to uncreate the output variables, which would otherwise be left
    // in an uninitialised state.
    for (int i = 0; i < num_outs; i++) {
      const char *out_name = get_arg(args, 1+i);
      struct variable *v = get_variable(s, out_name);
      if (v) {
        drop_variable(v);
      }
    }
  }
}

void cmd_restore(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "rb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
    return;
  }

  int bad = 0;
  int values = 0;
  for (int i = 1; arg_exists(args, i); i+=2, values++) {
    const char *vname = get_arg(args, i);
    const char *type = get_arg(args, i+1);

    const struct type *t = get_type(s, type);
    struct variable *v = create_variable(s, vname, t);

    if (v == NULL) {
      bad = 1;
      failure();
      printf("Variable already exists: %s\n", vname);
      break;
    }

    errno = 0;
    if (t->restore(t->aux, f, s->ctx, value_ptr(&v->value)) != 0) {
      bad = 1;
      failure();
      printf("Failed to restore variable %s.\n"
             "Possibly malformed data in %s (errno: %s)\n",
             vname, fname, strerror(errno));
      drop_variable(v);
      break;
    }
  }

  if (!bad && end_of_input(f) != 0) {
    failure();
    printf("Expected EOF after reading %d values from %s\n",
           values, fname);
  }

  fclose(f);

  if (!bad) {
    int err = futhark_context_sync(s->ctx);
    error_check(s, err);
  }
}

void cmd_store(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "wb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
  } else {
    for (int i = 1; arg_exists(args, i); i++) {
      const char *vname = get_arg(args, i);
      struct variable *v = get_variable(s, vname);

      if (v == NULL) {
        failure();
        printf("Unknown variable: %s\n", vname);
        return;
      }

      const struct type *t = v->value.type;
      t->store(t->aux, f, s->ctx, value_ptr(&v->value));
    }
    fclose(f);
  }
}

void cmd_free(struct server_state *s, const char *args[]) {
  for (int i = 0; arg_exists(args, i); i++) {
    const char *name = get_arg(args, i);
    struct variable *v = get_variable(s, name);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", name);
      return;
    }

    const struct type *t = v->value.type;

    int err = t->free(t->aux, s->ctx, value_ptr(&v->value));
    error_check(s, err);
    drop_variable(v);
  }
}

void cmd_rename(struct server_state *s, const char *args[]) {
  const char *oldname = get_arg(args, 0);
  const char *newname = get_arg(args, 1);
  struct variable *old = get_variable(s, oldname);
  struct variable *new = get_variable(s, newname);

  if (old == NULL) {
    failure();
    printf("Unknown variable: %s\n", oldname);
    return;
  }

  if (new != NULL) {
    failure();
    printf("Variable already exists: %s\n", newname);
    return;
  }

  free(old->name);
  old->name = strdup(newname);
}

void cmd_inputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_ins = entry_num_ins(e);
  for (int i = 0; i < num_ins; i++) {
    if (e->in_unique[i]) {
      putchar('*');
    }
    puts(e->in_types[i]->name);
  }
}

void cmd_outputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  for (int i = 0; i < num_outs; i++) {
    if (e->out_unique[i]) {
      putchar('*');
    }
    puts(e->out_types[i]->name);
  }
}

void cmd_clear(struct server_state *s, const char *args[]) {
  (void)args;
  int err = 0;
  for (int i = 0; i < s->variables_capacity; i++) {
    struct variable *v = &s->variables[i];
    if (v->name != NULL) {
      err |= v->value.type->free(v->value.type->aux, s->ctx, value_ptr(&v->value));
      drop_variable(v);
    }
  }
  err |= futhark_context_clear_caches(s->ctx);
  error_check(s, err);
}

void cmd_pause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_pause_profiling(s->ctx);
}

void cmd_unpause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_unpause_profiling(s->ctx);
}

void cmd_report(struct server_state *s, const char *args[]) {
  (void)args;
  char *report = futhark_context_report(s->ctx);
  if (report) {
    puts(report);
  } else {
    failure();
    report = futhark_context_get_error(s->ctx);
    if (report) {
      puts(report);
    } else {
      puts("Failed to produce profiling report.\n");
    }
  }
  free(report);
}

void cmd_set_tuning_param(struct server_state *s, const char *args[]) {
  const char *param = get_arg(args, 0);
  const char *val_s = get_arg(args, 1);
  size_t val = atol(val_s);
  int err = futhark_context_config_set_tuning_param(s->cfg, param, val);

  error_check(s, err);

  if (err != 0) {
    printf("Failed to set tuning parameter %s to %ld\n", param, (long)val);
  }
}

void cmd_tuning_params(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  const char **params = e->tuning_params;
  for (int i = 0; params[i] != NULL; i++) {
    printf("%s\n", params[i]);
  }
}

void cmd_tuning_param_class(struct server_state *s, const char *args[]) {
  (void)s;
  const char *param = get_arg(args, 0);

  int n = futhark_get_tuning_param_count();

  for (int i = 0; i < n; i++) {
    if (strcmp(futhark_get_tuning_param_name(i), param) == 0) {
      printf("%s\n", futhark_get_tuning_param_class(i));
      return;
    }
  }

  failure();
  printf("Unknown tuning parameter: %s\n", param);
}

void cmd_fields(struct server_state *s, const char *args[]) {
  const char *type = get_arg(args, 0);
  const struct type *t = get_type(s, type);
  const struct record *r = t->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  for (int i = 0; i < r->num_fields; i++) {
    const struct field f = r->fields[i];
    printf("%s %s\n", f.name, f.type->name);
  }
}

void cmd_project(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *from_name = get_arg(args, 1);
  const char *field_name = get_arg(args, 2);

  struct variable *from = get_variable(s, from_name);

  if (from == NULL) {
    failure();
    printf("Unknown variable: %s\n", from_name);
    return;
  }

  const struct type *from_type = from->value.type;
  const struct record *r = from_type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  const struct field *field = NULL;
  for (int i = 0; i < r->num_fields; i++) {
    if (strcmp(r->fields[i].name, field_name) == 0) {
      field = &r->fields[i];
      break;
    }
  }

  if (field == NULL) {
    failure();
    printf("No such field\n");
  }

  struct variable *to = create_variable(s, to_name, field->type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  field->project(s->ctx, value_ptr(&to->value), from->value.value.v_ptr);
}

void cmd_new(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *type_name = get_arg(args, 1);
  const struct type *type = get_type(s, type_name);
  struct variable *to = create_variable(s, to_name, type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  const struct record* r = type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  int num_args = 0;
  for (int i = 2; arg_exists(args, i); i++) {
    num_args++;
  }

  if (num_args != r->num_fields) {
    failure();
    printf("%d fields expected but %d values provided.\n", num_args, r->num_fields);
    return;
  }

  const void** value_ptrs = alloca(num_args * sizeof(void*));

  for (int i = 0; i < num_args; i++) {
    struct variable* v = get_variable(s, args[2+i]);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", args[2+i]);
      return;
    }

    if (strcmp(v->value.type->name, r->fields[i].type->name) != 0) {
      failure();
      printf("Field %s mismatch: expected type %s, got %s\n",
             r->fields[i].name, r->fields[i].type->name, v->value.type->name);
      return;
    }

    value_ptrs[i] = value_ptr(&v->value);
  }

  r->new(s->ctx, value_ptr(&to->value), value_ptrs);
}

void cmd_entry_points(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    puts(s->prog.entry_points[i].name);
  }
}

void cmd_types(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.types[i] != NULL; i++) {
    puts(s->prog.types[i]->name);
  }
}

char *next_word(char **line) {
  char *p = *line;

  while (isspace(*p)) {
    p++;
  }

  if (*p == 0) {
    return NULL;
  }

  if (*p == '"') {
    char *save = p+1;
    // Skip ahead till closing quote.
    p++;

    while (*p && *p != '"') {
      p++;
    }

    if (*p == '"') {
      *p = 0;
      *line = p+1;
      return save;
    } else {
      return NULL;
    }
  } else {
    char *save = p;
    // Skip ahead till next whitespace.

    while (*p && !isspace(*p)) {
      p++;
    }

    if (*p) {
      *p = 0;
      *line = p+1;
    } else {
      *line = p;
    }
    return save;
  }
}

void process_line(struct server_state *s, char *line) {
  int max_num_tokens = 1000;
  const char* tokens[max_num_tokens];
  int num_tokens = 0;

  while ((tokens[num_tokens] = next_word(&line)) != NULL) {
    num_tokens++;
    if (num_tokens == max_num_tokens) {
      futhark_panic(1, "Line too long.\n");
    }
  }

  const char *command = tokens[0];

  if (command == NULL) {
    failure();
    printf("Empty line\n");
  } else if (strcmp(command, "call") == 0) {
    cmd_call(s, tokens+1);
  } else if (strcmp(command, "restore") == 0) {
    cmd_restore(s, tokens+1);
  } else if (strcmp(command, "store") == 0) {
    cmd_store(s, tokens+1);
  } else if (strcmp(command, "free") == 0) {
    cmd_free(s, tokens+1);
  } else if (strcmp(command, "rename") == 0) {
    cmd_rename(s, tokens+1);
  } else if (strcmp(command, "inputs") == 0) {
    cmd_inputs(s, tokens+1);
  } else if (strcmp(command, "outputs") == 0) {
    cmd_outputs(s, tokens+1);
  } else if (strcmp(command, "clear") == 0) {
    cmd_clear(s, tokens+1);
  } else if (strcmp(command, "pause_profiling") == 0) {
    cmd_pause_profiling(s, tokens+1);
  } else if (strcmp(command, "unpause_profiling") == 0) {
    cmd_unpause_profiling(s, tokens+1);
  } else if (strcmp(command, "report") == 0) {
    cmd_report(s, tokens+1);
  } else if (strcmp(command, "set_tuning_param") == 0) {
    cmd_set_tuning_param(s, tokens+1);
  } else if (strcmp(command, "tuning_params") == 0) {
    cmd_tuning_params(s, tokens+1);
  } else if (strcmp(command, "tuning_param_class") == 0) {
    cmd_tuning_param_class(s, tokens+1);
  } else if (strcmp(command, "fields") == 0) {
    cmd_fields(s, tokens+1);
  } else if (strcmp(command, "new") == 0) {
    cmd_new(s, tokens+1);
  } else if (strcmp(command, "project") == 0) {
    cmd_project(s, tokens+1);
  } else if (strcmp(command, "entry_points") == 0) {
    cmd_entry_points(s, tokens+1);
  } else if (strcmp(command, "types") == 0) {
    cmd_types(s, tokens+1);
  } else {
    futhark_panic(1, "Unknown command: %s\n", command);
  }
}

void run_server(struct futhark_prog *prog,
                struct futhark_context_config *cfg,
                struct futhark_context *ctx) {
  char *line = NULL;
  size_t buflen = 0;
  ssize_t linelen;

  struct server_state s = {
    .cfg = cfg,
    .ctx = ctx,
    .variables_capacity = 100,
    .prog = *prog
  };

  s.variables = malloc(s.variables_capacity * sizeof(struct variable));

  for (int i = 0; i < s.variables_capacity; i++) {
    s.variables[i].name = NULL;
  }

  ok();
  while ((linelen = getline(&line, &buflen, stdin)) > 0) {
    process_line(&s, line);
    ok();
  }

  free(s.variables);
  free(line);
}

// The aux struct lets us write generic method implementations without
// code duplication.

typedef void* (*array_new_fn)(struct futhark_context *, const void*, const int64_t*);
typedef const int64_t* (*array_shape_fn)(struct futhark_context*, void*);
typedef int (*array_values_fn)(struct futhark_context*, void*, void*);
typedef int (*array_free_fn)(struct futhark_context*, void*);

struct array_aux {
  int rank;
  const struct primtype_info_t* info;
  const char *name;
  array_new_fn new;
  array_shape_fn shape;
  array_values_fn values;
  array_free_fn free;
};

int restore_array(const struct array_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *data = NULL;
  int64_t shape[aux->rank];
  if (read_array(f, aux->info, &data, shape, aux->rank) != 0) {
    return 1;
  }

  void *arr = aux->new(ctx, data, shape);
  if (arr == NULL) {
    return 1;
  }
  int err = futhark_context_sync(ctx);
  *(void**)p = arr;
  free(data);
  return err;
}

void store_array(const struct array_aux *aux, FILE *f,
                 struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  const int64_t *shape = aux->shape(ctx, arr);
  int64_t size = sizeof(aux->info->size);
  for (int i = 0; i < aux->rank; i++) {
    size *= shape[i];
  }
  int32_t *data = malloc(size);
  assert(aux->values(ctx, arr, data) == 0);
  assert(futhark_context_sync(ctx) == 0);
  assert(write_array(f, 1, aux->info, data, shape, aux->rank) == 0);
  free(data);
}

int free_array(const struct array_aux *aux,
               struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  return aux->free(ctx, arr);
}

typedef void* (*opaque_restore_fn)(struct futhark_context*, void*);
typedef int (*opaque_store_fn)(struct futhark_context*, const void*, void **, size_t *);
typedef int (*opaque_free_fn)(struct futhark_context*, void*);

struct opaque_aux {
  opaque_restore_fn restore;
  opaque_store_fn store;
  opaque_free_fn free;
};

int restore_opaque(const struct opaque_aux *aux, FILE *f,
                   struct futhark_context *ctx, void *p) {
  // We have a problem: we need to load data from 'f', since the
  // restore function takes a pointer, but we don't know how much we
  // need (and cannot possibly).  So we do something hacky: we read
  // *all* of the file, pass all of the data to the restore function
  // (which doesn't care if there's extra at the end), then we compute
  // how much space the the object actually takes in serialised form
  // and rewind the file to that position.  The only downside is more IO.
  size_t start = ftell(f);
  size_t size;
  char *bytes = fslurp_file(f, &size);
  void *obj = aux->restore(ctx, bytes);
  free(bytes);
  if (obj != NULL) {
    *(void**)p = obj;
    size_t obj_size;
    (void)aux->store(ctx, obj, NULL, &obj_size);
    fseek(f, start+obj_size, SEEK_SET);
    return 0;
  } else {
    fseek(f, start, SEEK_SET);
    return 1;
  }
}

void store_opaque(const struct opaque_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  size_t obj_size;
  void *data = NULL;
  (void)aux->store(ctx, obj, &data, &obj_size);
  assert(futhark_context_sync(ctx) == 0);
  fwrite(data, sizeof(char), obj_size, f);
  free(data);
}

int free_opaque(const struct opaque_aux *aux,
                struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  return aux->free(ctx, obj);
}

// End of server.h.

// Start of tuning.h.


int is_blank_line_or_comment(const char *s) {
  size_t i = strspn(s, " \t");
  return s[i] == '\0' || // Line is blank.
         strncmp(s + i, "--", 2) == 0; // Line is comment.
}

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    if (is_blank_line_or_comment(line)) {
      continue;
    }
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      char *endptr;
      int value = strtol(eql+1, &endptr, 10);
      if (*endptr && *endptr != '\n') {
        snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
                 lineno);
        return line;
      }
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

const struct type type_ZMZNZMZNZMZNf16;
const struct type type_ZMZNZMZNf16;
void *futhark_new_f16_3d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_f16_3d(ctx, p, shape[0], shape[1], shape[2]);
}
const struct array_aux type_ZMZNZMZNZMZNf16_aux = {.name ="[][][]f16", .rank =3, .info =&f16_info, .new =(array_new_fn) futhark_new_f16_3d_wrap, .free =(array_free_fn) futhark_free_f16_3d, .shape =(array_shape_fn) futhark_shape_f16_3d, .values =(array_values_fn) futhark_values_f16_3d};
const struct type type_ZMZNZMZNZMZNf16 = {.name ="[][][]f16", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNZMZNZMZNf16_aux};
void *futhark_new_f16_2d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_f16_2d(ctx, p, shape[0], shape[1]);
}
const struct array_aux type_ZMZNZMZNf16_aux = {.name ="[][]f16", .rank =2, .info =&f16_info, .new =(array_new_fn) futhark_new_f16_2d_wrap, .free =(array_free_fn) futhark_free_f16_2d, .shape =(array_shape_fn) futhark_shape_f16_2d, .values =(array_values_fn) futhark_values_f16_2d};
const struct type type_ZMZNZMZNf16 = {.name ="[][]f16", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNZMZNf16_aux};
const struct type *mk_input_out_types[] = {&type_ZMZNZMZNZMZNf16, &type_ZMZNZMZNf16, &type_ZMZNZMZNf16, NULL};
bool mk_input_out_unique[] = {false, false, false};
const struct type *mk_input_in_types[] = {&type_i64, &type_i64, NULL};
bool mk_input_in_unique[] = {false, false};
const char *mk_input_tuning_params[] = {"builtin#replicate_f16.tblock_size_11023", NULL};
int call_mk_input(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f16_3d * *out0 = outs[0];
    struct futhark_f16_2d * *out1 = outs[1];
    struct futhark_f16_2d * *out2 = outs[2];
    int64_t in0 = *(int64_t *) ins[0];
    int64_t in1 = *(int64_t *) ins[1];
    
    return futhark_entry_mk_input(ctx, out0, out1, out2, in0, in1);
}
const struct type *run128_out_types[] = {&type_ZMZNZMZNZMZNf16, NULL};
bool run128_out_unique[] = {true};
const struct type *run128_in_types[] = {&type_ZMZNZMZNZMZNf16, &type_ZMZNZMZNf16, &type_ZMZNZMZNf16, NULL};
bool run128_in_unique[] = {false, false, false};
const char *run128_tuning_params[] = {"run128.Ry_10059", "run128.Ry_9679", "run128.Tk_10057", "run128.Tk_9677", "run128.Ty_10058", "run128.Ty_9678", "run128.segmap_num_tblocks_9053", "run128.segmap_num_tblocks_9150", "run128.segmap_tblock_size_9051", "run128.segmap_tblock_size_9148", "run128.segred_num_tblocks_9289", "run128.segred_num_tblocks_9368", "run128.segred_tblock_size_9287", "run128.segred_tblock_size_9366", "run128.suff_intra_par_1", "run128.suff_intra_par_3", "run128.suff_outer_par_0", "run128.suff_outer_par_2", "run128.suff_outer_par_4", "run128.suff_outer_par_5", NULL};
int call_run128(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f16_3d * *out0 = outs[0];
    struct futhark_f16_3d * in0 = *(struct futhark_f16_3d * *) ins[0];
    struct futhark_f16_2d * in1 = *(struct futhark_f16_2d * *) ins[1];
    struct futhark_f16_2d * in2 = *(struct futhark_f16_2d * *) ins[2];
    
    return futhark_entry_run128(ctx, out0, in0, in1, in2);
}
const struct type *run16_out_types[] = {&type_ZMZNZMZNZMZNf16, NULL};
bool run16_out_unique[] = {true};
const struct type *run16_in_types[] = {&type_ZMZNZMZNZMZNf16, &type_ZMZNZMZNf16, &type_ZMZNZMZNf16, NULL};
bool run16_in_unique[] = {false, false, false};
const char *run16_tuning_params[] = {"run16.segmap_num_tblocks_7019", "run16.segmap_num_tblocks_7116", "run16.segmap_tblock_size_7017", "run16.segmap_tblock_size_7114", "run16.segred_num_tblocks_7255", "run16.segred_num_tblocks_7334", "run16.segred_tblock_size_7253", "run16.segred_tblock_size_7332", "run16.suff_intra_par_1", "run16.suff_intra_par_3", "run16.suff_outer_par_0", "run16.suff_outer_par_2", "run16.suff_outer_par_4", "run16.suff_outer_par_5", NULL};
int call_run16(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f16_3d * *out0 = outs[0];
    struct futhark_f16_3d * in0 = *(struct futhark_f16_3d * *) ins[0];
    struct futhark_f16_2d * in1 = *(struct futhark_f16_2d * *) ins[1];
    struct futhark_f16_2d * in2 = *(struct futhark_f16_2d * *) ins[2];
    
    return futhark_entry_run16(ctx, out0, in0, in1, in2);
}
const struct type *run32_out_types[] = {&type_ZMZNZMZNZMZNf16, NULL};
bool run32_out_unique[] = {true};
const struct type *run32_in_types[] = {&type_ZMZNZMZNZMZNf16, &type_ZMZNZMZNf16, &type_ZMZNZMZNf16, NULL};
bool run32_in_unique[] = {false, false, false};
const char *run32_tuning_params[] = {"run32.segmap_num_tblocks_7697", "run32.segmap_num_tblocks_7794", "run32.segmap_tblock_size_7695", "run32.segmap_tblock_size_7792", "run32.segred_num_tblocks_7933", "run32.segred_num_tblocks_8012", "run32.segred_tblock_size_7931", "run32.segred_tblock_size_8010", "run32.suff_intra_par_1", "run32.suff_intra_par_3", "run32.suff_outer_par_0", "run32.suff_outer_par_2", "run32.suff_outer_par_4", "run32.suff_outer_par_5", NULL};
int call_run32(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f16_3d * *out0 = outs[0];
    struct futhark_f16_3d * in0 = *(struct futhark_f16_3d * *) ins[0];
    struct futhark_f16_2d * in1 = *(struct futhark_f16_2d * *) ins[1];
    struct futhark_f16_2d * in2 = *(struct futhark_f16_2d * *) ins[2];
    
    return futhark_entry_run32(ctx, out0, in0, in1, in2);
}
const struct type *run64_out_types[] = {&type_ZMZNZMZNZMZNf16, NULL};
bool run64_out_unique[] = {true};
const struct type *run64_in_types[] = {&type_ZMZNZMZNZMZNf16, &type_ZMZNZMZNf16, &type_ZMZNZMZNf16, NULL};
bool run64_in_unique[] = {false, false, false};
const char *run64_tuning_params[] = {"run64.Ry_10059", "run64.Ry_9679", "run64.Tk_10057", "run64.Tk_9677", "run64.Ty_10058", "run64.Ty_9678", "run64.segmap_num_tblocks_8375", "run64.segmap_num_tblocks_8472", "run64.segmap_tblock_size_8373", "run64.segmap_tblock_size_8470", "run64.segred_num_tblocks_8611", "run64.segred_num_tblocks_8690", "run64.segred_tblock_size_8609", "run64.segred_tblock_size_8688", "run64.suff_intra_par_1", "run64.suff_intra_par_3", "run64.suff_outer_par_0", "run64.suff_outer_par_2", "run64.suff_outer_par_4", "run64.suff_outer_par_5", NULL};
int call_run64(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f16_3d * *out0 = outs[0];
    struct futhark_f16_3d * in0 = *(struct futhark_f16_3d * *) ins[0];
    struct futhark_f16_2d * in1 = *(struct futhark_f16_2d * *) ins[1];
    struct futhark_f16_2d * in2 = *(struct futhark_f16_2d * *) ins[2];
    
    return futhark_entry_run64(ctx, out0, in0, in1, in2);
}
const struct type *types[] = {&type_i8, &type_i16, &type_i32, &type_i64, &type_u8, &type_u16, &type_u32, &type_u64, &type_f16, &type_f32, &type_f64, &type_bool, &type_ZMZNZMZNZMZNf16, &type_ZMZNZMZNf16, NULL};
struct entry_point entry_points[] = {{.name ="mk_input", .f =call_mk_input, .tuning_params =mk_input_tuning_params, .in_types =mk_input_in_types, .out_types =mk_input_out_types, .in_unique =mk_input_in_unique, .out_unique =mk_input_out_unique}, {.name ="run128", .f =call_run128, .tuning_params =run128_tuning_params, .in_types =run128_in_types, .out_types =run128_out_types, .in_unique =run128_in_unique, .out_unique =run128_out_unique}, {.name ="run16", .f =call_run16, .tuning_params =run16_tuning_params, .in_types =run16_in_types, .out_types =run16_out_types, .in_unique =run16_in_unique, .out_unique =run16_out_unique}, {.name ="run32", .f =call_run32, .tuning_params =run32_tuning_params, .in_types =run32_in_types, .out_types =run32_out_types, .in_unique =run32_in_unique, .out_unique =run32_out_unique}, {.name ="run64", .f =call_run64, .tuning_params =run64_tuning_params, .in_types =run64_in_types, .out_types =run64_out_types, .in_unique =run64_in_unique, .out_unique =run64_out_unique}, {.name =NULL}};
struct futhark_prog prog = {.types =types, .entry_points =entry_points};
int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"debugging", no_argument, NULL, 1}, {"log", no_argument, NULL, 2}, {"profile", no_argument, NULL, 3}, {"help", no_argument, NULL, 4}, {"print-params", no_argument, NULL, 5}, {"param", required_argument, NULL, 6}, {"tuning", required_argument, NULL, 7}, {"cache-file", required_argument, NULL, 8}, {"device", required_argument, NULL, 9}, {"default-thread-block-size", required_argument, NULL, 10}, {"default-grid-size", required_argument, NULL, 11}, {"default-group-size", required_argument, NULL, 12}, {"default-num-groups", required_argument, NULL, 13}, {"default-tile-size", required_argument, NULL, 14}, {"default-reg-tile-size", required_argument, NULL, 15}, {"default-registers", required_argument, NULL, 16}, {"default-cache", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"unified-memory", required_argument, NULL, 19}, {"dump-cuda", required_argument, NULL, 20}, {"load-cuda", required_argument, NULL, 21}, {"dump-ptx", required_argument, NULL, 22}, {"load-ptx", required_argument, NULL, 23}, {"nvrtc-option", required_argument, NULL, 24}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n";
    
    while ((ch = getopt_long(argc, argv, ":DLPhd:", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 'D')
            futhark_context_config_set_debugging(cfg, 1);
        if (ch == 2 || ch == 'L')
            futhark_context_config_set_logging(cfg, 1);
        if (ch == 3 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == 4 || ch == 'h') {
            printf("Usage: %s [OPTIONS]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 5) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 6) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 7) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning file '%s': %s\n", optarg, ret);
        }
        if (ch == 8)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 9 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 10)
            futhark_context_config_set_default_thread_block_size(cfg, atoi(optarg));
        if (ch == 11)
            futhark_context_config_set_default_grid_size(cfg, atoi(optarg));
        if (ch == 12)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 13)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 14)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_registers(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_cache(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19)
            futhark_context_config_set_unified_memory(cfg, atoi(optarg));
        if (ch == 20) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(0);
        }
        if (ch == 21) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 22) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 23)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 24)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
int main(int argc, char **argv)
{
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    futhark_context_set_logging_file(ctx, stdout);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "Error during context initialisation:\n%s", error);
    if (entry_point != NULL)
        run_server(&prog, cfg, ctx);
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_11289;
    struct memblock_device counters_mem_11445;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhreplicate_f16zitblock_sizze_11023;
    int64_t *builtinzhreplicate_i32zitblock_sizze_11300;
    int64_t *run128ziRy_10059;
    int64_t *run128ziRy_9679;
    int64_t *run128ziTk_10057;
    int64_t *run128ziTk_9677;
    int64_t *run128ziTy_10058;
    int64_t *run128ziTy_9678;
    int64_t *run128zisegmap_num_tblocks_9053;
    int64_t *run128zisegmap_num_tblocks_9150;
    int64_t *run128zisegmap_tblock_sizze_9051;
    int64_t *run128zisegmap_tblock_sizze_9148;
    int64_t *run128zisegred_num_tblocks_9289;
    int64_t *run128zisegred_num_tblocks_9368;
    int64_t *run128zisegred_tblock_sizze_9287;
    int64_t *run128zisegred_tblock_sizze_9366;
    int64_t *run128zisuff_intra_par_1;
    int64_t *run128zisuff_intra_par_3;
    int64_t *run128zisuff_outer_par_0;
    int64_t *run128zisuff_outer_par_2;
    int64_t *run128zisuff_outer_par_4;
    int64_t *run128zisuff_outer_par_5;
    int64_t *run16zisegmap_num_tblocks_7019;
    int64_t *run16zisegmap_num_tblocks_7116;
    int64_t *run16zisegmap_tblock_sizze_7017;
    int64_t *run16zisegmap_tblock_sizze_7114;
    int64_t *run16zisegred_num_tblocks_7255;
    int64_t *run16zisegred_num_tblocks_7334;
    int64_t *run16zisegred_tblock_sizze_7253;
    int64_t *run16zisegred_tblock_sizze_7332;
    int64_t *run16zisuff_intra_par_1;
    int64_t *run16zisuff_intra_par_3;
    int64_t *run16zisuff_outer_par_0;
    int64_t *run16zisuff_outer_par_2;
    int64_t *run16zisuff_outer_par_4;
    int64_t *run16zisuff_outer_par_5;
    int64_t *run32zisegmap_num_tblocks_7697;
    int64_t *run32zisegmap_num_tblocks_7794;
    int64_t *run32zisegmap_tblock_sizze_7695;
    int64_t *run32zisegmap_tblock_sizze_7792;
    int64_t *run32zisegred_num_tblocks_7933;
    int64_t *run32zisegred_num_tblocks_8012;
    int64_t *run32zisegred_tblock_sizze_7931;
    int64_t *run32zisegred_tblock_sizze_8010;
    int64_t *run32zisuff_intra_par_1;
    int64_t *run32zisuff_intra_par_3;
    int64_t *run32zisuff_outer_par_0;
    int64_t *run32zisuff_outer_par_2;
    int64_t *run32zisuff_outer_par_4;
    int64_t *run32zisuff_outer_par_5;
    int64_t *run64ziRy_10059;
    int64_t *run64ziRy_9679;
    int64_t *run64ziTk_10057;
    int64_t *run64ziTk_9677;
    int64_t *run64ziTy_10058;
    int64_t *run64ziTy_9678;
    int64_t *run64zisegmap_num_tblocks_8375;
    int64_t *run64zisegmap_num_tblocks_8472;
    int64_t *run64zisegmap_tblock_sizze_8373;
    int64_t *run64zisegmap_tblock_sizze_8470;
    int64_t *run64zisegred_num_tblocks_8611;
    int64_t *run64zisegred_num_tblocks_8690;
    int64_t *run64zisegred_tblock_sizze_8609;
    int64_t *run64zisegred_tblock_sizze_8688;
    int64_t *run64zisuff_intra_par_1;
    int64_t *run64zisuff_intra_par_3;
    int64_t *run64zisuff_outer_par_0;
    int64_t *run64zisuff_outer_par_2;
    int64_t *run64zisuff_outer_par_4;
    int64_t *run64zisuff_outer_par_5;
};
static const int num_tuning_params = 70;
static const char *tuning_param_names[] = {"builtin#replicate_f16.tblock_size_11023", "builtin#replicate_i32.tblock_size_11300", "run128.Ry_10059", "run128.Ry_9679", "run128.Tk_10057", "run128.Tk_9677", "run128.Ty_10058", "run128.Ty_9678", "run128.segmap_num_tblocks_9053", "run128.segmap_num_tblocks_9150", "run128.segmap_tblock_size_9051", "run128.segmap_tblock_size_9148", "run128.segred_num_tblocks_9289", "run128.segred_num_tblocks_9368", "run128.segred_tblock_size_9287", "run128.segred_tblock_size_9366", "run128.suff_intra_par_1", "run128.suff_intra_par_3", "run128.suff_outer_par_0", "run128.suff_outer_par_2", "run128.suff_outer_par_4", "run128.suff_outer_par_5", "run16.segmap_num_tblocks_7019", "run16.segmap_num_tblocks_7116", "run16.segmap_tblock_size_7017", "run16.segmap_tblock_size_7114", "run16.segred_num_tblocks_7255", "run16.segred_num_tblocks_7334", "run16.segred_tblock_size_7253", "run16.segred_tblock_size_7332", "run16.suff_intra_par_1", "run16.suff_intra_par_3", "run16.suff_outer_par_0", "run16.suff_outer_par_2", "run16.suff_outer_par_4", "run16.suff_outer_par_5", "run32.segmap_num_tblocks_7697", "run32.segmap_num_tblocks_7794", "run32.segmap_tblock_size_7695", "run32.segmap_tblock_size_7792", "run32.segred_num_tblocks_7933", "run32.segred_num_tblocks_8012", "run32.segred_tblock_size_7931", "run32.segred_tblock_size_8010", "run32.suff_intra_par_1", "run32.suff_intra_par_3", "run32.suff_outer_par_0", "run32.suff_outer_par_2", "run32.suff_outer_par_4", "run32.suff_outer_par_5", "run64.Ry_10059", "run64.Ry_9679", "run64.Tk_10057", "run64.Tk_9677", "run64.Ty_10058", "run64.Ty_9678", "run64.segmap_num_tblocks_8375", "run64.segmap_num_tblocks_8472", "run64.segmap_tblock_size_8373", "run64.segmap_tblock_size_8470", "run64.segred_num_tblocks_8611", "run64.segred_num_tblocks_8690", "run64.segred_tblock_size_8609", "run64.segred_tblock_size_8688", "run64.suff_intra_par_1", "run64.suff_intra_par_3", "run64.suff_outer_par_0", "run64.suff_outer_par_2", "run64.suff_outer_par_4", "run64.suff_outer_par_5", NULL};
static const char *tuning_param_vars[] = {"builtinzhreplicate_f16zitblock_sizze_11023", "builtinzhreplicate_i32zitblock_sizze_11300", "run128ziRy_10059", "run128ziRy_9679", "run128ziTk_10057", "run128ziTk_9677", "run128ziTy_10058", "run128ziTy_9678", "run128zisegmap_num_tblocks_9053", "run128zisegmap_num_tblocks_9150", "run128zisegmap_tblock_sizze_9051", "run128zisegmap_tblock_sizze_9148", "run128zisegred_num_tblocks_9289", "run128zisegred_num_tblocks_9368", "run128zisegred_tblock_sizze_9287", "run128zisegred_tblock_sizze_9366", "run128zisuff_intra_par_1", "run128zisuff_intra_par_3", "run128zisuff_outer_par_0", "run128zisuff_outer_par_2", "run128zisuff_outer_par_4", "run128zisuff_outer_par_5", "run16zisegmap_num_tblocks_7019", "run16zisegmap_num_tblocks_7116", "run16zisegmap_tblock_sizze_7017", "run16zisegmap_tblock_sizze_7114", "run16zisegred_num_tblocks_7255", "run16zisegred_num_tblocks_7334", "run16zisegred_tblock_sizze_7253", "run16zisegred_tblock_sizze_7332", "run16zisuff_intra_par_1", "run16zisuff_intra_par_3", "run16zisuff_outer_par_0", "run16zisuff_outer_par_2", "run16zisuff_outer_par_4", "run16zisuff_outer_par_5", "run32zisegmap_num_tblocks_7697", "run32zisegmap_num_tblocks_7794", "run32zisegmap_tblock_sizze_7695", "run32zisegmap_tblock_sizze_7792", "run32zisegred_num_tblocks_7933", "run32zisegred_num_tblocks_8012", "run32zisegred_tblock_sizze_7931", "run32zisegred_tblock_sizze_8010", "run32zisuff_intra_par_1", "run32zisuff_intra_par_3", "run32zisuff_outer_par_0", "run32zisuff_outer_par_2", "run32zisuff_outer_par_4", "run32zisuff_outer_par_5", "run64ziRy_10059", "run64ziRy_9679", "run64ziTk_10057", "run64ziTk_9677", "run64ziTy_10058", "run64ziTy_9678", "run64zisegmap_num_tblocks_8375", "run64zisegmap_num_tblocks_8472", "run64zisegmap_tblock_sizze_8373", "run64zisegmap_tblock_sizze_8470", "run64zisegred_num_tblocks_8611", "run64zisegred_num_tblocks_8690", "run64zisegred_tblock_sizze_8609", "run64zisegred_tblock_sizze_8688", "run64zisuff_intra_par_1", "run64zisuff_intra_par_3", "run64zisuff_outer_par_0", "run64zisuff_outer_par_2", "run64zisuff_outer_par_4", "run64zisuff_outer_par_5", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "reg_tile_size", "reg_tile_size", "tile_size", "tile_size", "tile_size", "tile_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(32, !run128.suff_outer_par_0)", "threshold(32, !run128.suff_outer_par_2 !run128.suff_outer_par_0 !run128.suff_intra_par_1)", "threshold(def, )", "threshold(def, !run128.suff_outer_par_0 !run128.suff_intra_par_1)", "threshold(def, !run128.suff_outer_par_2 !run128.suff_intra_par_3 !run128.suff_outer_par_0 !run128.suff_intra_par_1)", "threshold(def, !run128.suff_outer_par_2 !run128.suff_intra_par_3 !run128.suff_outer_par_0 !run128.suff_intra_par_1)", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(32, !run16.suff_outer_par_0)", "threshold(32, !run16.suff_outer_par_2 !run16.suff_outer_par_0 !run16.suff_intra_par_1)", "threshold(def, )", "threshold(def, !run16.suff_outer_par_0 !run16.suff_intra_par_1)", "threshold(def, !run16.suff_outer_par_2 !run16.suff_intra_par_3 !run16.suff_outer_par_0 !run16.suff_intra_par_1)", "threshold(def, !run16.suff_outer_par_2 !run16.suff_intra_par_3 !run16.suff_outer_par_0 !run16.suff_intra_par_1)", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(32, !run32.suff_outer_par_0)", "threshold(32, !run32.suff_outer_par_2 !run32.suff_outer_par_0 !run32.suff_intra_par_1)", "threshold(def, )", "threshold(def, !run32.suff_outer_par_0 !run32.suff_intra_par_1)", "threshold(def, !run32.suff_outer_par_2 !run32.suff_intra_par_3 !run32.suff_outer_par_0 !run32.suff_intra_par_1)", "threshold(def, !run32.suff_outer_par_2 !run32.suff_intra_par_3 !run32.suff_outer_par_0 !run32.suff_intra_par_1)", "reg_tile_size", "reg_tile_size", "tile_size", "tile_size", "tile_size", "tile_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "threshold(32, !run64.suff_outer_par_0)", "threshold(32, !run64.suff_outer_par_2 !run64.suff_outer_par_0 !run64.suff_intra_par_1)", "threshold(def, )", "threshold(def, !run64.suff_outer_par_0 !run64.suff_intra_par_1)", "threshold(def, !run64.suff_outer_par_2 !run64.suff_intra_par_3 !run64.suff_outer_par_0 !run64.suff_intra_par_1)", "threshold(def, !run64.suff_outer_par_2 !run64.suff_intra_par_3 !run64.suff_outer_par_0 !run64.suff_intra_par_1)", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 0, 0, 0, 0, 0};
static const int max_failure_args = 0;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n#define FUTHARK_CUDATC\n// start of prelude.cu\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\n#ifdef FUTHARK_CUDATC\n#include <cute/tensor.hpp>\n#else\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n#endif\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence", "_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000", ", 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, ",
                                    "0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n", "\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24", ", 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x3",
                                    "7140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x3", "79C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x3", "7EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0",
                                    "x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0", "x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0", "x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000,",
                                    " 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000,", " 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000,", " 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C000",
                                    "0, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A00", "0, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x3875400", "0, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, ",
                                    "1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to acciden", "tally implement\n// floating-point functions in the wrong precision, so be careful.\n\n// Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n", "\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n ",
                                    " foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  re", "turn sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y =", "= 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys",
                                    ";\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - ", "1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < ", "0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  r",
                                    "eturn y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\n", "SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint3", "2_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8",
                                    "_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  ", "return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VERSION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_h", "i(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int1",
                                    "6_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32", "_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz", "(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR ",
                                    "int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1;\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR", " float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } el", "se {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return ",
                                    "acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" u", "nmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) retur", "n INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts",
                                    "_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, flo", "at y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  r", "eturn x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double",
                                    " futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return", " res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_i", "snan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (floa",
                                    "t) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#else\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin6", "4(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } ", "else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef",
                                    " __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f", "16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATT", "R f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16",
                                    "(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n ", " return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 ", "futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hy",
                                    "pot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No", " native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, ", "y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x ",
                                    "< 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p,", " uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if ", "defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_global((volatile __global int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_",
                                    "t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(F", "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int", "64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, doub",
                                    "le x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHA", "RK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_a", "nd_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t",
                                    " mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                            ", "                 \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n              ", "                                  int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n                                                int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      in",
                                    "t32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n          ", "                            int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n                                      int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if ", "(x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n          ",
                                    "                        int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                           ", "      \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                              ", "     \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD",
                                    ") < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_str", "ide2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                                                        \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                    ", "                 \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                                                \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                 ",
                                    "               \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];                            \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\nusing namespace cute;\n\ntemplate<class TypeIn>\nstruct convert_type {\n    using TypeOut = TypeIn;\n};\n\ntemplate<>\nstruct convert_type<f16> {\n    using TypeOut = half_t;\n};\n\ntemplate<class ElmTypeAIn, class ElmTypeBIn, class ElmTypeCIn, class SizeM, class SizeN, class WarpsM, class WarpsN>\nstruct get_mma_config {};\n\n// TODO: use FMA when Tensor Cores not available?\n\ntemplate<class SizeM, class SizeN, class WarpsM, class WarpsN>\nstruct get_mma_config<half_t, half_t, half_t, SizeM, SizeN, WarpsM, WarpsN> {\n    // TODO: should depend on architecture available\n    using MMATraits = MMA_Traits<SM80_16x8x16_F16F16F16F16_TN>;\n    using ACopyOpSharedRegisters = SM75_U32x4_LDSM_N;\n    using BCopyOpSharedRegisters = SM75_U16x8_LDSM_T;\n\n    using MMATile = Tile<Int<16 * WarpsM{}>, Int<16 * WarpsN{}>, _16>;\n    using TiledMMA = TiledMMA<\n        MMA_Atom<MMATraits>,\n        Layout<Shape<WarpsM,WarpsN,_1>>,\n        MMATile\n    >;\n};\n\ntemplate<class SizeM, class SizeN, class WarpsM, class WarpsN>\nstruct get_mma_config<half_t, half_t, float, SizeM, SizeN, WarpsM, WarpsN>{\n    // TODO: should depend on architecture available\n    using MMATraits = MMA_Traits<SM80_16x8x16_F32F16F", "16F32_TN>;\n    using ACopyOpSharedRegisters = SM75_U32x4_LDSM_N;\n    using BCopyOpSharedRegisters = SM75_U16x8_LDSM_T;\n\n    using MMATile = Tile<Int<16 * WarpsM{}>, Int<16 * WarpsN{}>, _16>;\n    using TiledMMA = TiledMMA<\n        MMA_Atom<MMATraits>,\n        Layout<Shape<WarpsM,WarpsN,_1>>,\n        MMATile\n    >;\n};\n\ntemplate<class SizeY, class SizeX, class Swizzle, class Majorness, int shift_len>\nstruct get_layout_config {};\n\ntemplate<class SizeY, class SizeX, int shift_len>\nstruct get_layout_config<SizeY, SizeX, _1, LayoutRight, shift_len>{\n    using SharedLayout = ComposedLayout<Swizzle<3, 3, shift_len>, _0, Layout<Shape<SizeY, SizeX>, Stride<SizeX, _1>>>;\n};\n\ntemplate<class SizeY, class SizeX, int shift_len>\nstruct get_layout_config<SizeY, SizeX, _0, LayoutRight, shift_len>{\n    using SharedLayout = Layout<Shape<SizeY, SizeX>, Stride<SizeX, _1>>;\n};\n\ntemplate<class SizeY, class SizeX, int shift_len>\nstruct get_layout_config<SizeY, SizeX, _1, LayoutLeft, shift_len>{\n    using SharedLayout = ComposedLayout<Swizzle<3, 3, shift_len>, _0, Layout<Shape<SizeY, SizeX>, Stride<_1, SizeY>>>;\n};\n\ntemplate<class SizeY, class SizeX, int shift_len>\nstruct get_layout_config<SizeY, SizeX, _0, LayoutLeft, shift_len>{\n    using SharedLayout = Layout<Shape<SizeY, SizeX>, Stride<_1, SizeY>>;\n};\n\ntemplate<class ElmTypeIn, class SizeY, class SizeX, class WarpsM, class WarpsN>\nFUTHARK_FUN_ATTR void futrts_copyGlobalShared(unsigned char **mem_out_p, unsigned char *global_mem, unsigned char *shared_mem, int64_t offset, ElmTypeIn, SizeY, SizeX, WarpsM, WarpsN)\n{\n    *mem_out_p = shared_mem;\n\n    int flatThreadIdx = threadIdx.z * blockDim.y * blockDim.x + threadIdx.y * blockDim.x + threadIdx.x;\n\n    if (flatThreadIdx < WarpsM{} * WarpsN{} * 32) {\n      using ElmType = typename convert_type<ElmTypeIn>::TypeOut;\n\n      using CopyOpGlobalShared = SM80_CP_ASYNC_CACHEGLOBAL<uint128_t>;\n\n      constexpr int elmsPerLoad = 16 / sizeof(ElmType);\n      constexpr int threadsX = SizeX{} / elmsPerLoad", ";\n      constexpr int threadsY = (WarpsM{} * WarpsN{} * 32) / threadsX;\n\n      constexpr unsigned int sizeXunsigned = SizeX{};\n      constexpr unsigned int shift_len = max(bit_width(sizeXunsigned) - 4, _3{});\n\n      using LayoutConfig = get_layout_config<SizeY, SizeX, _1, LayoutRight, shift_len>;\n      typename LayoutConfig::SharedLayout s_layout;\n\n      auto g_layout = make_layout(Shape<SizeY, SizeX>{}, LayoutRight{});\n\n      TiledCopy copy_global_shared = make_tiled_copy(Copy_Atom<CopyOpGlobalShared, ElmType>{},\n          make_layout(Shape<Int<threadsY>, Int<threadsX>>{}, LayoutRight{}),\n          Layout<Shape<_1,Int<elmsPerLoad>>>{}\n      );\n\n      Tensor s = make_tensor(make_smem_ptr(reinterpret_cast<ElmType *>(shared_mem)), s_layout);\n      Tensor g = make_tensor(make_gmem_ptr(&reinterpret_cast<ElmType *>(global_mem)[offset]), g_layout);\n\n      ThrCopy thr_copy_global_shared = copy_global_shared.get_slice(flatThreadIdx);\n      Tensor tAgA = thr_copy_global_shared.partition_S(g);\n      Tensor tAsA = thr_copy_global_shared.partition_D(s);\n\n      copy(copy_global_shared, tAgA, tAsA);\n\n      cp_async_fence();\n    }\n\n//     Assuming the copied data is only used in futrts_tensorMMM, we do not need to wait for it here\n//     cp_async_wait<0>();\n//     __syncthreads();\n}\n\ntemplate<class ElmTypeAIn, class ElmTypeBIn, class ElmTypeCIn, class SizeM, class SizeN, class WarpsM, class WarpsN, int numRegs>\nFUTHARK_FUN_ATTR void futrts_copyRegistersShared(unsigned char **mem_out_p, ElmTypeCIn (&registers_mem)[numRegs], unsigned char *shared_mem, ElmTypeAIn, ElmTypeBIn, SizeM, SizeN, WarpsM, WarpsN)\n{\n    *mem_out_p = shared_mem;\n\n    int flatThreadIdx = threadIdx.z * blockDim.y * blockDim.x + threadIdx.y * blockDim.x + threadIdx.x;\n\n    if (flatThreadIdx < WarpsM{} * WarpsN{} * 32) {\n        using ElmTypeA = typename convert_type<ElmTypeAIn>::TypeOut;\n        using ElmTypeB = typename convert_type<ElmTypeBIn>::TypeOut;\n        using ElmTypeC = typename convert_type<ElmTypeCIn>",
                                    "::TypeOut;\n\n        using MMAConfig = get_mma_config<ElmTypeA, ElmTypeB, ElmTypeC, SizeM, SizeN, WarpsM, WarpsN>;\n        typename MMAConfig::TiledMMA tiled_mma;\n\n        auto s_layout = make_layout(Shape<SizeM, SizeN>{}, LayoutRight{});\n\n        ThrMMA thr_mma = tiled_mma.get_slice(flatThreadIdx);\n\n        auto r_layout = partition_shape_C(thr_mma, s_layout.shape());\n        Tensor tCrC = make_tensor(make_rmem_ptr(reinterpret_cast<ElmTypeC *>(registers_mem)), r_layout);\n\n        Tensor s = make_tensor(make_smem_ptr(reinterpret_cast<ElmTypeC *>(shared_mem)), s_layout);\n        Tensor tCsC = thr_mma.partition_C(s);\n\n        copy(AutoVectorizingCopy{}, tCrC, tCsC);\n    }\n    __syncthreads();\n}\n\ntemplate<class ElmTypeAIn, class ElmTypeBIn, class ElmTypeCIn, class SizeM, class SizeN, class SizeK, class WarpsM, class WarpsN, class ASwizzled, class BSwizzled, int numRegs>\nFUTHARK_FUN_ATTR void futrts_tensorMMM(ElmTypeCIn (*mem_out_p)[numRegs], unsigned char *A_mem, unsigned char *B_mem, ElmTypeCIn (&C_mem)[numRegs], ElmTypeAIn, ElmTypeBIn, SizeM, SizeN, SizeK, WarpsM, WarpsN, ASwizzled, BSwizzled)\n{\n    int flatThreadIdx = threadIdx.z * blockDim.y * blockDim.x + threadIdx.y * blockDim.x + threadIdx.x;\n\n    using ElmTypeA = typename convert_type<ElmTypeAIn>::TypeOut;\n    using ElmTypeB = typename convert_type<ElmTypeBIn>::TypeOut;\n    using ElmTypeC = typename convert_type<ElmTypeCIn>::TypeOut;\n\n    using MMAConfig = get_mma_config<ElmTypeA, ElmTypeB, ElmTypeC, SizeM, SizeN, WarpsM, WarpsN>;\n    typename MMAConfig::TiledMMA tiled_mma;\n\n    constexpr unsigned int sizeKunsigned = SizeK{};\n    constexpr unsigned int shift_lenK = max(bit_width(sizeKunsigned) - 4, _3{});\n\n    constexpr unsigned int sizeNunsigned = SizeN{};\n    constexpr unsigned int shift_lenN = max(bit_width(sizeNunsigned) - 4, _3{});\n\n    using ALayoutConfig = get_layout_config<SizeM, SizeK, ASwizzled, LayoutRight, shift_lenK>;\n    using BLayoutConfig = get_layout_config<SizeN, SizeK, BSwizzled, LayoutLeft, s", "hift_lenN>;\n    typename ALayoutConfig::SharedLayout sA_layout;\n    typename BLayoutConfig::SharedLayout sB_layout;\n\n    auto sC_layout = make_layout(Shape<SizeM, SizeN>{}, LayoutRight{});\n\n    ThrMMA thr_mma = tiled_mma.get_slice(flatThreadIdx);\n\n    auto rC_layout = partition_shape_C(thr_mma, sC_layout.shape());\n    Tensor tCrC = make_tensor(make_rmem_ptr(reinterpret_cast<ElmTypeC *>(C_mem)), rC_layout);\n\n    Tensor sA = make_tensor(make_smem_ptr(reinterpret_cast<ElmTypeA *>(A_mem)), sA_layout);\n    Tensor sB = make_tensor(make_smem_ptr(reinterpret_cast<ElmTypeB *>(B_mem)), sB_layout);\n\n    TiledCopy copyA_shared_registers = make_tiled_copy_A(Copy_Atom<typename MMAConfig::ACopyOpSharedRegisters, ElmTypeA>{}, tiled_mma);\n    TiledCopy copyB_shared_registers = make_tiled_copy_B(Copy_Atom<typename MMAConfig::BCopyOpSharedRegisters, ElmTypeB>{}, tiled_mma);\n\n    Tensor tCrA  = thr_mma.partition_fragment_A(sA);\n    Tensor tCrB  = thr_mma.partition_fragment_B(sB);\n\n    auto smem_thr_copy_A   = copyA_shared_registers.get_thread_slice(threadIdx.x);\n    Tensor tCsA            = smem_thr_copy_A.partition_S(sA);\n    Tensor tCrA_copy_view  = smem_thr_copy_A.retile_D(tCrA);\n\n    auto smem_thr_copy_B   = copyB_shared_registers.get_thread_slice(threadIdx.x);\n    Tensor tCsB            = smem_thr_copy_B.partition_S(sB);\n    Tensor tCrB_copy_view  = smem_thr_copy_B.retile_D(tCrB);\n\n    // Wait for data copied asynchronously by futrts_copyGlobalShared\n    cp_async_wait<0>();\n    __syncthreads();\n\n    constexpr int K_BLOCK_MAX = size<2>(tCrA);\n    CUTE_UNROLL\n    for (int k_block = 0; k_block < K_BLOCK_MAX; ++k_block)\n    {\n        // Copy shared->registers\n        copy(copyA_shared_registers, tCsA(_,_,k_block), tCrA_copy_view(_,_,k_block));\n        copy(copyB_shared_registers, tCsB(_,_,k_block), tCrB_copy_view(_,_,k_block));\n\n        // Perform mma on k_block in registers\n        gemm(tiled_mma, tCrA(_,_,k_block), tCrB(_,_,k_block), tCrC);\n    }\n\n    for (int32_t i = 0; i < numRegs", "; i++)\n        (*mem_out_p)[i] = C_mem[i];\n}\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhreplicate_f16zireplicate_11019(int64_t num_elems_11015, uint16_t val_11016_bits, int64_t replicate_n_11018, int64_t virt_num_tblocks_11024, int64_t num_tblocks_11025, __global unsigned char *mem_11014)\n{\n    f16 val_11016 = futrts_from_bits16(val_11016_bits);\n    int32_t replicate_ltid_11020;\n    int32_t tblock_sizze_11022;\n    int32_t replicate_gid_11021;\n    int32_t replicate_gtid_11019;\n    int32_t phys_tblock_id_11026;\n    int32_t iterations_11027;\n    \n    replicate_ltid_11020 = get_local_id(0);\n    tblock_sizze_11022 = get_local_size(0);\n    replicate_gid_11021 = get_tblock_id(0);\n    replicate_gtid_11019 = replicate_gid_11021 * tblock_sizze_11022 + replicate_ltid_11020;\n    phys_tblock_id_11026 = get_tblock_id(0);\n    iterations_11027 = sdiv_up32(sext_i64_i32(virt_num_tblocks_11024) - phys_tblock_id_11026, sext_i64_i32(num_tblocks_11025));\n    for (int32_t i_11028 = 0; i_11028 < iterations_11027; i_11028++) {\n        int32_t virt_tblock_id_11029;\n        int64_t global_tid_11030;\n        int64_t slice_11032;\n        int64_t rep_i_11031;\n        int64_t remnant_11033;\n        \n        virt_tblock_id_11029 = phys_tblock_id_11026 + i_11028 * sext_i64_i32(num_tblocks_11025);\n        global_tid_11030 = sext_i32_i64(virt_tblock_id_11029) * sext_i32_i64(tblock_sizze_11022) + sext_i32_i64(replicate_ltid_11020);\n        slice_11032 = num_elems_11015;\n        rep_i_11031 = global_tid_11030;\n        remnant_11033 = global_tid_11030 - rep_i_11031;\n        if (slt64(global_tid_11030, replicate_n_11018)) {\n            ((__global uint16_t *) mem_11014)[rep_i_11031] = futrts_to_bits16(val_11016);\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_11296(int64_t num_elems_11292, int32_t val_11293, int64_t replicate_n_11295, int64_t virt_num_tblocks_11301, int64_t num_tblocks_11302, __global un",
                                    "signed char *mem_11291)\n{\n    int32_t replicate_ltid_11297;\n    int32_t tblock_sizze_11299;\n    int32_t replicate_gid_11298;\n    int32_t replicate_gtid_11296;\n    int32_t phys_tblock_id_11303;\n    int32_t iterations_11304;\n    \n    replicate_ltid_11297 = get_local_id(0);\n    tblock_sizze_11299 = get_local_size(0);\n    replicate_gid_11298 = get_tblock_id(0);\n    replicate_gtid_11296 = replicate_gid_11298 * tblock_sizze_11299 + replicate_ltid_11297;\n    phys_tblock_id_11303 = get_tblock_id(0);\n    iterations_11304 = sdiv_up32(sext_i64_i32(virt_num_tblocks_11301) - phys_tblock_id_11303, sext_i64_i32(num_tblocks_11302));\n    for (int32_t i_11305 = 0; i_11305 < iterations_11304; i_11305++) {\n        int32_t virt_tblock_id_11306;\n        int64_t global_tid_11307;\n        int64_t slice_11309;\n        int64_t rep_i_11308;\n        int64_t remnant_11310;\n        \n        virt_tblock_id_11306 = phys_tblock_id_11303 + i_11305 * sext_i64_i32(num_tblocks_11302);\n        global_tid_11307 = sext_i32_i64(virt_tblock_id_11306) * sext_i32_i64(tblock_sizze_11299) + sext_i32_i64(replicate_ltid_11297);\n        slice_11309 = num_elems_11292;\n        rep_i_11308 = global_tid_11307;\n        remnant_11310 = global_tid_11307 - rep_i_11308;\n        if (slt64(global_tid_11307, replicate_n_11295)) {\n            ((__global int32_t *) mem_11291)[rep_i_11308] = val_11293;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run128zisegmap_9085_dim1, 1, 1)\nvoid run128zisegmap_9085(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t num_tblocks_9081, int64_t num_threads_10974, int32_t virt_num_tblocks_11024, __global unsigned char *K_mem_10473, __global unsigned char *mem_10788, __global unsigned char *mem_10798, __global unsigned char *mem_10840, __global unsigned char *color_10856)\n{\n    #define segmap_tblock_sizze_9080 (run128zisegmap_9085zisegmap_tblock_sizze_9080)\n    if (*g", "lobal_failure >= 0)\n        return;\n    \n    int32_t local_tid_11026;\n    int32_t tblock_sizze_11029;\n    int32_t wave_sizze_11028;\n    int32_t block_id_11027;\n    int32_t global_tid_11025;\n    int64_t phys_tid_9085;\n    int32_t phys_tblock_id_11030;\n    int32_t iterations_11031;\n    \n    local_tid_11026 = get_local_id(0);\n    tblock_sizze_11029 = get_local_size(0);\n    wave_sizze_11028 = LOCKSTEP_WIDTH;\n    block_id_11027 = get_tblock_id(0);\n    global_tid_11025 = block_id_11027 * tblock_sizze_11029 + local_tid_11026;\n    phys_tid_9085 = sext_i32_i64(global_tid_11025);\n    phys_tblock_id_11030 = get_tblock_id(0);\n    iterations_11031 = sdiv_up32(virt_num_tblocks_11024 - phys_tblock_id_11030, sext_i64_i32(num_tblocks_9081));\n    for (int32_t i_11032 = 0; i_11032 < iterations_11031; i_11032++) {\n        int32_t virt_tblock_id_11033;\n        int64_t global_tid_11034;\n        int64_t slice_11035;\n        int64_t gtid_9084;\n        int64_t remnant_11036;\n        \n        virt_tblock_id_11033 = phys_tblock_id_11030 + i_11032 * sext_i64_i32(num_tblocks_9081);\n        global_tid_11034 = sext_i32_i64(virt_tblock_id_11033) * segmap_tblock_sizze_9080 + sext_i32_i64(local_tid_11026);\n        slice_11035 = m_6642;\n        gtid_9084 = global_tid_11034;\n        remnant_11036 = global_tid_11034 - gtid_9084;\n        if (slt64(gtid_9084, m_6642)) {\n            f16 mem_10808[(int64_t) 128 * (int64_t) 128];\n            f16 mem_10822[(int64_t) 128];\n            \n            for (int64_t i_10441 = 0; i_10441 < (int64_t) 128; i_10441++) {\n                for (int64_t i_10445 = 0; i_10445 < dzlz7bUZLztZRz20Umz20U128z7dUzg_6643; i_10445++) {\n                    f16 defunc_0_f_res_9091;\n                    f16 redout_10447 = (f16) 0.0F;\n                    \n                    for (int64_t i_10448 = 0; i_10448 < (int64_t) 128; i_10448++) {\n                        f16 eta_p_9095;\n                        f16 eta_p_9096;\n                        f16 defunc_0_f_res_9097;\n                        ", "f16 defunc_0_op_res_9094;\n                        f16 redout_tmp_11039;\n                        \n                        eta_p_9095 = futrts_from_bits16(((__global uint16_t *) mem_10788)[gtid_9084 + i_10441 * (m_6642 * (int64_t) 128) + i_10448 * m_6642]);\n                        eta_p_9096 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10445 * (int64_t) 128 + i_10448]);\n                        defunc_0_f_res_9097 = eta_p_9095 * eta_p_9096;\n                        defunc_0_op_res_9094 = defunc_0_f_res_9097 + redout_10447;\n                        redout_tmp_11039 = defunc_0_op_res_9094;\n                        redout_10447 = redout_tmp_11039;\n                    }\n                    defunc_0_f_res_9091 = redout_10447;\n                    ((__global uint16_t *) color_10856)[phys_tid_9085 + i_10445 * num_threads_10974] = futrts_to_bits16(defunc_0_f_res_9091);\n                }\n                for (int64_t i_10451 = 0; i_10451 < (int64_t) 128; i_10451++) {\n                    f16 defunc_0_f_res_9100;\n                    f16 redout_10453 = (f16) 0.0F;\n                    \n                    for (int64_t i_10454 = 0; i_10454 < dzlz7bUZLztZRz20Umz20U128z7dUzg_6643; i_10454++) {\n                        f16 eta_p_9104;\n                        f16 eta_p_9105;\n                        f16 defunc_0_f_res_9106;\n                        f16 defunc_0_op_res_9103;\n                        f16 redout_tmp_11041;\n                        \n                        eta_p_9104 = futrts_from_bits16(((__global uint16_t *) color_10856)[phys_tid_9085 + i_10454 * num_threads_10974]);\n                        eta_p_9105 = futrts_from_bits16(((__global uint16_t *) mem_10798)[i_10454 + i_10451 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643]);\n                        defunc_0_f_res_9106 = eta_p_9104 * eta_p_9105;\n                        defunc_0_op_res_9103 = defunc_0_f_res_9106 + redout_10453;\n                        redout_tmp_11041 = defunc_0_op_res_9103;\n                        redout_10453 = ",
                                    "redout_tmp_11041;\n                    }\n                    defunc_0_f_res_9100 = redout_10453;\n                    mem_10822[i_10451] = defunc_0_f_res_9100;\n                }\n                for (int64_t i_0 = 0; i_0 < (int64_t) 128; i_0++) {\n                    mem_10808[i_10441 * (int64_t) 128 + i_0] = mem_10822[i_0];\n                }\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 128; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 128; i_1++) {\n                    ((__global uint16_t *) mem_10840)[gtid_9084 + (i_0 * (m_6642 * (int64_t) 128) + i_1 * m_6642)] = futrts_to_bits16(mem_10808[i_0 * (int64_t) 128 + i_1]);\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_9080\n}\nFUTHARK_KERNEL_SIZED(run128zisegmap_9531_dim1, 1, 1)\nvoid run128zisegmap_9531(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t num_tblocks_9509, int64_t num_threads_10996, int32_t virt_num_tblocks_11111, __global unsigned char *K_mem_10473, __global unsigned char *mem_10715, __global unsigned char *mem_10725, __global unsigned char *mem_10756, __global unsigned char *color_10859)\n{\n    #define segmap_tblock_sizze_9508 (run128zisegmap_9531zisegmap_tblock_sizze_9508)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11113;\n    int32_t tblock_sizze_11116;\n    int32_t wave_sizze_11115;\n    int32_t block_id_11114;\n    int32_t global_tid_11112;\n    int64_t phys_tid_9531;\n    int32_t phys_tblock_id_11117;\n    int32_t iterations_11118;\n    \n    local_tid_11113 = get_local_id(0);\n    tblock_sizze_11116 = get_local_size(0);\n    wave_sizze_11115 = LOCKSTEP_WIDTH;\n    block_id_11114 = get_tblock_id(0);\n    global_tid_11112 = block_id_11114 * tblock_sizze_11116 + local_tid_11113;\n    phys_tid_9531 = sext_i32_i64(global_tid_11112);\n    phys_tblock_id_11117 = get_tblock_id(0);\n    iteratio", "ns_11118 = sdiv_up32(virt_num_tblocks_11111 - phys_tblock_id_11117, sext_i64_i32(num_tblocks_9509));\n    for (int32_t i_11119 = 0; i_11119 < iterations_11118; i_11119++) {\n        int32_t virt_tblock_id_11120;\n        int64_t global_tid_11121;\n        int64_t slice_11122;\n        int64_t slice_11123;\n        int64_t gtid_9529;\n        int64_t remnant_11124;\n        int64_t gtid_9530;\n        int64_t remnant_11125;\n        \n        virt_tblock_id_11120 = phys_tblock_id_11117 + i_11119 * sext_i64_i32(num_tblocks_9509);\n        global_tid_11121 = sext_i32_i64(virt_tblock_id_11120) * segmap_tblock_sizze_9508 + sext_i32_i64(local_tid_11113);\n        slice_11122 = (int64_t) 128;\n        slice_11123 = m_6642 * slice_11122;\n        gtid_9529 = squot64(global_tid_11121, slice_11122);\n        remnant_11124 = global_tid_11121 - gtid_9529 * slice_11122;\n        gtid_9530 = remnant_11124;\n        remnant_11125 = remnant_11124 - gtid_9530;\n        if (slt64(gtid_9529, m_6642) && slt64(gtid_9530, (int64_t) 128)) {\n            f16 mem_10739[(int64_t) 128];\n            \n            for (int64_t i_10457 = 0; i_10457 < dzlz7bUZLztZRz20Umz20U128z7dUzg_6643; i_10457++) {\n                f16 defunc_0_f_res_9535;\n                f16 redout_10459 = (f16) 0.0F;\n                \n                for (int64_t i_10460 = 0; i_10460 < (int64_t) 128; i_10460++) {\n                    f16 eta_p_9539;\n                    f16 eta_p_9540;\n                    f16 defunc_0_f_res_9541;\n                    f16 defunc_0_op_res_9538;\n                    f16 redout_tmp_11127;\n                    \n                    eta_p_9539 = futrts_from_bits16(((__global uint16_t *) mem_10715)[gtid_9529 * (int64_t) 128 + gtid_9530 + i_10460 * ((int64_t) 128 * m_6642)]);\n                    eta_p_9540 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10457 * (int64_t) 128 + i_10460]);\n                    defunc_0_f_res_9541 = eta_p_9539 * eta_p_9540;\n                    defunc_0_op_res_9538 = defunc_0_f_res_9541 +", " redout_10459;\n                    redout_tmp_11127 = defunc_0_op_res_9538;\n                    redout_10459 = redout_tmp_11127;\n                }\n                defunc_0_f_res_9535 = redout_10459;\n                ((__global uint16_t *) color_10859)[phys_tid_9531 + i_10457 * num_threads_10996] = futrts_to_bits16(defunc_0_f_res_9535);\n            }\n            for (int64_t i_10463 = 0; i_10463 < (int64_t) 128; i_10463++) {\n                f16 defunc_0_f_res_9544;\n                f16 redout_10465 = (f16) 0.0F;\n                \n                for (int64_t i_10466 = 0; i_10466 < dzlz7bUZLztZRz20Umz20U128z7dUzg_6643; i_10466++) {\n                    f16 eta_p_9548;\n                    f16 eta_p_9549;\n                    f16 defunc_0_f_res_9550;\n                    f16 defunc_0_op_res_9547;\n                    f16 redout_tmp_11129;\n                    \n                    eta_p_9548 = futrts_from_bits16(((__global uint16_t *) color_10859)[phys_tid_9531 + i_10466 * num_threads_10996]);\n                    eta_p_9549 = futrts_from_bits16(((__global uint16_t *) mem_10725)[i_10466 + i_10463 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643]);\n                    defunc_0_f_res_9550 = eta_p_9548 * eta_p_9549;\n                    defunc_0_op_res_9547 = defunc_0_f_res_9550 + redout_10465;\n                    redout_tmp_11129 = defunc_0_op_res_9547;\n                    redout_10465 = redout_tmp_11129;\n                }\n                defunc_0_f_res_9544 = redout_10465;\n                mem_10739[i_10463] = defunc_0_f_res_9544;\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 128; i_0++) {\n                ((__global uint16_t *) mem_10756)[gtid_9529 * (int64_t) 128 + gtid_9530 + i_0 * ((int64_t) 128 * m_6642)] = futrts_to_bits16(mem_10739[i_0]);\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_9508\n}\nFUTHARK_KERNEL_SIZED(run128zisegmap_intrablock_10078_dim1, 1, 1)\nvoid run128z",
                                    "isegmap_intrablock_10078(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t one_intra_par_min_9514, int64_t full_tiles_10106, int64_t kk_10264, __global unsigned char *V_mem_10474, __global unsigned char *ext_mem_10579, __global unsigned char *mem_10690)\n{\n    #define Ty_10060 (run128zisegmap_intrablock_10078ziTy_10060)\n    #define Ry_10061 (run128zisegmap_intrablock_10078ziRy_10061)\n    #define Tk_10062 (run128zisegmap_intrablock_10078ziTk_10062)\n    #define tk_div_tx_10063 (run128zisegmap_intrablock_10078zitk_div_tx_10063)\n    #define TxRx_10065 (run128zisegmap_intrablock_10078ziTxRx_10065)\n    #define a_loc_szz_10068 (run128zisegmap_intrablock_10078zia_loc_szz_10068)\n    #define gridDim_x_10071 (run128zisegmap_intrablock_10078zigridDim_x_10071)\n    #define loop_nonempty_10430 (run128zisegmap_intrablock_10078ziloop_nonempty_10430)\n    #define bytes_10626 (run128zisegmap_intrablock_10078zibytes_10626)\n    \n    volatile __local unsigned char *color_10865_backing_1 = &shared_mem[0];\n    const int64_t color_10865_backing_1_offset = 0 + (bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10864_backing_0 = &shared_mem[color_10865_backing_1_offset];\n    const int64_t color_10864_backing_0_offset = color_10865_backing_1_offset + (bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11354;\n    int32_t tblock_sizze_11357;\n    int32_t wave_sizze_11356;\n    int32_t block_id_11355;\n    int32_t global_tid_11353;\n    int64_t gid_flat_10078;\n    int64_t slice_11360;\n    int64_t slice_11361;\n    int64_t ltid_pre_11358;\n    int64_t remnant_11362;\n    int64_t ltid_pre_11359;\n    int64_t remnant_11363;\n    int64_t slice_11364;\n    int64_t slice_11365;\n    int64_t slice_11366;\n    int64_t gtid_9638;\n    int64_t remnant_11367;\n    int64_t gid_y_10076;\n    i", "nt64_t remnant_11368;\n    int64_t gid_x_10077;\n    int64_t remnant_11369;\n    __local unsigned char *color_10864;\n    __local unsigned char *color_10865;\n    int64_t iii_10079;\n    int64_t jjj_10080;\n    f16 mem_10625[Ry_10061 * Ry_10061];\n    int64_t ltid_flat_10094;\n    int64_t ltid_y_10093;\n    int64_t ltid_x_10092;\n    f16 mem_10606[Ry_10061 * Ry_10061];\n    f16 ext_mem_10664[Ry_10061 * Ry_10061];\n    f16 mem_param_10630[Ry_10061 * Ry_10061];\n    int64_t ltid_flat_10286;\n    int64_t ltid_flat_10331;\n    f16 mem_10686[Ry_10061 * Ry_10061];\n    int64_t ltid_flat_10392;\n    int64_t ltid_y_10391;\n    int64_t ltid_x_10390;\n    int64_t binop_x_10407;\n    int64_t binop_y_10412;\n    int64_t slice_11393;\n    int64_t slice_11394;\n    int64_t slice_11395;\n    int64_t reg_tile_i_11390;\n    int64_t remnant_11396;\n    int64_t reg_tile_i_11391;\n    int64_t remnant_11397;\n    int64_t reg_tile_i_11392;\n    int64_t remnant_11398;\n    int64_t tile_dim_start_11399;\n    int64_t tile_dim_start_11400;\n    int64_t tile_dim_start_11401;\n    \n    local_tid_11354 = get_local_id(0);\n    tblock_sizze_11357 = get_local_size(0);\n    wave_sizze_11356 = LOCKSTEP_WIDTH;\n    block_id_11355 = get_tblock_id(0);\n    global_tid_11353 = block_id_11355 * tblock_sizze_11357 + local_tid_11354;\n    gid_flat_10078 = sext_i32_i64(block_id_11355);\n    slice_11360 = Ty_10060;\n    slice_11361 = Ty_10060 * slice_11360;\n    ltid_pre_11358 = squot64(sext_i32_i64(local_tid_11354), slice_11360);\n    remnant_11362 = sext_i32_i64(local_tid_11354) - ltid_pre_11358 * slice_11360;\n    ltid_pre_11359 = remnant_11362;\n    remnant_11363 = remnant_11362 - ltid_pre_11359;\n    slice_11364 = gridDim_x_10071;\n    slice_11365 = gridDim_x_10071 * slice_11364;\n    slice_11366 = m_6642 * slice_11365;\n    gtid_9638 = squot64(sext_i32_i64(block_id_11355), slice_11365);\n    remnant_11367 = sext_i32_i64(block_id_11355) - gtid_9638 * slice_11365;\n    gid_y_10076 = squot64(remnant_11367, slice_11364);\n    remnant_11368 = remnant_11367 - ", "gid_y_10076 * slice_11364;\n    gid_x_10077 = remnant_11368;\n    remnant_11369 = remnant_11368 - gid_x_10077;\n    color_10864 = (__local unsigned char *) color_10864_backing_0;\n    color_10865 = (__local unsigned char *) color_10865_backing_1;\n    iii_10079 = TxRx_10065 * gid_y_10076;\n    jjj_10080 = TxRx_10065 * gid_x_10077;\n    ltid_flat_10094 = sext_i32_i64(local_tid_11354);\n    ltid_y_10093 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10092 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    for (int64_t i_10097 = 0; i_10097 < Ry_10061; i_10097++) {\n        for (int64_t i_10100 = 0; i_10100 < Ry_10061; i_10100++) {\n            mem_10606[i_10097 * Ry_10061 + i_10100] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_10061; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_10061; i_1++) {\n            mem_10625[i_0 * Ry_10061 + i_1] = mem_10606[i_0 * Ry_10061 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < Ry_10061 * Ry_10061; i_2++)\n        mem_param_10630[i_2] = mem_10625[i_2];\n    for (int64_t i_10107 = 0; i_10107 < full_tiles_10106; i_10107++) {\n        int64_t kk_10111;\n        int64_t ltid_flat_10131;\n        int64_t ltid_flat_10172;\n        f16 mem_10657[Ry_10061 * Ry_10061];\n        int64_t ltid_flat_10229;\n        int64_t ltid_y_10228;\n        int64_t ltid_x_10227;\n        int64_t binop_x_10242;\n        int64_t binop_y_10247;\n        f16 mem_param_tmp_11372[Ry_10061 * Ry_10061];\n        \n        kk_10111 = Tk_10062 * i_10107;\n        ltid_flat_10131 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11376 = 0; nest_i_11376 < Ry_10061; nest_i_11376++) {\n            for (int64_t nest_i_11377 = 0; nest_i_11377 < tk_div_tx_10063; nest_i_11377++) {\n                int64_t ltid_seq_10134;\n                int64_t ltid_seq_10135;\n                int64_t ltid_y_10132;\n                int64_t ltid_x_10133;\n                int64_t binop_y_10136;\n               ",
                                    " int64_t k_10137;\n                int64_t binop_y_10138;\n                int64_t i_10139;\n                int64_t gtid_10140;\n                int64_t defunc_0_map_res_seqdim_idx_10141;\n                bool cond_10142;\n                f16 defunc_0_map_res_elem_10143;\n                bool cond_10147;\n                int64_t defunc_0_map_res_loc_ind_10148;\n                \n                ltid_seq_10134 = nest_i_11376;\n                ltid_seq_10135 = nest_i_11377;\n                ltid_y_10132 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10133 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10136 = Ty_10060 * ltid_seq_10135;\n                k_10137 = ltid_x_10133 + binop_y_10136;\n                binop_y_10138 = Ty_10060 * ltid_seq_10134;\n                i_10139 = ltid_y_10132 + binop_y_10138;\n                gtid_10140 = iii_10079 + i_10139;\n                defunc_0_map_res_seqdim_idx_10141 = kk_10111 + k_10137;\n                cond_10142 = slt64(gtid_10140, (int64_t) 128);\n                if (cond_10142) {\n                    f16 A_elem_10145 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_9638 * one_intra_par_min_9514 + gtid_10140 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + defunc_0_map_res_seqdim_idx_10141]);\n                    \n                    defunc_0_map_res_elem_10143 = A_elem_10145;\n                } else {\n                    defunc_0_map_res_elem_10143 = (f16) 0.0F;\n                }\n                cond_10147 = slt64(k_10137, Tk_10062);\n                if (cond_10147) {\n                    int64_t binop_y_10149;\n                    int64_t x_10150;\n                    \n                    binop_y_10149 = Tk_10062 * i_10139;\n                    x_10150 = k_10137 + binop_y_10149;\n                    defunc_0_map_res_loc_ind_10148 = x_10150;\n                } else {\n                    defunc_0_map_res_loc_ind_10148 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, defunc_0_m", "ap_res_loc_ind_10148) && slt64(defunc_0_map_res_loc_ind_10148, a_loc_szz_10068)) {\n                    ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10148] = futrts_to_bits16(defunc_0_map_res_elem_10143);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10172 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11378 = 0; nest_i_11378 < Ry_10061; nest_i_11378++) {\n            for (int64_t nest_i_11379 = 0; nest_i_11379 < tk_div_tx_10063; nest_i_11379++) {\n                int64_t ltid_seq_10175;\n                int64_t ltid_seq_10176;\n                int64_t ltid_y_10173;\n                int64_t ltid_x_10174;\n                int64_t binop_y_10177;\n                int64_t k_10178;\n                int64_t binop_y_10179;\n                int64_t i_10180;\n                int64_t gtid_10181;\n                int64_t as_transformed_row_seqdim_idx_10182;\n                bool cond_10183;\n                f16 as_transformed_row_elem_10184;\n                bool cond_10188;\n                int64_t as_transformed_row_loc_ind_10189;\n                \n                ltid_seq_10175 = nest_i_11378;\n                ltid_seq_10176 = nest_i_11379;\n                ltid_y_10173 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10174 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10177 = Ty_10060 * ltid_seq_10176;\n                k_10178 = ltid_y_10173 + binop_y_10177;\n                binop_y_10179 = Ty_10060 * ltid_seq_10175;\n                i_10180 = ltid_x_10174 + binop_y_10179;\n                gtid_10181 = jjj_10080 + i_10180;\n                as_transformed_row_seqdim_idx_10182 = kk_10111 + k_10178;\n                cond_10183 = slt64(gtid_10181, (int64_t) 128);\n                if (cond_10183) {\n                    f16 A_elem_10186 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10182 * (int64_t) 128 + gtid_10181]);\n                    \n  ", "                  as_transformed_row_elem_10184 = A_elem_10186;\n                } else {\n                    as_transformed_row_elem_10184 = (f16) 0.0F;\n                }\n                cond_10188 = slt64(k_10178, Tk_10062);\n                if (cond_10188) {\n                    int64_t binop_y_10190;\n                    int64_t x_10191;\n                    \n                    binop_y_10190 = TxRx_10065 * k_10178;\n                    x_10191 = i_10180 + binop_y_10190;\n                    as_transformed_row_loc_ind_10189 = x_10191;\n                } else {\n                    as_transformed_row_loc_ind_10189 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_10189) && slt64(as_transformed_row_loc_ind_10189, a_loc_szz_10068)) {\n                    ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10189] = futrts_to_bits16(as_transformed_row_elem_10184);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10229 = sext_i32_i64(local_tid_11354);\n        ltid_y_10228 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n        ltid_x_10227 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n        binop_x_10242 = Ry_10061 * ltid_y_10228;\n        binop_y_10247 = Ry_10061 * ltid_x_10227;\n        for (int64_t i_10232 = 0; i_10232 < Tk_10062; i_10232++) {\n            int64_t binop_y_10249 = TxRx_10065 * i_10232;\n            \n            for (int64_t i_10236 = 0; i_10236 < Ry_10061; i_10236++) {\n                int64_t binop_x_10243;\n                int64_t binop_y_10244;\n                int64_t defunc_0_map_res_loc_ind_64_10245;\n                f16 defunc_0_map_res_loc_elem_10246;\n                \n                binop_x_10243 = i_10236 + binop_x_10242;\n                binop_y_10244 = Tk_10062 * binop_x_10243;\n                defunc_0_map_res_loc_ind_64_10245 = i_10232 + binop_y_10244;\n                if (loop_nonempty_10430) {\n                    f16 x_10431 = futrts_from_bits16((",
                                    "(__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10245]);\n                    \n                    defunc_0_map_res_loc_elem_10246 = x_10431;\n                } else {\n                    defunc_0_map_res_loc_elem_10246 = (f16) 0.0F;\n                }\n                for (int64_t i_10239 = 0; i_10239 < Ry_10061; i_10239++) {\n                    int64_t binop_x_10248;\n                    int64_t as_transformed_row_loc_ind_64_10250;\n                    f16 as_transformed_row_loc_elem_10251;\n                    f16 c_10252;\n                    f16 defunc_0_f_res_10255;\n                    f16 defunc_0_op_res_10258;\n                    \n                    binop_x_10248 = i_10239 + binop_y_10247;\n                    as_transformed_row_loc_ind_64_10250 = binop_x_10248 + binop_y_10249;\n                    as_transformed_row_loc_elem_10251 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10250]);\n                    c_10252 = mem_param_10630[i_10236 * Ry_10061 + i_10239];\n                    defunc_0_f_res_10255 = defunc_0_map_res_loc_elem_10246 * as_transformed_row_loc_elem_10251;\n                    defunc_0_op_res_10258 = c_10252 + defunc_0_f_res_10255;\n                    mem_param_10630[i_10236 * Ry_10061 + i_10239] = defunc_0_op_res_10258;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < Ry_10061; i_0++) {\n            for (int64_t i_1 = 0; i_1 < Ry_10061; i_1++) {\n                mem_10657[i_0 * Ry_10061 + i_1] = mem_param_10630[i_0 * Ry_10061 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < Ry_10061 * Ry_10061; i_3++)\n            mem_param_tmp_11372[i_3] = mem_10657[i_3];\n        for (int32_t i_4 = 0; i_4 < Ry_10061 * Ry_10061; i_4++)\n            mem_param_10630[i_4] = mem_param_tmp_11372[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < Ry_10061 * Ry_10061; i_5++)\n        ext_mem_10664[i_5] = mem_param_10630[i_5];\n    ltid_flat_10286 = se", "xt_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11383 = 0; nest_i_11383 < Ry_10061; nest_i_11383++) {\n        for (int64_t nest_i_11384 = 0; nest_i_11384 < tk_div_tx_10063; nest_i_11384++) {\n            int64_t ltid_seq_10289;\n            int64_t ltid_seq_10290;\n            int64_t ltid_y_10287;\n            int64_t ltid_x_10288;\n            int64_t binop_y_10291;\n            int64_t k_10292;\n            int64_t binop_y_10293;\n            int64_t i_10294;\n            int64_t gtid_10295;\n            int64_t defunc_0_map_res_seqdim_idx_10296;\n            bool binop_x_10297;\n            bool binop_y_10298;\n            bool cond_10299;\n            f16 defunc_0_map_res_elem_10300;\n            bool cond_10304;\n            int64_t defunc_0_map_res_loc_ind_10305;\n            \n            ltid_seq_10289 = nest_i_11383;\n            ltid_seq_10290 = nest_i_11384;\n            ltid_y_10287 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10288 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10291 = Ty_10060 * ltid_seq_10290;\n            k_10292 = ltid_x_10288 + binop_y_10291;\n            binop_y_10293 = Ty_10060 * ltid_seq_10289;\n            i_10294 = ltid_y_10287 + binop_y_10293;\n            gtid_10295 = iii_10079 + i_10294;\n            defunc_0_map_res_seqdim_idx_10296 = kk_10264 + k_10292;\n            binop_x_10297 = slt64(gtid_10295, (int64_t) 128);\n            binop_y_10298 = slt64(defunc_0_map_res_seqdim_idx_10296, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n            cond_10299 = binop_x_10297 && binop_y_10298;\n            if (cond_10299) {\n                f16 A_elem_10302 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_9638 * one_intra_par_min_9514 + gtid_10295 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + defunc_0_map_res_seqdim_idx_10296]);\n                \n                defunc_0_map_res_elem_10300 = A_elem_10302;\n            } else {\n                defunc_0_map_res_elem_10300 = (f16) 0.0F;\n            }\n            cond", "_10304 = slt64(k_10292, Tk_10062);\n            if (cond_10304) {\n                int64_t binop_y_10306;\n                int64_t x_10307;\n                \n                binop_y_10306 = Tk_10062 * i_10294;\n                x_10307 = k_10292 + binop_y_10306;\n                defunc_0_map_res_loc_ind_10305 = x_10307;\n            } else {\n                defunc_0_map_res_loc_ind_10305 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10305) && slt64(defunc_0_map_res_loc_ind_10305, a_loc_szz_10068)) {\n                ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10305] = futrts_to_bits16(defunc_0_map_res_elem_10300);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10331 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11385 = 0; nest_i_11385 < Ry_10061; nest_i_11385++) {\n        for (int64_t nest_i_11386 = 0; nest_i_11386 < tk_div_tx_10063; nest_i_11386++) {\n            int64_t ltid_seq_10334;\n            int64_t ltid_seq_10335;\n            int64_t ltid_y_10332;\n            int64_t ltid_x_10333;\n            int64_t binop_y_10336;\n            int64_t k_10337;\n            int64_t binop_y_10338;\n            int64_t i_10339;\n            int64_t gtid_10340;\n            int64_t as_transformed_row_seqdim_idx_10341;\n            bool binop_x_10342;\n            bool binop_y_10343;\n            bool cond_10344;\n            f16 as_transformed_row_elem_10345;\n            bool cond_10349;\n            int64_t as_transformed_row_loc_ind_10350;\n            \n            ltid_seq_10334 = nest_i_11385;\n            ltid_seq_10335 = nest_i_11386;\n            ltid_y_10332 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10333 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10336 = Ty_10060 * ltid_seq_10335;\n            k_10337 = ltid_y_10332 + binop_y_10336;\n            binop_y_10338 = Ty_10060 * ltid_seq_10334;\n            i_10339 = ltid_x_10333 + binop_y_10338;\n        ",
                                    "    gtid_10340 = jjj_10080 + i_10339;\n            as_transformed_row_seqdim_idx_10341 = kk_10264 + k_10337;\n            binop_x_10342 = slt64(gtid_10340, (int64_t) 128);\n            binop_y_10343 = slt64(as_transformed_row_seqdim_idx_10341, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n            cond_10344 = binop_x_10342 && binop_y_10343;\n            if (cond_10344) {\n                f16 A_elem_10347 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10341 * (int64_t) 128 + gtid_10340]);\n                \n                as_transformed_row_elem_10345 = A_elem_10347;\n            } else {\n                as_transformed_row_elem_10345 = (f16) 0.0F;\n            }\n            cond_10349 = slt64(k_10337, Tk_10062);\n            if (cond_10349) {\n                int64_t binop_y_10351;\n                int64_t x_10352;\n                \n                binop_y_10351 = TxRx_10065 * k_10337;\n                x_10352 = i_10339 + binop_y_10351;\n                as_transformed_row_loc_ind_10350 = x_10352;\n            } else {\n                as_transformed_row_loc_ind_10350 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_10350) && slt64(as_transformed_row_loc_ind_10350, a_loc_szz_10068)) {\n                ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10350] = futrts_to_bits16(as_transformed_row_elem_10345);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10392 = sext_i32_i64(local_tid_11354);\n    ltid_y_10391 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10390 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    binop_x_10407 = Ry_10061 * ltid_y_10391;\n    binop_y_10412 = Ry_10061 * ltid_x_10390;\n    for (int64_t i_10395 = 0; i_10395 < Tk_10062; i_10395++) {\n        int64_t cmpop_x_10397;\n        bool cond_10398;\n        int64_t binop_y_10414;\n        \n        cmpop_x_10397 = kk_10264 + i_10395;\n        cond_10398 = slt64(cmpop_x_10397, dzlz7bUZLztZRz20Umz2", "0U128z7dUzg_6643);\n        binop_y_10414 = TxRx_10065 * i_10395;\n        if (cond_10398) {\n            for (int64_t i_10401 = 0; i_10401 < Ry_10061; i_10401++) {\n                int64_t binop_x_10408;\n                int64_t binop_y_10409;\n                int64_t defunc_0_map_res_loc_ind_64_10410;\n                f16 defunc_0_map_res_loc_elem_10411;\n                \n                binop_x_10408 = i_10401 + binop_x_10407;\n                binop_y_10409 = Tk_10062 * binop_x_10408;\n                defunc_0_map_res_loc_ind_64_10410 = i_10395 + binop_y_10409;\n                if (loop_nonempty_10430) {\n                    f16 x_10428 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10410]);\n                    \n                    defunc_0_map_res_loc_elem_10411 = x_10428;\n                } else {\n                    defunc_0_map_res_loc_elem_10411 = (f16) 0.0F;\n                }\n                for (int64_t i_10404 = 0; i_10404 < Ry_10061; i_10404++) {\n                    int64_t binop_x_10413;\n                    int64_t as_transformed_row_loc_ind_64_10415;\n                    f16 as_transformed_row_loc_elem_10416;\n                    f16 c_10417;\n                    f16 defunc_0_f_res_10420;\n                    f16 defunc_0_op_res_10423;\n                    \n                    binop_x_10413 = i_10404 + binop_y_10412;\n                    as_transformed_row_loc_ind_64_10415 = binop_x_10413 + binop_y_10414;\n                    as_transformed_row_loc_elem_10416 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10415]);\n                    c_10417 = ext_mem_10664[i_10401 * Ry_10061 + i_10404];\n                    defunc_0_f_res_10420 = defunc_0_map_res_loc_elem_10411 * as_transformed_row_loc_elem_10416;\n                    defunc_0_op_res_10423 = c_10417 + defunc_0_f_res_10420;\n                    ext_mem_10664[i_10401 * Ry_10061 + i_10404] = defunc_0_op_res_10423;\n                }\n            }\n      ", "  }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_10061; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_10061; i_1++) {\n            mem_10686[i_0 * Ry_10061 + i_1] = ext_mem_10664[i_0 * Ry_10061 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11393 = Ty_10060;\n    slice_11394 = Ty_10060 * slice_11393;\n    slice_11395 = slice_11394;\n    reg_tile_i_11390 = squot64(sext_i32_i64(local_tid_11354), slice_11394);\n    remnant_11396 = sext_i32_i64(local_tid_11354) - reg_tile_i_11390 * slice_11394;\n    reg_tile_i_11391 = squot64(remnant_11396, slice_11393);\n    remnant_11397 = remnant_11396 - reg_tile_i_11391 * slice_11393;\n    reg_tile_i_11392 = remnant_11397;\n    remnant_11398 = remnant_11397 - reg_tile_i_11392;\n    tile_dim_start_11399 = gtid_9638 + reg_tile_i_11390;\n    tile_dim_start_11400 = Ry_10061 * (Ty_10060 * gid_y_10076 + reg_tile_i_11391);\n    tile_dim_start_11401 = Ry_10061 * (Ty_10060 * gid_x_10077 + reg_tile_i_11392);\n    for (int64_t nest_i_11402 = 0; nest_i_11402 < (int64_t) 1; nest_i_11402++) {\n        for (int64_t nest_i_11403 = 0; nest_i_11403 < Ry_10061; nest_i_11403++) {\n            for (int64_t nest_i_11404 = 0; nest_i_11404 < Ry_10061; nest_i_11404++) {\n                if ((slt64(tile_dim_start_11399 + nest_i_11402, m_6642) && slt64(tile_dim_start_11400 + nest_i_11403, (int64_t) 128)) && slt64(tile_dim_start_11401 + nest_i_11404, (int64_t) 128)) {\n                    f16 tmp_11405 = mem_10686[nest_i_11403 * Ry_10061 + nest_i_11404];\n                    \n                    ((__global uint16_t *) mem_10690)[(tile_dim_start_11399 + nest_i_11402) * (int64_t) 16384 + (tile_dim_start_11400 + nest_i_11403) * (int64_t) 128 + (tile_dim_start_11401 + nest_i_11404)] = futrts_to_bits16(tmp_11405);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n    #undef Ty_10060\n    #undef Ry_10061\n    #undef Tk_10062\n    #undef tk_div_tx_10063\n    #undef TxRx_10065\n    #undef a_loc_szz_10068\n    #undef gridDim_x_10071\n    #undef loop",
                                    "_nonempty_10430\n    #undef bytes_10626\n}\nFUTHARK_KERNEL\nvoid run128zisegmap_intrablock_9114(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t one_intra_par_min_9036, int64_t bytes_10763, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10769)\n{\n    volatile __local unsigned char *red_arr_mem_11089_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11089_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11070_backing_2 = &shared_mem[red_arr_mem_11089_backing_3_offset];\n    const int64_t red_arr_mem_11070_backing_2_offset = red_arr_mem_11089_backing_3_offset + ((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10858_backing_1 = &shared_mem[red_arr_mem_11070_backing_2_offset];\n    const int64_t color_10858_backing_1_offset = red_arr_mem_11070_backing_2_offset + (bytes_10763 + srem64((int64_t) 8 - srem64(bytes_10763, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10857_backing_0 = &shared_mem[color_10858_backing_1_offset];\n    const int64_t color_10857_backing_0_offset = color_10858_backing_1_offset + (int64_t) 32768;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11046;\n    int32_t tblock_sizze_11049;\n    int32_t wave_sizze_11048;\n    int32_t block_id_11047;\n    int32_t global_tid_11045;\n    int64_t phys_tblock_id_9114;\n    int64_t slice_11053;\n    int64_t slice_11054;\n    int64_t slice_11055;\n    int64_t ltid_pre_11050;\n    int64_t ", "remnant_11056;\n    int64_t ltid_pre_11051;\n    int64_t remnant_11057;\n    int64_t ltid_pre_11052;\n    int64_t remnant_11058;\n    int64_t slice_11062;\n    int64_t slice_11063;\n    int64_t slice_11064;\n    int64_t ltid_pre_11059;\n    int64_t remnant_11065;\n    int64_t ltid_pre_11060;\n    int64_t remnant_11066;\n    int64_t ltid_pre_11061;\n    int64_t remnant_11067;\n    int64_t slice_11068;\n    int64_t gtid_9113;\n    int64_t remnant_11069;\n    __local unsigned char *color_10857;\n    __local unsigned char *color_10858;\n    int64_t phys_tid_9121;\n    __local unsigned char *red_arr_mem_11070;\n    int64_t gtid_9118;\n    int64_t gtid_9119;\n    int64_t gtid_9120;\n    int64_t dims_flat_11072;\n    f16 eta_p_9122;\n    f16 eta_p_9123;\n    f16 eta_p_11074;\n    f16 eta_p_11075;\n    bool ltid_in_bounds_11077;\n    int32_t skip_threads_11078;\n    bool no_carry_in_11084;\n    int64_t phys_tid_9134;\n    __local unsigned char *red_arr_mem_11089;\n    int64_t gtid_9131;\n    int64_t gtid_9132;\n    int64_t gtid_9133;\n    int64_t dims_flat_11091;\n    f16 eta_p_9135;\n    f16 eta_p_9136;\n    f16 eta_p_11093;\n    f16 eta_p_11094;\n    bool ltid_in_bounds_11096;\n    int32_t skip_threads_11097;\n    bool no_carry_in_11103;\n    int32_t num_chunks_11108;\n    \n    local_tid_11046 = get_local_id(0);\n    tblock_sizze_11049 = get_local_size(0);\n    wave_sizze_11048 = LOCKSTEP_WIDTH;\n    block_id_11047 = get_tblock_id(0);\n    global_tid_11045 = block_id_11047 * tblock_sizze_11049 + local_tid_11046;\n    phys_tblock_id_9114 = sext_i32_i64(block_id_11047);\n    slice_11053 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;\n    slice_11054 = (int64_t) 128 * slice_11053;\n    slice_11055 = (int64_t) 128 * slice_11054;\n    ltid_pre_11050 = squot64(sext_i32_i64(local_tid_11046), slice_11054);\n    remnant_11056 = sext_i32_i64(local_tid_11046) - ltid_pre_11050 * slice_11054;\n    ltid_pre_11051 = squot64(remnant_11056, slice_11053);\n    remnant_11057 = remnant_11056 - ltid_pre_11051 * slice_11053;\n    ltid_pre_11052 = remnant_110", "57;\n    remnant_11058 = remnant_11057 - ltid_pre_11052;\n    slice_11062 = (int64_t) 128;\n    slice_11063 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * slice_11062;\n    slice_11064 = (int64_t) 128 * slice_11063;\n    ltid_pre_11059 = squot64(sext_i32_i64(local_tid_11046), slice_11063);\n    remnant_11065 = sext_i32_i64(local_tid_11046) - ltid_pre_11059 * slice_11063;\n    ltid_pre_11060 = squot64(remnant_11065, slice_11062);\n    remnant_11066 = remnant_11065 - ltid_pre_11060 * slice_11062;\n    ltid_pre_11061 = remnant_11066;\n    remnant_11067 = remnant_11066 - ltid_pre_11061;\n    slice_11068 = m_6642;\n    gtid_9113 = sext_i32_i64(block_id_11047);\n    remnant_11069 = sext_i32_i64(block_id_11047) - gtid_9113;\n    color_10857 = (__local unsigned char *) color_10857_backing_0;\n    color_10858 = (__local unsigned char *) color_10858_backing_1;\n    phys_tid_9121 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11070 = (__local unsigned char *) red_arr_mem_11070_backing_2;\n    gtid_9118 = sext_i32_i64(sext_i64_i32(ltid_pre_11059));\n    gtid_9119 = sext_i32_i64(sext_i64_i32(ltid_pre_11060));\n    gtid_9120 = sext_i32_i64(sext_i64_i32(ltid_pre_11061));\n    if ((slt64(gtid_9118, (int64_t) 128) && slt64(gtid_9119, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) && slt64(gtid_9120, (int64_t) 128)) {\n        f16 eta_p_9127;\n        f16 eta_p_9128;\n        f16 defunc_0_f_res_9129;\n        \n        eta_p_9127 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_9113 * (int64_t) 16384 + gtid_9118 * (int64_t) 128 + gtid_9120]);\n        eta_p_9128 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9119 * (int64_t) 128 + gtid_9120]);\n        defunc_0_f_res_9129 = eta_p_9127 * eta_p_9128;\n        ((__local uint16_t *) red_arr_mem_11070)[gtid_9118 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) + gtid_9119 * (int64_t) 128 + gtid_9120] = futrts_to_bits16(defunc_0_f_res_9129);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11072 = (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128",
                                    "z7dUzg_6643 * (int64_t) 128;\n    ltid_in_bounds_11077 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11077) {\n            eta_p_9123 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_9122 = eta_p_9123;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11078 = 1;\n        while (slt32(skip_threads_11078, 32)) {\n            bool thread_active_11079 = sle32(skip_threads_11078, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11077;\n            \n            if (thread_active_11079) {\n                // read operands\n                {\n                    eta_p_9122 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11078)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11080 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 128), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11078));\n                \n                if (thread_active_11079 && inactive_11080) {\n                    eta_p_9122 = eta_p_9123;\n                }\n                if (thread_active_11079) {\n                    if (!inactive_11080) {\n                        f16 defunc_0_op_res_9124 = eta_p_9122 + eta_p_9123;\n                        \n                        eta_p_9122 = defunc_0_op_res_9124;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11079) {\n                // write result\n                {\n             ", "       ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_9122);\n                    eta_p_9123 = eta_p_9122;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11078 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11077) {\n            ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_9122);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11081;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n                eta_p_11075 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11074 = eta_p_11075;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11081 = 1;\n            while (slt32(skip_threads_11081, 32)) {\n                bool thread_active_11082 = sle32(skip_threads_11081, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077);\n                \n                if (thread_active_11082) {\n                    // read operands\n                    {\n                        eta_p_11074 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11081)]);\n                    }\n             ", "   }\n                // perform operation\n                {\n                    bool inactive_11083 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), (int64_t) 128), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11081) * 32 + 32 - 1));\n                    \n                    if (thread_active_11082 && inactive_11083) {\n                        eta_p_11074 = eta_p_11075;\n                    }\n                    if (thread_active_11082) {\n                        if (!inactive_11083) {\n                            f16 defunc_0_op_res_11076 = eta_p_11074 + eta_p_11075;\n                            \n                            eta_p_11074 = defunc_0_op_res_11076;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11082) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11074);\n                        eta_p_11075 = eta_p_11074;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11081 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11084 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11077;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11084) {\n                eta_p_9123 = eta_p_9122;\n                eta_p_9122 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11085 = slt64(sre",
                                    "m64(sext_i32_i64(local_tid_11046), (int64_t) 128), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11084) {\n                if (inactive_11085) {\n                    eta_p_9122 = eta_p_9123;\n                }\n            }\n            if (!no_carry_in_11084) {\n                if (!inactive_11085) {\n                    f16 defunc_0_op_res_9124 = eta_p_9122 + eta_p_9123;\n                    \n                    eta_p_9122 = defunc_0_op_res_9124;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11084) {\n                ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_9122);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n            ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_9123);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11086 = sdiv_up32(128 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i64_i32(one_intra_par_min_9036));\n        \n        for (int32_t chunk_i_11087 = 0; chunk_i_11087 < num_chunks_11086; chunk_i_11087++) {\n            int32_t i_11088 = chunk_i_11087 * sext_i64_i32(one_intra_par_min_9036) + local_tid_11046;\n            \n            if (slt32(i_11088, 128 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643))) {\n                ((__local uint16_t *) color_10858)[sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643))) * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) * sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643))] = futrts_to_bits16(futrts_from_", "bits16(((__local uint16_t *) red_arr_mem_11070)[(int64_t) 127 + sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643))) * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) * sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) * (int64_t) 128]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_9134 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11089 = (__local unsigned char *) red_arr_mem_11089_backing_3;\n    gtid_9131 = sext_i32_i64(sext_i64_i32(ltid_pre_11050));\n    gtid_9132 = sext_i32_i64(sext_i64_i32(ltid_pre_11051));\n    gtid_9133 = sext_i32_i64(sext_i64_i32(ltid_pre_11052));\n    if ((slt64(gtid_9131, (int64_t) 128) && slt64(gtid_9132, (int64_t) 128)) && slt64(gtid_9133, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) {\n        f16 eta_p_9140;\n        f16 eta_p_9141;\n        f16 defunc_0_f_res_9142;\n        \n        eta_p_9140 = futrts_from_bits16(((__local uint16_t *) color_10858)[gtid_9131 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9133]);\n        eta_p_9141 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_9133 * (int64_t) 128 + gtid_9132]);\n        defunc_0_f_res_9142 = eta_p_9140 * eta_p_9141;\n        ((__local uint16_t *) red_arr_mem_11089)[gtid_9131 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + gtid_9132 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9133] = futrts_to_bits16(defunc_0_f_res_9142);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11091 = (int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;\n    ltid_in_bounds_11096 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11096) {\n            eta_p_9136 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n            ", "if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_9135 = eta_p_9136;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11097 = 1;\n        while (slt32(skip_threads_11097, 32)) {\n            bool thread_active_11098 = sle32(skip_threads_11097, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11096;\n            \n            if (thread_active_11098) {\n                // read operands\n                {\n                    eta_p_9135 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11097)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11099 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11097));\n                \n                if (thread_active_11098 && inactive_11099) {\n                    eta_p_9135 = eta_p_9136;\n                }\n                if (thread_active_11098) {\n                    if (!inactive_11099) {\n                        f16 defunc_0_op_res_9137 = eta_p_9135 + eta_p_9136;\n                        \n                        eta_p_9135 = defunc_0_op_res_9137;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11098) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_9135);\n                    eta_p_9136 = eta_p_9135;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11097 *= 2;\n ",
                                    "       }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11096) {\n            ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_9135);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11100;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n                eta_p_11094 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11093 = eta_p_11094;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11100 = 1;\n            while (slt32(skip_threads_11100, 32)) {\n                bool thread_active_11101 = sle32(skip_threads_11100, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096);\n                \n                if (thread_active_11101) {\n                    // read operands\n                    {\n                        eta_p_11093 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11100)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11102 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11100) * 32 + 32 - 1));\n                    \n                    if ", "(thread_active_11101 && inactive_11102) {\n                        eta_p_11093 = eta_p_11094;\n                    }\n                    if (thread_active_11101) {\n                        if (!inactive_11102) {\n                            f16 defunc_0_op_res_11095 = eta_p_11093 + eta_p_11094;\n                            \n                            eta_p_11093 = defunc_0_op_res_11095;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11101) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11093);\n                        eta_p_11094 = eta_p_11093;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11100 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11103 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11096;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11103) {\n                eta_p_9136 = eta_p_9135;\n                eta_p_9135 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11104 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11103) {\n                if (inactive_11104) {\n                    eta_p_9135 = eta_p_9136;\n                }\n            }\n         ", "   if (!no_carry_in_11103) {\n                if (!inactive_11104) {\n                    f16 defunc_0_op_res_9137 = eta_p_9135 + eta_p_9136;\n                    \n                    eta_p_9135 = defunc_0_op_res_9137;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11103) {\n                ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_9135);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n            ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_9136);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11105 = sdiv_up32(16384, sext_i64_i32(one_intra_par_min_9036));\n        \n        for (int32_t chunk_i_11106 = 0; chunk_i_11106 < num_chunks_11105; chunk_i_11106++) {\n            int32_t i_11107 = chunk_i_11106 * sext_i64_i32(one_intra_par_min_9036) + local_tid_11046;\n            \n            if (slt32(i_11107, 16384)) {\n                ((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11107, 128)) * (int64_t) 128 + sext_i32_i64(i_11107 - squot32(i_11107, 128) * 128)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 - (int64_t) 1 + sext_i32_i64(squot32(i_11107, 128)) * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + sext_i32_i64(i_11107 - squot32(i_11107, 128) * 128) * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11108 = sdiv_up32(16384, sext_i64_i32(one_intra_par_min_9036));\n    for (int32_t chunk_i_11109 = 0; chunk_i_11109 < num_chunks_11108; chunk_i_11109++) {\n        int32_t i",
                                    "_11110 = chunk_i_11109 * sext_i64_i32(one_intra_par_min_9036) + local_tid_11046;\n        \n        if (slt32(i_11110, 16384)) {\n            ((__global uint16_t *) mem_10769)[gtid_9113 * (int64_t) 16384 + sext_i32_i64(squot32(i_11110, 128)) * (int64_t) 128 + sext_i32_i64(i_11110 - squot32(i_11110, 128) * 128)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11110, 128)) * (int64_t) 128 + sext_i32_i64(i_11110 - squot32(i_11110, 128) * 128)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL\nvoid run128zisegmap_intrablock_9555(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t one_intra_par_min_9514, int64_t bytes_10693, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10699)\n{\n    volatile __local unsigned char *red_arr_mem_11173_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11173_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11154_backing_2 = &shared_mem[red_arr_mem_11173_backing_3_offset];\n    const int64_t red_arr_mem_11154_backing_2_offset = red_arr_mem_11173_backing_3_offset + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10861_backing_1 = &shared_mem[red_arr_mem_11154_backing_2_offset];\n    const int64_t color_10861_backing_1_offset = red_arr_mem_11154_backing_2_offset + (bytes_10693 + srem64((int64_t) 8 - srem64(bytes_10693, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10860_backing_0", " = &shared_mem[color_10861_backing_1_offset];\n    const int64_t color_10860_backing_0_offset = color_10861_backing_1_offset + (int64_t) 256;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11134;\n    int32_t tblock_sizze_11137;\n    int32_t wave_sizze_11136;\n    int32_t block_id_11135;\n    int32_t global_tid_11133;\n    int64_t phys_tblock_id_9555;\n    int64_t slice_11140;\n    int64_t slice_11141;\n    int64_t ltid_pre_11138;\n    int64_t remnant_11142;\n    int64_t ltid_pre_11139;\n    int64_t remnant_11143;\n    int64_t slice_11146;\n    int64_t slice_11147;\n    int64_t ltid_pre_11144;\n    int64_t remnant_11148;\n    int64_t ltid_pre_11145;\n    int64_t remnant_11149;\n    int64_t slice_11150;\n    int64_t slice_11151;\n    int64_t gtid_9553;\n    int64_t remnant_11152;\n    int64_t gtid_9554;\n    int64_t remnant_11153;\n    __local unsigned char *color_10860;\n    __local unsigned char *color_10861;\n    int64_t phys_tid_9561;\n    __local unsigned char *red_arr_mem_11154;\n    int64_t gtid_9559;\n    int64_t gtid_9560;\n    int64_t dims_flat_11156;\n    f16 eta_p_9562;\n    f16 eta_p_9563;\n    f16 eta_p_11158;\n    f16 eta_p_11159;\n    bool ltid_in_bounds_11161;\n    int32_t skip_threads_11162;\n    bool no_carry_in_11168;\n    int64_t phys_tid_9572;\n    __local unsigned char *red_arr_mem_11173;\n    int64_t gtid_9570;\n    int64_t gtid_9571;\n    int64_t dims_flat_11175;\n    f16 eta_p_9573;\n    f16 eta_p_9574;\n    f16 eta_p_11177;\n    f16 eta_p_11178;\n    bool ltid_in_bounds_11180;\n    int32_t skip_threads_11181;\n    bool no_carry_in_11187;\n    int32_t num_chunks_11192;\n    \n    local_tid_11134 = get_local_id(0);\n    tblock_sizze_11137 = get_local_size(0);\n    wave_sizze_11136 = LOCKSTEP_WIDTH;\n    block_id_11135 = get_tblock_id(0);\n    global_tid_11133 = block_id_11135 * tblock_sizze_11137 + local_tid_11134;\n    phys_tblock_id_9555 = sext_i32_i64(block_id_11135);\n    slice_11140 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;\n    slice_11141 = (int64_t) 128 * slice_111", "40;\n    ltid_pre_11138 = squot64(sext_i32_i64(local_tid_11134), slice_11140);\n    remnant_11142 = sext_i32_i64(local_tid_11134) - ltid_pre_11138 * slice_11140;\n    ltid_pre_11139 = remnant_11142;\n    remnant_11143 = remnant_11142 - ltid_pre_11139;\n    slice_11146 = (int64_t) 128;\n    slice_11147 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * slice_11146;\n    ltid_pre_11144 = squot64(sext_i32_i64(local_tid_11134), slice_11146);\n    remnant_11148 = sext_i32_i64(local_tid_11134) - ltid_pre_11144 * slice_11146;\n    ltid_pre_11145 = remnant_11148;\n    remnant_11149 = remnant_11148 - ltid_pre_11145;\n    slice_11150 = (int64_t) 128;\n    slice_11151 = m_6642 * slice_11150;\n    gtid_9553 = squot64(sext_i32_i64(block_id_11135), slice_11150);\n    remnant_11152 = sext_i32_i64(block_id_11135) - gtid_9553 * slice_11150;\n    gtid_9554 = remnant_11152;\n    remnant_11153 = remnant_11152 - gtid_9554;\n    color_10860 = (__local unsigned char *) color_10860_backing_0;\n    color_10861 = (__local unsigned char *) color_10861_backing_1;\n    phys_tid_9561 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_11154 = (__local unsigned char *) red_arr_mem_11154_backing_2;\n    gtid_9559 = sext_i32_i64(sext_i64_i32(ltid_pre_11144));\n    gtid_9560 = sext_i32_i64(sext_i64_i32(ltid_pre_11145));\n    if (slt64(gtid_9559, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) && slt64(gtid_9560, (int64_t) 128)) {\n        f16 eta_p_9566;\n        f16 eta_p_9567;\n        f16 defunc_0_f_res_9568;\n        \n        eta_p_9566 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_9553 * (int64_t) 16384 + gtid_9554 * (int64_t) 128 + gtid_9560]);\n        eta_p_9567 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9559 * (int64_t) 128 + gtid_9560]);\n        defunc_0_f_res_9568 = eta_p_9566 * eta_p_9567;\n        ((__local uint16_t *) red_arr_mem_11154)[gtid_9559 * (int64_t) 128 + gtid_9560] = futrts_to_bits16(defunc_0_f_res_9568);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11156 = dzlz7bUZLztZRz20Umz20U128",
                                    "z7dUzg_6643 * (int64_t) 128;\n    ltid_in_bounds_11161 = slt64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11161) {\n            eta_p_9563 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_9562 = eta_p_9563;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11162 = 1;\n        while (slt32(skip_threads_11162, 32)) {\n            bool thread_active_11163 = sle32(skip_threads_11162, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11161;\n            \n            if (thread_active_11163) {\n                // read operands\n                {\n                    eta_p_9562 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11162)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11164 = slt64(srem64(sext_i32_i64(local_tid_11134), (int64_t) 128), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11162));\n                \n                if (thread_active_11163 && inactive_11164) {\n                    eta_p_9562 = eta_p_9563;\n                }\n                if (thread_active_11163) {\n                    if (!inactive_11164) {\n                        f16 defunc_0_op_res_9564 = eta_p_9562 + eta_p_9563;\n                        \n                        eta_p_9562 = defunc_0_op_res_9564;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11163) {\n                // write result\n                {\n                    ((volatil", "e __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_9562);\n                    eta_p_9563 = eta_p_9562;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11162 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11161) {\n            ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_9562);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11165;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n                eta_p_11159 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11158 = eta_p_11159;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11165 = 1;\n            while (slt32(skip_threads_11165, 32)) {\n                bool thread_active_11166 = sle32(skip_threads_11165, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161);\n                \n                if (thread_active_11166) {\n                    // read operands\n                    {\n                        eta_p_11158 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11165)]);\n                    }\n                }\n           ", "     // perform operation\n                {\n                    bool inactive_11167 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), (int64_t) 128), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11165) * 32 + 32 - 1));\n                    \n                    if (thread_active_11166 && inactive_11167) {\n                        eta_p_11158 = eta_p_11159;\n                    }\n                    if (thread_active_11166) {\n                        if (!inactive_11167) {\n                            f16 defunc_0_op_res_11160 = eta_p_11158 + eta_p_11159;\n                            \n                            eta_p_11158 = defunc_0_op_res_11160;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11166) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11158);\n                        eta_p_11159 = eta_p_11158;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11165 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11168 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11161;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11168) {\n                eta_p_9563 = eta_p_9562;\n                eta_p_9562 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11169 = slt64(srem64(sext_i32_i64",
                                    "(local_tid_11134), (int64_t) 128), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11168) {\n                if (inactive_11169) {\n                    eta_p_9562 = eta_p_9563;\n                }\n            }\n            if (!no_carry_in_11168) {\n                if (!inactive_11169) {\n                    f16 defunc_0_op_res_9564 = eta_p_9562 + eta_p_9563;\n                    \n                    eta_p_9562 = defunc_0_op_res_9564;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11168) {\n                ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_9562);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n            ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_9563);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11170 = sdiv_up32(sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i64_i32(one_intra_par_min_9514));\n        \n        for (int32_t chunk_i_11171 = 0; chunk_i_11171 < num_chunks_11170; chunk_i_11171++) {\n            int32_t i_11172 = chunk_i_11171 * sext_i64_i32(one_intra_par_min_9514) + local_tid_11134;\n            \n            if (slt32(i_11172, sext_i64_i32(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643))) {\n                ((__local uint16_t *) color_10861)[sext_i32_i64(i_11172)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[(int64_t) 127 + sext_i32_i64(i_11172) * (int64_t) 128]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_9572 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_1", "1173 = (__local unsigned char *) red_arr_mem_11173_backing_3;\n    gtid_9570 = sext_i32_i64(sext_i64_i32(ltid_pre_11138));\n    gtid_9571 = sext_i32_i64(sext_i64_i32(ltid_pre_11139));\n    if (slt64(gtid_9570, (int64_t) 128) && slt64(gtid_9571, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) {\n        f16 eta_p_9577;\n        f16 eta_p_9578;\n        f16 defunc_0_f_res_9579;\n        \n        eta_p_9577 = futrts_from_bits16(((__local uint16_t *) color_10861)[gtid_9571]);\n        eta_p_9578 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_9571 * (int64_t) 128 + gtid_9570]);\n        defunc_0_f_res_9579 = eta_p_9577 * eta_p_9578;\n        ((__local uint16_t *) red_arr_mem_11173)[gtid_9570 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9571] = futrts_to_bits16(defunc_0_f_res_9579);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11175 = (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;\n    ltid_in_bounds_11180 = slt64(sext_i32_i64(local_tid_11134), (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11180) {\n            eta_p_9574 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_9573 = eta_p_9574;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11181 = 1;\n        while (slt32(skip_threads_11181, 32)) {\n            bool thread_active_11182 = sle32(skip_threads_11181, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11180;\n            \n            if (thread_active_11182) {\n                // read operands\n                {\n                    eta_p_9573 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11181)]);\n                }\n            }\n            // perform operation\n       ", "     {\n                bool inactive_11183 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11181));\n                \n                if (thread_active_11182 && inactive_11183) {\n                    eta_p_9573 = eta_p_9574;\n                }\n                if (thread_active_11182) {\n                    if (!inactive_11183) {\n                        f16 defunc_0_op_res_9575 = eta_p_9573 + eta_p_9574;\n                        \n                        eta_p_9573 = defunc_0_op_res_9575;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11182) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_9573);\n                    eta_p_9574 = eta_p_9573;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11181 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11180) {\n            ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_9573);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11184;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n                eta_p_11178 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_1",
                                    "1173)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11177 = eta_p_11178;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11184 = 1;\n            while (slt32(skip_threads_11184, 32)) {\n                bool thread_active_11185 = sle32(skip_threads_11184, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180);\n                \n                if (thread_active_11185) {\n                    // read operands\n                    {\n                        eta_p_11177 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11184)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11186 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11184) * 32 + 32 - 1));\n                    \n                    if (thread_active_11185 && inactive_11186) {\n                        eta_p_11177 = eta_p_11178;\n                    }\n                    if (thread_active_11185) {\n                        if (!inactive_11186) {\n                            f16 defunc_0_op_res_11179 = eta_p_11177 + eta_p_11178;\n                            \n                            eta_p_11177 = defunc_0_op_res_11179;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11185) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11173)[s", "ext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11177);\n                        eta_p_11178 = eta_p_11177;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11184 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11187 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11180;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11187) {\n                eta_p_9574 = eta_p_9573;\n                eta_p_9573 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11188 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11187) {\n                if (inactive_11188) {\n                    eta_p_9573 = eta_p_9574;\n                }\n            }\n            if (!no_carry_in_11187) {\n                if (!inactive_11188) {\n                    f16 defunc_0_op_res_9575 = eta_p_9573 + eta_p_9574;\n                    \n                    eta_p_9573 = defunc_0_op_res_9575;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11187) {\n                ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_9573);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n            ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_9574);\n  ", "      }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11189 = sdiv_up32(128, sext_i64_i32(one_intra_par_min_9514));\n        \n        for (int32_t chunk_i_11190 = 0; chunk_i_11190 < num_chunks_11189; chunk_i_11190++) {\n            int32_t i_11191 = chunk_i_11190 * sext_i64_i32(one_intra_par_min_9514) + local_tid_11134;\n            \n            if (slt32(i_11191, 128)) {\n                ((__local uint16_t *) color_10860)[sext_i32_i64(i_11191)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 - (int64_t) 1 + sext_i32_i64(i_11191) * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11192 = sdiv_up32(128, sext_i64_i32(one_intra_par_min_9514));\n    for (int32_t chunk_i_11193 = 0; chunk_i_11193 < num_chunks_11192; chunk_i_11193++) {\n        int32_t i_11194 = chunk_i_11193 * sext_i64_i32(one_intra_par_min_9514) + local_tid_11134;\n        \n        if (slt32(i_11194, 128)) {\n            ((__global uint16_t *) mem_10699)[gtid_9553 * (int64_t) 16384 + gtid_9554 * (int64_t) 128 + sext_i32_i64(i_11194)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10860)[sext_i32_i64(i_11194)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run128zisegmap_intrablock_9700_dim1, 1, 1)\nvoid run128zisegmap_intrablock_9700(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t gridDim_x_9693, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10575)\n{\n    #define Ty_9680 (run128zisegmap_intrablock_9700ziTy_9680)\n    #define Ry_9681 (run128zisegmap_intrablock_9700ziRy_9681)\n    #define Tk_9682 (run128zisegmap_intrablock_9700ziTk_9682)\n    #define tk_div_tx_9683 (run128",
                                    "zisegmap_intrablock_9700zitk_div_tx_9683)\n    #define TxRx_9685 (run128zisegmap_intrablock_9700ziTxRx_9685)\n    #define a_loc_szz_9688 (run128zisegmap_intrablock_9700zia_loc_szz_9688)\n    #define b_loc_szz_9692 (run128zisegmap_intrablock_9700zib_loc_szz_9692)\n    #define gridDim_y_9694 (run128zisegmap_intrablock_9700zigridDim_y_9694)\n    #define full_tiles_9728 (run128zisegmap_intrablock_9700zifull_tiles_9728)\n    #define binop_y_9874 (run128zisegmap_intrablock_9700zibinop_y_9874)\n    #define kk_9890 (run128zisegmap_intrablock_9700zikk_9890)\n    #define loop_nonempty_10436 (run128zisegmap_intrablock_9700ziloop_nonempty_10436)\n    #define bytes_10511 (run128zisegmap_intrablock_9700zibytes_10511)\n    #define bytes_10513 (run128zisegmap_intrablock_9700zibytes_10513)\n    \n    volatile __local unsigned char *color_10863_backing_1 = &shared_mem[0];\n    const int64_t color_10863_backing_1_offset = 0 + (bytes_10511 + srem64((int64_t) 8 - srem64(bytes_10511, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10862_backing_0 = &shared_mem[color_10863_backing_1_offset];\n    const int64_t color_10862_backing_0_offset = color_10863_backing_1_offset + (bytes_10513 + srem64((int64_t) 8 - srem64(bytes_10513, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11198;\n    int32_t tblock_sizze_11201;\n    int32_t wave_sizze_11200;\n    int32_t block_id_11199;\n    int32_t global_tid_11197;\n    int64_t gid_flat_9700;\n    int64_t slice_11204;\n    int64_t slice_11205;\n    int64_t ltid_pre_11202;\n    int64_t remnant_11206;\n    int64_t ltid_pre_11203;\n    int64_t remnant_11207;\n    int64_t slice_11208;\n    int64_t slice_11209;\n    int64_t slice_11210;\n    int64_t gtid_9591;\n    int64_t remnant_11211;\n    int64_t gid_y_9698;\n    int64_t remnant_11212;\n    int64_t gid_x_9699;\n    int64_t remnant_11213;\n    __local unsigned char *color_10862;\n    __local unsigned char *color_10863;\n    int64_t iii_9701;\n    int64_t jjj_97", "02;\n    f16 mem_10510[Ry_9681 * Ry_9681];\n    int64_t ltid_flat_9716;\n    int64_t ltid_y_9715;\n    int64_t ltid_x_9714;\n    f16 mem_10491[Ry_9681 * Ry_9681];\n    f16 ext_mem_10549[Ry_9681 * Ry_9681];\n    f16 mem_param_10515[Ry_9681 * Ry_9681];\n    int64_t ltid_flat_9912;\n    int64_t ltid_flat_9958;\n    f16 mem_10571[Ry_9681 * Ry_9681];\n    int64_t ltid_flat_10021;\n    int64_t ltid_y_10020;\n    int64_t ltid_x_10019;\n    int64_t binop_x_10036;\n    int64_t binop_x_10041;\n    int64_t slice_11237;\n    int64_t slice_11238;\n    int64_t slice_11239;\n    int64_t reg_tile_i_11234;\n    int64_t remnant_11240;\n    int64_t reg_tile_i_11235;\n    int64_t remnant_11241;\n    int64_t reg_tile_i_11236;\n    int64_t remnant_11242;\n    int64_t tile_dim_start_11243;\n    int64_t tile_dim_start_11244;\n    int64_t tile_dim_start_11245;\n    \n    local_tid_11198 = get_local_id(0);\n    tblock_sizze_11201 = get_local_size(0);\n    wave_sizze_11200 = LOCKSTEP_WIDTH;\n    block_id_11199 = get_tblock_id(0);\n    global_tid_11197 = block_id_11199 * tblock_sizze_11201 + local_tid_11198;\n    gid_flat_9700 = sext_i32_i64(block_id_11199);\n    slice_11204 = Ty_9680;\n    slice_11205 = Ty_9680 * slice_11204;\n    ltid_pre_11202 = squot64(sext_i32_i64(local_tid_11198), slice_11204);\n    remnant_11206 = sext_i32_i64(local_tid_11198) - ltid_pre_11202 * slice_11204;\n    ltid_pre_11203 = remnant_11206;\n    remnant_11207 = remnant_11206 - ltid_pre_11203;\n    slice_11208 = gridDim_x_9693;\n    slice_11209 = gridDim_y_9694 * slice_11208;\n    slice_11210 = m_6642 * slice_11209;\n    gtid_9591 = squot64(sext_i32_i64(block_id_11199), slice_11209);\n    remnant_11211 = sext_i32_i64(block_id_11199) - gtid_9591 * slice_11209;\n    gid_y_9698 = squot64(remnant_11211, slice_11208);\n    remnant_11212 = remnant_11211 - gid_y_9698 * slice_11208;\n    gid_x_9699 = remnant_11212;\n    remnant_11213 = remnant_11212 - gid_x_9699;\n    color_10862 = (__local unsigned char *) color_10862_backing_0;\n    color_10863 = (__local unsigned char *) ", "color_10863_backing_1;\n    iii_9701 = TxRx_9685 * gid_y_9698;\n    jjj_9702 = TxRx_9685 * gid_x_9699;\n    ltid_flat_9716 = sext_i32_i64(local_tid_11198);\n    ltid_y_9715 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_9714 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    for (int64_t i_9719 = 0; i_9719 < Ry_9681; i_9719++) {\n        for (int64_t i_9722 = 0; i_9722 < Ry_9681; i_9722++) {\n            mem_10491[i_9719 * Ry_9681 + i_9722] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_9681; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_9681; i_1++) {\n            mem_10510[i_0 * Ry_9681 + i_1] = mem_10491[i_0 * Ry_9681 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < Ry_9681 * Ry_9681; i_2++)\n        mem_param_10515[i_2] = mem_10510[i_2];\n    for (int64_t i_9729 = 0; i_9729 < full_tiles_9728; i_9729++) {\n        int64_t kk_9733;\n        int64_t ltid_flat_9753;\n        int64_t ltid_flat_9795;\n        f16 mem_10542[Ry_9681 * Ry_9681];\n        int64_t ltid_flat_9854;\n        int64_t ltid_y_9853;\n        int64_t ltid_x_9852;\n        int64_t binop_x_9867;\n        int64_t binop_x_9872;\n        f16 mem_param_tmp_11216[Ry_9681 * Ry_9681];\n        \n        kk_9733 = Tk_9682 * i_9729;\n        ltid_flat_9753 = sext_i32_i64(local_tid_11198);\n        for (int64_t nest_i_11220 = 0; nest_i_11220 < Ry_9681; nest_i_11220++) {\n            for (int64_t nest_i_11221 = 0; nest_i_11221 < tk_div_tx_9683; nest_i_11221++) {\n                int64_t ltid_seq_9756;\n                int64_t ltid_seq_9757;\n                int64_t ltid_y_9754;\n                int64_t ltid_x_9755;\n                int64_t binop_y_9758;\n                int64_t k_9759;\n                int64_t binop_y_9760;\n                int64_t i_9761;\n                int64_t gtid_9762;\n                int64_t as_transformed_row_seqdim_idx_9763;\n                bool cond_9764;\n                f16 as_transformed_row_elem_9765;\n         ",
                                    "       bool cond_9769;\n                int64_t as_transformed_row_loc_ind_9770;\n                \n                ltid_seq_9756 = nest_i_11220;\n                ltid_seq_9757 = nest_i_11221;\n                ltid_y_9754 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9755 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9758 = Ty_9680 * ltid_seq_9757;\n                k_9759 = ltid_x_9755 + binop_y_9758;\n                binop_y_9760 = Ty_9680 * ltid_seq_9756;\n                i_9761 = ltid_y_9754 + binop_y_9760;\n                gtid_9762 = iii_9701 + i_9761;\n                as_transformed_row_seqdim_idx_9763 = kk_9733 + k_9759;\n                cond_9764 = slt64(gtid_9762, (int64_t) 128);\n                if (cond_9764) {\n                    f16 A_elem_9767 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_9591 * (int64_t) 16384 + gtid_9762 * (int64_t) 128 + as_transformed_row_seqdim_idx_9763]);\n                    \n                    as_transformed_row_elem_9765 = A_elem_9767;\n                } else {\n                    as_transformed_row_elem_9765 = (f16) 0.0F;\n                }\n                cond_9769 = slt64(k_9759, Tk_9682);\n                if (cond_9769) {\n                    int64_t binop_y_9771;\n                    int64_t x_9772;\n                    \n                    binop_y_9771 = Tk_9682 * i_9761;\n                    x_9772 = k_9759 + binop_y_9771;\n                    as_transformed_row_loc_ind_9770 = x_9772;\n                } else {\n                    as_transformed_row_loc_ind_9770 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9770) && slt64(as_transformed_row_loc_ind_9770, a_loc_szz_9688)) {\n                    ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9770] = futrts_to_bits16(as_transformed_row_elem_9765);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9795 = sext_i32_i64(lo", "cal_tid_11198);\n        for (int64_t nest_i_11222 = 0; nest_i_11222 < Ry_9681; nest_i_11222++) {\n            for (int64_t nest_i_11223 = 0; nest_i_11223 < tk_div_tx_9683; nest_i_11223++) {\n                int64_t ltid_seq_9798;\n                int64_t ltid_seq_9799;\n                int64_t ltid_y_9796;\n                int64_t ltid_x_9797;\n                int64_t binop_y_9800;\n                int64_t k_9801;\n                int64_t binop_y_9802;\n                int64_t i_9803;\n                int64_t gtid_9804;\n                int64_t as_transformed_row_seqdim_idx_9805;\n                bool cond_9806;\n                f16 as_transformed_row_elem_9807;\n                bool cond_9811;\n                int64_t as_transformed_row_loc_ind_9812;\n                \n                ltid_seq_9798 = nest_i_11222;\n                ltid_seq_9799 = nest_i_11223;\n                ltid_y_9796 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9797 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9800 = Ty_9680 * ltid_seq_9799;\n                k_9801 = ltid_x_9797 + binop_y_9800;\n                binop_y_9802 = Ty_9680 * ltid_seq_9798;\n                i_9803 = ltid_y_9796 + binop_y_9802;\n                gtid_9804 = jjj_9702 + i_9803;\n                as_transformed_row_seqdim_idx_9805 = kk_9733 + k_9801;\n                cond_9806 = slt64(gtid_9804, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n                if (cond_9806) {\n                    f16 A_elem_9809 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9804 * (int64_t) 128 + as_transformed_row_seqdim_idx_9805]);\n                    \n                    as_transformed_row_elem_9807 = A_elem_9809;\n                } else {\n                    as_transformed_row_elem_9807 = (f16) 0.0F;\n                }\n                cond_9811 = slt64(k_9801, Tk_9682);\n                if (cond_9811) {\n                    int64_t binop_y_9813;\n                    int64_t binop_y_9814;\n                    int6", "4_t x_9815;\n                    \n                    binop_y_9813 = (int64_t) 1 + Tk_9682;\n                    binop_y_9814 = i_9803 * binop_y_9813;\n                    x_9815 = k_9801 + binop_y_9814;\n                    as_transformed_row_loc_ind_9812 = x_9815;\n                } else {\n                    as_transformed_row_loc_ind_9812 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9812) && slt64(as_transformed_row_loc_ind_9812, b_loc_szz_9692)) {\n                    ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9812] = futrts_to_bits16(as_transformed_row_elem_9807);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9854 = sext_i32_i64(local_tid_11198);\n        ltid_y_9853 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n        ltid_x_9852 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n        binop_x_9867 = Ry_9681 * ltid_y_9853;\n        binop_x_9872 = Ry_9681 * ltid_x_9852;\n        for (int64_t i_9857 = 0; i_9857 < Tk_9682; i_9857++) {\n            for (int64_t i_9861 = 0; i_9861 < Ry_9681; i_9861++) {\n                int64_t binop_x_9868;\n                int64_t binop_y_9869;\n                int64_t as_transformed_row_loc_ind_64_9870;\n                f16 as_transformed_row_loc_elem_9871;\n                \n                binop_x_9868 = i_9861 + binop_x_9867;\n                binop_y_9869 = Tk_9682 * binop_x_9868;\n                as_transformed_row_loc_ind_64_9870 = i_9857 + binop_y_9869;\n                if (loop_nonempty_10436) {\n                    f16 x_10437 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_9870]);\n                    \n                    as_transformed_row_loc_elem_9871 = x_10437;\n                } else {\n                    as_transformed_row_loc_elem_9871 = (f16) 0.0F;\n                }\n                for (int64_t i_9864 = 0; i_9864 < Ry_9681; i_9864++) {\n                    int64_t binop_x_98",
                                    "73;\n                    int64_t binop_y_9875;\n                    int64_t as_transformed_row_loc_ind_64_9876;\n                    f16 as_transformed_row_loc_elem_9877;\n                    f16 c_9878;\n                    f16 defunc_0_f_res_9881;\n                    f16 defunc_0_op_res_9884;\n                    \n                    binop_x_9873 = i_9864 + binop_x_9872;\n                    binop_y_9875 = binop_x_9873 * binop_y_9874;\n                    as_transformed_row_loc_ind_64_9876 = i_9857 + binop_y_9875;\n                    as_transformed_row_loc_elem_9877 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_9876]);\n                    c_9878 = mem_param_10515[i_9861 * Ry_9681 + i_9864];\n                    defunc_0_f_res_9881 = as_transformed_row_loc_elem_9871 * as_transformed_row_loc_elem_9877;\n                    defunc_0_op_res_9884 = c_9878 + defunc_0_f_res_9881;\n                    mem_param_10515[i_9861 * Ry_9681 + i_9864] = defunc_0_op_res_9884;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < Ry_9681; i_0++) {\n            for (int64_t i_1 = 0; i_1 < Ry_9681; i_1++) {\n                mem_10542[i_0 * Ry_9681 + i_1] = mem_param_10515[i_0 * Ry_9681 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < Ry_9681 * Ry_9681; i_3++)\n            mem_param_tmp_11216[i_3] = mem_10542[i_3];\n        for (int32_t i_4 = 0; i_4 < Ry_9681 * Ry_9681; i_4++)\n            mem_param_10515[i_4] = mem_param_tmp_11216[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < Ry_9681 * Ry_9681; i_5++)\n        ext_mem_10549[i_5] = mem_param_10515[i_5];\n    ltid_flat_9912 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11227 = 0; nest_i_11227 < Ry_9681; nest_i_11227++) {\n        for (int64_t nest_i_11228 = 0; nest_i_11228 < tk_div_tx_9683; nest_i_11228++) {\n            int64_t ltid_seq_9915;\n            int64_t ltid_seq_9916;\n            int64_t ltid_y_9913;\n            int64", "_t ltid_x_9914;\n            int64_t binop_y_9917;\n            int64_t k_9918;\n            int64_t binop_y_9919;\n            int64_t i_9920;\n            int64_t gtid_9921;\n            int64_t as_transformed_row_seqdim_idx_9922;\n            bool binop_x_9923;\n            bool binop_y_9924;\n            bool cond_9925;\n            f16 as_transformed_row_elem_9926;\n            bool cond_9930;\n            int64_t as_transformed_row_loc_ind_9931;\n            \n            ltid_seq_9915 = nest_i_11227;\n            ltid_seq_9916 = nest_i_11228;\n            ltid_y_9913 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9914 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9917 = Ty_9680 * ltid_seq_9916;\n            k_9918 = ltid_x_9914 + binop_y_9917;\n            binop_y_9919 = Ty_9680 * ltid_seq_9915;\n            i_9920 = ltid_y_9913 + binop_y_9919;\n            gtid_9921 = iii_9701 + i_9920;\n            as_transformed_row_seqdim_idx_9922 = kk_9890 + k_9918;\n            binop_x_9923 = slt64(gtid_9921, (int64_t) 128);\n            binop_y_9924 = slt64(as_transformed_row_seqdim_idx_9922, (int64_t) 128);\n            cond_9925 = binop_x_9923 && binop_y_9924;\n            if (cond_9925) {\n                f16 A_elem_9928 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_9591 * (int64_t) 16384 + gtid_9921 * (int64_t) 128 + as_transformed_row_seqdim_idx_9922]);\n                \n                as_transformed_row_elem_9926 = A_elem_9928;\n            } else {\n                as_transformed_row_elem_9926 = (f16) 0.0F;\n            }\n            cond_9930 = slt64(k_9918, Tk_9682);\n            if (cond_9930) {\n                int64_t binop_y_9932;\n                int64_t x_9933;\n                \n                binop_y_9932 = Tk_9682 * i_9920;\n                x_9933 = k_9918 + binop_y_9932;\n                as_transformed_row_loc_ind_9931 = x_9933;\n            } else {\n                as_transformed_row_loc_ind_9931 = (int64_t) -1;\n            }\n     ", "       if (sle64((int64_t) 0, as_transformed_row_loc_ind_9931) && slt64(as_transformed_row_loc_ind_9931, a_loc_szz_9688)) {\n                ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9931] = futrts_to_bits16(as_transformed_row_elem_9926);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_9958 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11229 = 0; nest_i_11229 < Ry_9681; nest_i_11229++) {\n        for (int64_t nest_i_11230 = 0; nest_i_11230 < tk_div_tx_9683; nest_i_11230++) {\n            int64_t ltid_seq_9961;\n            int64_t ltid_seq_9962;\n            int64_t ltid_y_9959;\n            int64_t ltid_x_9960;\n            int64_t binop_y_9963;\n            int64_t k_9964;\n            int64_t binop_y_9965;\n            int64_t i_9966;\n            int64_t gtid_9967;\n            int64_t as_transformed_row_seqdim_idx_9968;\n            bool binop_x_9969;\n            bool binop_y_9970;\n            bool cond_9971;\n            f16 as_transformed_row_elem_9972;\n            bool cond_9976;\n            int64_t as_transformed_row_loc_ind_9977;\n            \n            ltid_seq_9961 = nest_i_11229;\n            ltid_seq_9962 = nest_i_11230;\n            ltid_y_9959 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9960 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9963 = Ty_9680 * ltid_seq_9962;\n            k_9964 = ltid_x_9960 + binop_y_9963;\n            binop_y_9965 = Ty_9680 * ltid_seq_9961;\n            i_9966 = ltid_y_9959 + binop_y_9965;\n            gtid_9967 = jjj_9702 + i_9966;\n            as_transformed_row_seqdim_idx_9968 = kk_9890 + k_9964;\n            binop_x_9969 = slt64(gtid_9967, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n            binop_y_9970 = slt64(as_transformed_row_seqdim_idx_9968, (int64_t) 128);\n            cond_9971 = binop_x_9969 && binop_y_9970;\n            if (cond_9971) {\n                f16 A_elem_9974 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_996",
                                    "7 * (int64_t) 128 + as_transformed_row_seqdim_idx_9968]);\n                \n                as_transformed_row_elem_9972 = A_elem_9974;\n            } else {\n                as_transformed_row_elem_9972 = (f16) 0.0F;\n            }\n            cond_9976 = slt64(k_9964, Tk_9682);\n            if (cond_9976) {\n                int64_t binop_y_9978;\n                int64_t binop_y_9979;\n                int64_t x_9980;\n                \n                binop_y_9978 = (int64_t) 1 + Tk_9682;\n                binop_y_9979 = i_9966 * binop_y_9978;\n                x_9980 = k_9964 + binop_y_9979;\n                as_transformed_row_loc_ind_9977 = x_9980;\n            } else {\n                as_transformed_row_loc_ind_9977 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_9977) && slt64(as_transformed_row_loc_ind_9977, b_loc_szz_9692)) {\n                ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9977] = futrts_to_bits16(as_transformed_row_elem_9972);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10021 = sext_i32_i64(local_tid_11198);\n    ltid_y_10020 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_10019 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    binop_x_10036 = Ry_9681 * ltid_y_10020;\n    binop_x_10041 = Ry_9681 * ltid_x_10019;\n    for (int64_t i_10024 = 0; i_10024 < Tk_9682; i_10024++) {\n        int64_t cmpop_x_10026;\n        bool cond_10027;\n        \n        cmpop_x_10026 = kk_9890 + i_10024;\n        cond_10027 = slt64(cmpop_x_10026, (int64_t) 128);\n        if (cond_10027) {\n            for (int64_t i_10030 = 0; i_10030 < Ry_9681; i_10030++) {\n                int64_t binop_x_10037;\n                int64_t binop_y_10038;\n                int64_t as_transformed_row_loc_ind_64_10039;\n                f16 as_transformed_row_loc_elem_10040;\n                \n                binop_x_10037 = i_10030 + binop_x_10036;\n                binop_y_10038 = Tk_9682 * binop_x_10037;\n             ", "   as_transformed_row_loc_ind_64_10039 = i_10024 + binop_y_10038;\n                if (loop_nonempty_10436) {\n                    f16 x_10434 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_10039]);\n                    \n                    as_transformed_row_loc_elem_10040 = x_10434;\n                } else {\n                    as_transformed_row_loc_elem_10040 = (f16) 0.0F;\n                }\n                for (int64_t i_10033 = 0; i_10033 < Ry_9681; i_10033++) {\n                    int64_t binop_x_10042;\n                    int64_t binop_y_10044;\n                    int64_t as_transformed_row_loc_ind_64_10045;\n                    f16 as_transformed_row_loc_elem_10046;\n                    f16 c_10047;\n                    f16 defunc_0_f_res_10050;\n                    f16 defunc_0_op_res_10053;\n                    \n                    binop_x_10042 = i_10033 + binop_x_10041;\n                    binop_y_10044 = binop_y_9874 * binop_x_10042;\n                    as_transformed_row_loc_ind_64_10045 = i_10024 + binop_y_10044;\n                    as_transformed_row_loc_elem_10046 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_10045]);\n                    c_10047 = ext_mem_10549[i_10030 * Ry_9681 + i_10033];\n                    defunc_0_f_res_10050 = as_transformed_row_loc_elem_10040 * as_transformed_row_loc_elem_10046;\n                    defunc_0_op_res_10053 = c_10047 + defunc_0_f_res_10050;\n                    ext_mem_10549[i_10030 * Ry_9681 + i_10033] = defunc_0_op_res_10053;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_9681; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_9681; i_1++) {\n            mem_10571[i_0 * Ry_9681 + i_1] = ext_mem_10549[i_0 * Ry_9681 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11237 = Ty_9680;\n    slice_11238 = Ty_9680 * slice_11237;\n    slice_11239 = slice_11238;\n    reg_tile_i_11234 = squot64(sext_i32_i64", "(local_tid_11198), slice_11238);\n    remnant_11240 = sext_i32_i64(local_tid_11198) - reg_tile_i_11234 * slice_11238;\n    reg_tile_i_11235 = squot64(remnant_11240, slice_11237);\n    remnant_11241 = remnant_11240 - reg_tile_i_11235 * slice_11237;\n    reg_tile_i_11236 = remnant_11241;\n    remnant_11242 = remnant_11241 - reg_tile_i_11236;\n    tile_dim_start_11243 = gtid_9591 + reg_tile_i_11234;\n    tile_dim_start_11244 = Ry_9681 * (Ty_9680 * gid_y_9698 + reg_tile_i_11235);\n    tile_dim_start_11245 = Ry_9681 * (Ty_9680 * gid_x_9699 + reg_tile_i_11236);\n    for (int64_t nest_i_11246 = 0; nest_i_11246 < (int64_t) 1; nest_i_11246++) {\n        for (int64_t nest_i_11247 = 0; nest_i_11247 < Ry_9681; nest_i_11247++) {\n            for (int64_t nest_i_11248 = 0; nest_i_11248 < Ry_9681; nest_i_11248++) {\n                if ((slt64(tile_dim_start_11243 + nest_i_11246, m_6642) && slt64(tile_dim_start_11244 + nest_i_11247, (int64_t) 128)) && slt64(tile_dim_start_11245 + nest_i_11248, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) {\n                    f16 tmp_11249 = mem_10571[nest_i_11247 * Ry_9681 + nest_i_11248];\n                    \n                    ((__global uint16_t *) mem_10575)[(tile_dim_start_11243 + nest_i_11246) * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + (tile_dim_start_11244 + nest_i_11247) * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + (tile_dim_start_11245 + nest_i_11248)] = futrts_to_bits16(tmp_11249);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n    #undef Ty_9680\n    #undef Ry_9681\n    #undef Tk_9682\n    #undef tk_div_tx_9683\n    #undef TxRx_9685\n    #undef a_loc_szz_9688\n    #undef b_loc_szz_9692\n    #undef gridDim_y_9694\n    #undef full_tiles_9728\n    #undef binop_y_9874\n    #undef kk_9890\n    #undef loop_nonempty_10436\n    #undef bytes_10511\n    #undef bytes_10513\n}\nFUTHARK_KERNEL_SIZED(run128zisegred_large_9616_dim1, 1, 1)\nvoid run128zisegred_large_9616(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz2",
                                    "0U128z7dUzg_6643, int64_t num_tblocks_9609, int64_t blocks_per_segment_11283, int64_t q_11284, int64_t num_virtblocks_11285, int64_t threads_per_segment_11286, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479, __global unsigned char *segred_tmp_mem_11287, __global unsigned char *counters_mem_11289)\n{\n    #define segred_tblock_sizze_9608 (run128zisegred_large_9616zisegred_tblock_sizze_9608)\n    #define chunk_sizze_11250 (run128zisegred_large_9616zichunk_sizze_11250)\n    \n    volatile __local unsigned char *sync_arr_mem_11318_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11318_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11316_backing_0 = &shared_mem[sync_arr_mem_11318_backing_1_offset];\n    const int64_t red_arr_f16_mem_11316_backing_0_offset = sync_arr_mem_11318_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_9608 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9608, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11312;\n    int32_t tblock_sizze_11315;\n    int32_t wave_sizze_11314;\n    int32_t block_id_11313;\n    int32_t global_tid_11311;\n    int64_t phys_tid_9616;\n    __local unsigned char *red_arr_f16_mem_11316;\n    __local unsigned char *sync_arr_mem_11318;\n    int32_t phys_tblock_id_11320;\n    int32_t iterations_11321;\n    \n    local_tid_11312 = get_local_id(0);\n    tblock_sizze_11315 = get_local_size(0);\n    wave_sizze_11314 = LOCKSTEP_WIDTH;\n    block_id_11313 = get_tblock_id(0);\n    global_tid_11311 = block_id_11313 * tblock_sizze_11315 + local_tid_11312;\n    phys_tid_9616 = sext_i32_i64(global_tid_11311);\n    red_arr_f16_mem_11316 = (__local unsigned char *) red_arr_f16_mem_11316_backing_0;\n    sync_arr_mem_11318 = (__local unsigned char *) sync_arr_mem_11318_backing_1;\n    phys_tblock_id_11320 = get_tblock_id(0);\n    iterations_11321 = sdiv_up32(sext_i64_i32(num_virtblocks_1", "1285) - phys_tblock_id_11320, sext_i64_i32(num_tblocks_9609));\n    for (int32_t i_11322 = 0; i_11322 < iterations_11321; i_11322++) {\n        int32_t virt_tblock_id_11323;\n        int64_t flat_segment_id_11324;\n        int64_t global_tid_11325;\n        int64_t slice_11326;\n        int64_t slice_11327;\n        int64_t slice_11328;\n        int64_t gtid_9612;\n        int64_t remnant_11329;\n        int64_t gtid_9613;\n        int64_t remnant_11330;\n        int64_t gtid_9614;\n        int64_t remnant_11331;\n        int64_t gtid_9615;\n        f16 eta_p_block_res_acc_11332;\n        f16 eta_p_9617;\n        f16 eta_p_9618;\n        int64_t tblock_id_in_segment_11336;\n        int64_t block_base_offset_11337;\n        int32_t offset_11340;\n        int32_t skip_waves_11341;\n        f16 eta_p_11333;\n        f16 eta_p_11334;\n        \n        virt_tblock_id_11323 = phys_tblock_id_11320 + i_11322 * sext_i64_i32(num_tblocks_9609);\n        flat_segment_id_11324 = squot64(sext_i32_i64(virt_tblock_id_11323), blocks_per_segment_11283);\n        global_tid_11325 = srem64(sext_i32_i64(virt_tblock_id_11323) * segred_tblock_sizze_9608 + sext_i32_i64(local_tid_11312), threads_per_segment_11286);\n        slice_11326 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;\n        slice_11327 = (int64_t) 128 * slice_11326;\n        slice_11328 = m_6642 * slice_11327;\n        gtid_9612 = squot64(flat_segment_id_11324, slice_11327);\n        remnant_11329 = flat_segment_id_11324 - gtid_9612 * slice_11327;\n        gtid_9613 = squot64(remnant_11329, slice_11326);\n        remnant_11330 = remnant_11329 - gtid_9613 * slice_11326;\n        gtid_9614 = remnant_11330;\n        remnant_11331 = remnant_11330 - gtid_9614;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11332 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11336 = squot64(global_tid_11325, segred_tblock_sizze_9608);\n        block_base_offset_11337 = tblock_id_in_segment_11336 * q_11284 * segred_tblock_sizz", "e_9608;\n        for (int64_t i_11338 = 0; i_11338 < q_11284; i_11338++) {\n            int64_t block_offset_11339 = block_base_offset_11337 + i_11338 * segred_tblock_sizze_9608;\n            \n            gtid_9615 = global_tid_11325 + threads_per_segment_11286 * i_11338;\n            if (slt64(gtid_9615, (int64_t) 128)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_9623 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_9612 * (int64_t) 16384 + gtid_9613 * (int64_t) 128 + gtid_9615]);\n                        f16 eta_p_9624 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9614 * (int64_t) 128 + gtid_9615]);\n                        f16 defunc_0_f_res_9625 = eta_p_9623 * eta_p_9624;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_9617 = eta_p_block_res_acc_11332;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_9618 = defunc_0_f_res_9625;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_9619 = eta_p_9617 + eta_p_9618;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11332 = defunc_0_op_res_9619;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11341 = 1;\n        of",
                                    "fset_11340 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_9608))) {\n                eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n            }\n        }\n        offset_11340 = 1;\n        while (slt32(offset_11340, wave_sizze_11314)) {\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_9608)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11340 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            offset_11340 *= 2;\n        }\n        while (slt32(skip_waves_11341, squot32(sext_i64_i32(segred_tblock_sizze_9608) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11340 = skip_waves_11341 * wave_sizze_11314;\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_9608)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11341 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((__local uint16_", "t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            skip_waves_11341 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11312) == (int64_t) 0) {\n                eta_p_block_res_acc_11332 = eta_p_11333;\n            } else {\n                eta_p_block_res_acc_11332 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11283 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) mem_10479)[gtid_9612 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + gtid_9613 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9614] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                }\n            }\n        } else {\n            int32_t old_counter_11342;\n            bool is_last_block_11343;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11287)[sext_i32_i64(virt_tblock_id_11323)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                    mem_fence_global();\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int", ") 1);\n                    ((__local bool *) sync_arr_mem_11318)[(int64_t) 0] = old_counter_11342 == sext_i64_i32(blocks_per_segment_11283 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11343 = ((__local bool *) sync_arr_mem_11318)[(int64_t) 0];\n            if (is_last_block_11343) {\n                if (local_tid_11312 == 0) {\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11283));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11344 = sdiv_up64(blocks_per_segment_11283, segred_tblock_sizze_9608);\n                    \n                    eta_p_9617 = (f16) 0.0F;\n                    for (int64_t i_11345 = 0; i_11345 < read_per_thread_11344; i_11345++) {\n                        int64_t block_res_id_11346 = sext_i32_i64(local_tid_11312) * read_per_thread_11344 + i_11345;\n                        int64_t index_of_block_res_11347 = flat_segment_id_11324 * blocks_per_segment_11283 + block_res_id_11346;\n                        \n                        if (slt64(block_res_id_11346, blocks_per_segment_11283)) {\n                            eta_p_9618 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11287)[index_of_block_res_11347]);\n                            \n                            f16 defunc_0_op_res_9619 = eta_p_9617 + eta_p_9618;\n                            \n                            eta_p_9617 = defunc_0_op_res_9619;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_9617);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n          ",
                                    "          int32_t offset_11348;\n                    int32_t skip_waves_11349 = 1;\n                    f16 eta_p_11333;\n                    f16 eta_p_11334;\n                    \n                    offset_11348 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_9608))) {\n                            eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                        }\n                    }\n                    offset_11348 = 1;\n                    while (slt32(offset_11348, wave_sizze_11314)) {\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_9608)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11348 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        offset_11348 *= 2;\n                    }\n                    while (slt32(skip_waves_11349, squot32(sext_i64_i32(segred_tblock_sizze_9608) + wave_sizze_11314 - 1, wa", "ve_sizze_11314))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11348 = skip_waves_11349 * wave_sizze_11314;\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_9608)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11349 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        skip_waves_11349 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11312 == 0) {\n                            ((__global uint16_t *) mem_10479)[gtid_9612 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + gtid_9613 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9614] = futrts_to_bits16(eta_p_11333);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_9608\n    #", "undef chunk_sizze_11250\n}\nFUTHARK_KERNEL_SIZED(run128zisegred_large_9663_dim1, 1, 1)\nvoid run128zisegred_large_9663(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t one_intra_par_min_9514, int64_t num_tblocks_9656, int64_t blocks_per_segment_11439, int64_t q_11440, int64_t num_virtblocks_11441, int64_t threads_per_segment_11442, __global unsigned char *ext_mem_10579, __global unsigned char *mem_10589, __global unsigned char *mem_10594, __global unsigned char *segred_tmp_mem_11443, __global unsigned char *counters_mem_11445)\n{\n    #define segred_tblock_sizze_9655 (run128zisegred_large_9663zisegred_tblock_sizze_9655)\n    #define chunk_sizze_11406 (run128zisegred_large_9663zichunk_sizze_11406)\n    \n    volatile __local unsigned char *sync_arr_mem_11454_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11454_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11452_backing_0 = &shared_mem[sync_arr_mem_11454_backing_1_offset];\n    const int64_t red_arr_f16_mem_11452_backing_0_offset = sync_arr_mem_11454_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_9655 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9655, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11448;\n    int32_t tblock_sizze_11451;\n    int32_t wave_sizze_11450;\n    int32_t block_id_11449;\n    int32_t global_tid_11447;\n    int64_t phys_tid_9663;\n    __local unsigned char *red_arr_f16_mem_11452;\n    __local unsigned char *sync_arr_mem_11454;\n    int32_t phys_tblock_id_11456;\n    int32_t iterations_11457;\n    \n    local_tid_11448 = get_local_id(0);\n    tblock_sizze_11451 = get_local_size(0);\n    wave_sizze_11450 = LOCKSTEP_WIDTH;\n    block_id_11449 = get_tblock_id(0);\n    global_tid_11447 = block_id_11449 * tblock_sizze_11451 + local_tid_11448;\n    phys_tid_9663 = sext_i32_i64(global_tid_11447);\n    red_arr_f16_mem_11452 = (__local unsigned char *)",
                                    " red_arr_f16_mem_11452_backing_0;\n    sync_arr_mem_11454 = (__local unsigned char *) sync_arr_mem_11454_backing_1;\n    phys_tblock_id_11456 = get_tblock_id(0);\n    iterations_11457 = sdiv_up32(sext_i64_i32(num_virtblocks_11441) - phys_tblock_id_11456, sext_i64_i32(num_tblocks_9656));\n    for (int32_t i_11458 = 0; i_11458 < iterations_11457; i_11458++) {\n        int32_t virt_tblock_id_11459;\n        int64_t flat_segment_id_11460;\n        int64_t global_tid_11461;\n        int64_t slice_11462;\n        int64_t slice_11463;\n        int64_t slice_11464;\n        int64_t gtid_9659;\n        int64_t remnant_11465;\n        int64_t gtid_9660;\n        int64_t remnant_11466;\n        int64_t gtid_9661;\n        int64_t remnant_11467;\n        int64_t gtid_9662;\n        f16 eta_p_block_res_acc_11468;\n        f16 eta_p_9664;\n        f16 eta_p_9665;\n        int64_t tblock_id_in_segment_11472;\n        int64_t block_base_offset_11473;\n        int32_t offset_11476;\n        int32_t skip_waves_11477;\n        f16 eta_p_11469;\n        f16 eta_p_11470;\n        \n        virt_tblock_id_11459 = phys_tblock_id_11456 + i_11458 * sext_i64_i32(num_tblocks_9656);\n        flat_segment_id_11460 = squot64(sext_i32_i64(virt_tblock_id_11459), blocks_per_segment_11439);\n        global_tid_11461 = srem64(sext_i32_i64(virt_tblock_id_11459) * segred_tblock_sizze_9655 + sext_i32_i64(local_tid_11448), threads_per_segment_11442);\n        slice_11462 = (int64_t) 128;\n        slice_11463 = (int64_t) 128 * slice_11462;\n        slice_11464 = m_6642 * slice_11463;\n        gtid_9659 = squot64(flat_segment_id_11460, slice_11463);\n        remnant_11465 = flat_segment_id_11460 - gtid_9659 * slice_11463;\n        gtid_9660 = squot64(remnant_11465, slice_11462);\n        remnant_11466 = remnant_11465 - gtid_9660 * slice_11462;\n        gtid_9661 = remnant_11466;\n        remnant_11467 = remnant_11466 - gtid_9661;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11468 = (f16", ") 0.0F;\n        }\n        tblock_id_in_segment_11472 = squot64(global_tid_11461, segred_tblock_sizze_9655);\n        block_base_offset_11473 = tblock_id_in_segment_11472 * q_11440 * segred_tblock_sizze_9655;\n        for (int64_t i_11474 = 0; i_11474 < q_11440; i_11474++) {\n            int64_t block_offset_11475 = block_base_offset_11473 + i_11474 * segred_tblock_sizze_9655;\n            \n            gtid_9662 = global_tid_11461 + threads_per_segment_11442 * i_11474;\n            if (slt64(gtid_9662, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_9670 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_9659 * one_intra_par_min_9514 + gtid_9660 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9662]);\n                        f16 eta_p_9671 = futrts_from_bits16(((__global uint16_t *) mem_10589)[gtid_9662 + gtid_9661 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643]);\n                        f16 defunc_0_f_res_9672 = eta_p_9670 * eta_p_9671;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_9664 = eta_p_block_res_acc_11468;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_9665 = defunc_0_f_res_9672;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_9666 = eta_p_9664 + eta_p_9665;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11468 = defunc_0_op_res_9666;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in ", "lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11477 = 1;\n        offset_11476 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_9655))) {\n                eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n            }\n        }\n        offset_11476 = 1;\n        while (slt32(offset_11476, wave_sizze_11450)) {\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_9655)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11476 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            offset_11476 *= 2;\n        }\n        while (slt32(skip_waves_11477, squot32(sext_i64_i32(segred_tblock_sizze_9655) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11476 = skip_waves_11477 * wave_sizze_11450;\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_9655)) && ((local_tid_11448 - squot",
                                    "32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11477 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            skip_waves_11477 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11448) == (int64_t) 0) {\n                eta_p_block_res_acc_11468 = eta_p_11469;\n            } else {\n                eta_p_block_res_acc_11468 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11439 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) mem_10594)[gtid_9659 * (int64_t) 16384 + gtid_9660 * (int64_t) 128 + gtid_9661] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                }\n            }\n        } else {\n            int32_t old_counter_11478;\n            bool is_last_block_11479;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11443)[sext_i32_i64(virt_tblock_id_11459)] = futrts_to_bits16(eta_p_block_res_ac", "c_11468);\n                    mem_fence_global();\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11454)[(int64_t) 0] = old_counter_11478 == sext_i64_i32(blocks_per_segment_11439 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11479 = ((__local bool *) sync_arr_mem_11454)[(int64_t) 0];\n            if (is_last_block_11479) {\n                if (local_tid_11448 == 0) {\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11439));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11480 = sdiv_up64(blocks_per_segment_11439, segred_tblock_sizze_9655);\n                    \n                    eta_p_9664 = (f16) 0.0F;\n                    for (int64_t i_11481 = 0; i_11481 < read_per_thread_11480; i_11481++) {\n                        int64_t block_res_id_11482 = sext_i32_i64(local_tid_11448) * read_per_thread_11480 + i_11481;\n                        int64_t index_of_block_res_11483 = flat_segment_id_11460 * blocks_per_segment_11439 + block_res_id_11482;\n                        \n                        if (slt64(block_res_id_11482, blocks_per_segment_11439)) {\n                            eta_p_9665 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11443)[index_of_block_res_11483]);\n                            \n                            f16 defunc_0_op_res_9666 = eta_p_9664 + eta_p_9665;\n                            \n                            eta_p_9664 = defunc_0_op_res_9666;\n                        }\n                    }\n                }\n                ((__local uint16_", "t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_9664);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11484;\n                    int32_t skip_waves_11485 = 1;\n                    f16 eta_p_11469;\n                    f16 eta_p_11470;\n                    \n                    offset_11484 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_9655))) {\n                            eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                        }\n                    }\n                    offset_11484 = 1;\n                    while (slt32(offset_11484, wave_sizze_11450)) {\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_9655)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11484 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n  ",
                                    "                      }\n                        offset_11484 *= 2;\n                    }\n                    while (slt32(skip_waves_11485, squot32(sext_i64_i32(segred_tblock_sizze_9655) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11484 = skip_waves_11485 * wave_sizze_11450;\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_9655)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11485 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        skip_waves_11485 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11448 == 0) {\n                            ((__global uint16_t *) mem_10594)[gtid_9659 * (int64_t) 16384 + gtid_9660 * (int64_t) 128 + gtid_9661] = futrts_to_bits16(eta_p_11469);\n                        }\n                    }\n                }\n         ", "   }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_9655\n    #undef chunk_sizze_11406\n}\nFUTHARK_KERNEL_SIZED(run128zisegred_small_9616_dim1, 1, 1)\nvoid run128zisegred_small_9616(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t num_tblocks_9609, int64_t segment_sizze_nonzzero_11251, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479)\n{\n    #define segred_tblock_sizze_9608 (run128zisegred_small_9616zisegred_tblock_sizze_9608)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11258_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11258_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_9608 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9608, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11254;\n    int32_t tblock_sizze_11257;\n    int32_t wave_sizze_11256;\n    int32_t block_id_11255;\n    int32_t global_tid_11253;\n    int64_t phys_tid_9616;\n    __local unsigned char *red_arr_f16_mem_11258;\n    int32_t phys_tblock_id_11260;\n    int32_t iterations_11261;\n    \n    local_tid_11254 = get_local_id(0);\n    tblock_sizze_11257 = get_local_size(0);\n    wave_sizze_11256 = LOCKSTEP_WIDTH;\n    block_id_11255 = get_tblock_id(0);\n    global_tid_11253 = block_id_11255 * tblock_sizze_11257 + local_tid_11254;\n    phys_tid_9616 = sext_i32_i64(global_tid_11253);\n    red_arr_f16_mem_11258 = (__local unsigned char *) red_arr_f16_mem_11258_backing_0;\n    phys_tblock_id_11260 = get_tblock_id(0);\n    iterations_11261 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251))) - phys_tblock_id_11260, sext_i64_i32(num_tblocks_9609));\n    for (int32_t i_11262 = 0; i_11262 < iterations_11261; i_11262+", "+) {\n        int32_t virt_tblock_id_11263;\n        int64_t slice_11264;\n        int64_t slice_11265;\n        int64_t slice_11266;\n        int64_t gtid_9612;\n        int64_t remnant_11267;\n        int64_t gtid_9613;\n        int64_t remnant_11268;\n        int64_t gtid_9614;\n        int64_t remnant_11269;\n        int64_t gtid_9615;\n        \n        virt_tblock_id_11263 = phys_tblock_id_11260 + i_11262 * sext_i64_i32(num_tblocks_9609);\n        slice_11264 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;\n        slice_11265 = (int64_t) 128 * slice_11264;\n        slice_11266 = m_6642 * slice_11265;\n        gtid_9612 = squot64(squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251), slice_11265);\n        remnant_11267 = squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) - gtid_9612 * slice_11265;\n        gtid_9613 = squot64(remnant_11267, slice_11264);\n        remnant_11268 = remnant_11267 - gtid_9613 * slice_11264;\n        gtid_9614 = remnant_11268;\n        remnant_11269 = remnant_11268 - gtid_9614;\n        gtid_9615 = srem64(sext_i32_i64(local_tid_11254), (int64_t) 128);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, (int64_t) 128) && (((slt64(gtid_9612, m_6642) && slt64(gtid_9613, (int64_t) 128)) && slt64(gtid_9614, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) && slt64(sext_i32_i64(local_tid_11254), (int64_t) 128 * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251)))) {\n                // apply map function\n                {\n                    f16 eta_p_9623 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_9612 * (int64_t) 16384 + gtid_9613 * (int64_t) 128 + gtid_9615]);\n                    f16 eta_p_9624 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9614 * (int64_t) 12",
                                    "8 + gtid_9615]);\n                    f16 defunc_0_f_res_9625 = eta_p_9623 * eta_p_9624;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(defunc_0_f_res_9625);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, (int64_t) 128)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_9617;\n                f16 eta_p_9618;\n                f16 eta_p_11270;\n                f16 eta_p_11271;\n                bool ltid_in_bounds_11273 = slt64(sext_i32_i64(local_tid_11254), (int64_t) 128 * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251));\n                int32_t skip_threads_11274;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11273) {\n                        eta_p_9618 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                        if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                            eta_p_9617 = eta_p_9618;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11274 = 1;\n                    while (slt32(skip_threads_11274, 32)) {\n                        bool thread_active_11275 = sle32(skip_threads_11274, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && ltid_in_bounds_11273;\n                        \n                        if (thread_active_11275) {\n                            // read operands\n                           ", " {\n                                eta_p_9617 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11274)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11276 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 128), sext_i32_i64(local_tid_11254) - sext_i32_i64(local_tid_11254 - skip_threads_11274));\n                            \n                            if (thread_active_11275 && inactive_11276) {\n                                eta_p_9617 = eta_p_9618;\n                            }\n                            if (thread_active_11275) {\n                                if (!inactive_11276) {\n                                    f16 defunc_0_op_res_9619 = eta_p_9617 + eta_p_9618;\n                                    \n                                    eta_p_9617 = defunc_0_op_res_9619;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11275) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_9617);\n                                eta_p_9618 = eta_p_9617;\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11274 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to", " offset 'i'\n                {\n                    if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 31 && ltid_in_bounds_11273) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32))] = futrts_to_bits16(eta_p_9617);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11277;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                            eta_p_11271 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                            if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                                eta_p_11270 = eta_p_11271;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11277 = 1;\n                        while (slt32(skip_threads_11277, 32)) {\n                            bool thread_active_11278 = sle32(skip_threads_11277, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273);\n                            \n                            if (thread_active_11278) {\n                                // read operands\n                                {\n                                    eta_p_11270 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11277)]);\n                                }\n                            }\n                            // perform operation\n                     ",
                                    "       {\n                                bool inactive_11279 = slt64(srem64(sext_i32_i64(local_tid_11254 * 32 + 32 - 1), (int64_t) 128), sext_i32_i64(local_tid_11254 * 32 + 32 - 1) - sext_i32_i64((local_tid_11254 - skip_threads_11277) * 32 + 32 - 1));\n                                \n                                if (thread_active_11278 && inactive_11279) {\n                                    eta_p_11270 = eta_p_11271;\n                                }\n                                if (thread_active_11278) {\n                                    if (!inactive_11279) {\n                                        f16 defunc_0_op_res_11272 = eta_p_11270 + eta_p_11271;\n                                        \n                                        eta_p_11270 = defunc_0_op_res_11272;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11278) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_11270);\n                                    eta_p_11271 = eta_p_11270;\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11277 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11280 = squot32(local_tid_11254, 32) == 0 || !ltid_in_bounds_11273;\n                \n                // carry-in for every block exce", "pt the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11280) {\n                            eta_p_9618 = eta_p_9617;\n                            eta_p_9617 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_11281 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 128), sext_i32_i64(local_tid_11254) - sext_i32_i64(squot32(local_tid_11254, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11280) {\n                            if (inactive_11281) {\n                                eta_p_9617 = eta_p_9618;\n                            }\n                        }\n                        if (!no_carry_in_11280) {\n                            if (!inactive_11281) {\n                                f16 defunc_0_op_res_9619 = eta_p_9617 + eta_p_9618;\n                                \n                                eta_p_9617 = defunc_0_op_res_9619;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11280) {\n                            ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_9617);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_9618);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE", ");\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) && slt64(sext_i32_i64(local_tid_11254), squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251))) {\n                f16 tmp_11282 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[(sext_i32_i64(local_tid_11254) + (int64_t) 1) * segment_sizze_nonzzero_11251 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10479)[squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + (sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id",
                                    "_11263) * squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)] = futrts_to_bits16(tmp_11282);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_9608\n}\nFUTHARK_KERNEL_SIZED(run128zisegred_small_9663_dim1, 1, 1)\nvoid run128zisegred_small_9663(__global int *global_failure, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, int64_t one_intra_par_min_9514, int64_t num_tblocks_9656, int64_t segment_sizze_nonzzero_11407, __global unsigned char *ext_mem_10579, __global unsigned char *mem_10589, __global unsigned char *mem_10594)\n{\n    #define segred_tblock_sizze_9655 (run128zisegred_small_9663zisegred_tblock_sizze_9655)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11414_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11414_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_9655 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9655, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11410;\n    int32_t tblock_sizze_11413;\n    int32_t wave_sizze_11412;\n    int32_t block_id_11411;\n    int32_t global_tid_11409;\n    int64_t phys_tid_9663;\n    __local unsigned char *red_arr_f16_mem_11414;\n    int32_t phys_tblock_id_11416;\n    int32_t iterations_11417;\n    \n    local_tid_11410 = get_local_id(0);\n    tblock_sizze_11413 = get_local_size(0);\n    wave_sizze_11412 = LOCKSTEP_WIDTH;\n    block_id_11411 = get_tblock_id(0);\n    global_tid_11409 = block_id_11411 * tblock_sizze_11413 + local_tid_11410;\n    phys_tid_9663 = sext_i32_i64(global_tid_11409);\n    red_arr_f16_mem_11414 = (__local unsigned char *) red_arr", "_f16_mem_11414_backing_0;\n    phys_tblock_id_11416 = get_tblock_id(0);\n    iterations_11417 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6642 * (int64_t) 128 * (int64_t) 128, squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407))) - phys_tblock_id_11416, sext_i64_i32(num_tblocks_9656));\n    for (int32_t i_11418 = 0; i_11418 < iterations_11417; i_11418++) {\n        int32_t virt_tblock_id_11419;\n        int64_t slice_11420;\n        int64_t slice_11421;\n        int64_t slice_11422;\n        int64_t gtid_9659;\n        int64_t remnant_11423;\n        int64_t gtid_9660;\n        int64_t remnant_11424;\n        int64_t gtid_9661;\n        int64_t remnant_11425;\n        int64_t gtid_9662;\n        \n        virt_tblock_id_11419 = phys_tblock_id_11416 + i_11418 * sext_i64_i32(num_tblocks_9656);\n        slice_11420 = (int64_t) 128;\n        slice_11421 = (int64_t) 128 * slice_11420;\n        slice_11422 = m_6642 * slice_11421;\n        gtid_9659 = squot64(squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407), slice_11421);\n        remnant_11423 = squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) - gtid_9659 * slice_11421;\n        gtid_9660 = squot64(remnant_11423, slice_11420);\n        remnant_11424 = remnant_11423 - gtid_9660 * slice_11420;\n        gtid_9661 = remnant_11424;\n        remnant_11425 = remnant_11424 - gtid_9661;\n        gtid_9662 = srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) && (((slt64(gtid_9659, m_6642) && slt64(gtid_9660, (int64_t) 128)) && slt64(gtid_9661, (int64_t) 128)) && slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * squot64(segred_tblock_siz", "ze_9655, segment_sizze_nonzzero_11407)))) {\n                // apply map function\n                {\n                    f16 eta_p_9670 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_9659 * one_intra_par_min_9514 + gtid_9660 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 + gtid_9662]);\n                    f16 eta_p_9671 = futrts_from_bits16(((__global uint16_t *) mem_10589)[gtid_9662 + gtid_9661 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643]);\n                    f16 defunc_0_f_res_9672 = eta_p_9670 * eta_p_9671;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(defunc_0_f_res_9672);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_9664;\n                f16 eta_p_9665;\n                f16 eta_p_11426;\n                f16 eta_p_11427;\n                bool ltid_in_bounds_11429 = slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407));\n                int32_t skip_threads_11430;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11429) {\n                        eta_p_9665 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                        if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                            eta_p_9664 = eta_p_9665;\n                        }\n                    }\n                }\n           ",
                                    "     // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11430 = 1;\n                    while (slt32(skip_threads_11430, 32)) {\n                        bool thread_active_11431 = sle32(skip_threads_11430, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && ltid_in_bounds_11429;\n                        \n                        if (thread_active_11431) {\n                            // read operands\n                            {\n                                eta_p_9664 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11430)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11432 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11410) - sext_i32_i64(local_tid_11410 - skip_threads_11430));\n                            \n                            if (thread_active_11431 && inactive_11432) {\n                                eta_p_9664 = eta_p_9665;\n                            }\n                            if (thread_active_11431) {\n                                if (!inactive_11432) {\n                                    f16 defunc_0_op_res_9666 = eta_p_9664 + eta_p_9665;\n                                    \n                                    eta_p_9664 = defunc_0_op_res_9666;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11431) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = ", "futrts_to_bits16(eta_p_9664);\n                                eta_p_9665 = eta_p_9664;\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11430 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 31 && ltid_in_bounds_11429) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32))] = futrts_to_bits16(eta_p_9664);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11433;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                            eta_p_11427 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                            if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                                eta_p_11426 = eta_p_11427;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11433 = 1;\n                        while (slt32(skip_threads_11433, 32)) {\n                            bool thread_active_11434 = sle32(skip_threads_11433, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds", "_11429);\n                            \n                            if (thread_active_11434) {\n                                // read operands\n                                {\n                                    eta_p_11426 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11433)]);\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_11435 = slt64(srem64(sext_i32_i64(local_tid_11410 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11410 * 32 + 32 - 1) - sext_i32_i64((local_tid_11410 - skip_threads_11433) * 32 + 32 - 1));\n                                \n                                if (thread_active_11434 && inactive_11435) {\n                                    eta_p_11426 = eta_p_11427;\n                                }\n                                if (thread_active_11434) {\n                                    if (!inactive_11435) {\n                                        f16 defunc_0_op_res_11428 = eta_p_11426 + eta_p_11427;\n                                        \n                                        eta_p_11426 = defunc_0_op_res_11428;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11434) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_11426);\n                                    eta_p_11427 = eta_p_11426;\n                                }\n                         ",
                                    "   }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11433 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11436 = squot32(local_tid_11410, 32) == 0 || !ltid_in_bounds_11429;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11436) {\n                            eta_p_9665 = eta_p_9664;\n                            eta_p_9664 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_11437 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), sext_i32_i64(local_tid_11410) - sext_i32_i64(squot32(local_tid_11410, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11436) {\n                            if (inactive_11437) {\n                                eta_p_9664 = eta_p_9665;\n                            }\n                        }\n                        if (!no_carry_in_11436) {\n                            if (!inactive_11437) {\n                                f16 defunc_0_op_res_9666 = eta_p_9664 + eta_p_9665;\n                                \n                                eta_p_9664 = defunc_0_op_res_9666;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11436) {\n                            ((__local uint16_t *) red_arr_f16_mem_11414)[sext", "_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_9664);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_9665);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), m_6642 * (int64_t) 128 * (int64_t) 128) && slt64(sext_i32_i64(local_tid_11410), squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407))) {\n                f16 tmp_11438 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[(sext_i32_i64(local_tid_11410) + (int64_t) 1) * segment_sizze_nonzzero_11407 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10594)[squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 16384) * (int64_t) 16384 + squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 16384) * (int64_t) 16384, (int64_t) 128) * (int64_t) 128 + (sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407", ") + sext_i32_i64(local_tid_11410), (int64_t) 16384) * (int64_t) 16384 - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 16384) * (int64_t) 16384, (int64_t) 128) * (int64_t) 128)] = futrts_to_bits16(tmp_11438);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_9655\n}\nFUTHARK_KERNEL_SIZED(run16zisegmap_7051_dim1, 1, 1)\nvoid run16zisegmap_7051(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t num_tblocks_7047, int64_t num_threads_10866, int32_t virt_num_tblocks_11024, __global unsigned char *K_mem_10473, __global unsigned char *mem_10768, __global unsigned char *mem_10778, __global unsigned char *mem_10820, __global unsigned char *color_10856)\n{\n    #define segmap_tblock_sizze_7046 (run16zisegmap_7051zisegmap_tblock_sizze_7046)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11026;\n    int32_t tblock_sizze_11029;\n    int32_t wave_sizze_11028;\n    int32_t block_id_11027;\n    int32_t global_tid_11025;\n    int64_t phys_tid_7051;\n    int32_t phys_tblock_id_11030;\n    int32_t iterations_11031;\n    \n    local_tid_11026 = get_local_id(0);\n    tblock_sizze_11029 = get_local_size(0);\n    wave_sizze_11028 = LOCKSTEP_WIDTH;\n    block_id_11027 = get_tblock_id(0);\n    global_tid_11025 = block_id_11027 * tblock_sizze_11029 + local_tid_11026;\n    phys_tid_7051 = sext_i32_i64(global_tid_11025);\n    phys_tblock_id_11030 = get_tblock_id(0);\n    iterations_11031 = sdiv_up32(virt_num_tblocks_11024 - phys_tblock_id_11030, sext_i64_i32(num_tblocks_7047));\n    for (int32_t i_11032 = 0; i_11032 < iterations_11031; i_11032++) {\n        int32_t",
                                    " virt_tblock_id_11033;\n        int64_t global_tid_11034;\n        int64_t slice_11035;\n        int64_t gtid_7050;\n        int64_t remnant_11036;\n        \n        virt_tblock_id_11033 = phys_tblock_id_11030 + i_11032 * sext_i64_i32(num_tblocks_7047);\n        global_tid_11034 = sext_i32_i64(virt_tblock_id_11033) * segmap_tblock_sizze_7046 + sext_i32_i64(local_tid_11026);\n        slice_11035 = m_6594;\n        gtid_7050 = global_tid_11034;\n        remnant_11036 = global_tid_11034 - gtid_7050;\n        if (slt64(gtid_7050, m_6594)) {\n            f16 mem_10788[(int64_t) 16 * (int64_t) 16];\n            f16 mem_10802[(int64_t) 16];\n            \n            for (int64_t i_10441 = 0; i_10441 < (int64_t) 16; i_10441++) {\n                for (int64_t i_10445 = 0; i_10445 < dzlz7bUZLztZRz20Umz20U16z7dUzg_6595; i_10445++) {\n                    f16 defunc_0_f_res_7057;\n                    f16 redout_10447 = (f16) 0.0F;\n                    \n                    for (int64_t i_10448 = 0; i_10448 < (int64_t) 16; i_10448++) {\n                        f16 eta_p_7061;\n                        f16 eta_p_7062;\n                        f16 defunc_0_f_res_7063;\n                        f16 defunc_0_op_res_7060;\n                        f16 redout_tmp_11039;\n                        \n                        eta_p_7061 = futrts_from_bits16(((__global uint16_t *) mem_10768)[gtid_7050 + i_10441 * (m_6594 * (int64_t) 16) + i_10448 * m_6594]);\n                        eta_p_7062 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10445 * (int64_t) 16 + i_10448]);\n                        defunc_0_f_res_7063 = eta_p_7061 * eta_p_7062;\n                        defunc_0_op_res_7060 = defunc_0_f_res_7063 + redout_10447;\n                        redout_tmp_11039 = defunc_0_op_res_7060;\n                        redout_10447 = redout_tmp_11039;\n                    }\n                    defunc_0_f_res_7057 = redout_10447;\n                    ((__global uint16_t *) color_10856)[phys_tid_7051 + i_10445 * num_thre", "ads_10866] = futrts_to_bits16(defunc_0_f_res_7057);\n                }\n                for (int64_t i_10451 = 0; i_10451 < (int64_t) 16; i_10451++) {\n                    f16 defunc_0_f_res_7066;\n                    f16 redout_10453 = (f16) 0.0F;\n                    \n                    for (int64_t i_10454 = 0; i_10454 < dzlz7bUZLztZRz20Umz20U16z7dUzg_6595; i_10454++) {\n                        f16 eta_p_7070;\n                        f16 eta_p_7071;\n                        f16 defunc_0_f_res_7072;\n                        f16 defunc_0_op_res_7069;\n                        f16 redout_tmp_11041;\n                        \n                        eta_p_7070 = futrts_from_bits16(((__global uint16_t *) color_10856)[phys_tid_7051 + i_10454 * num_threads_10866]);\n                        eta_p_7071 = futrts_from_bits16(((__global uint16_t *) mem_10778)[i_10454 + i_10451 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595]);\n                        defunc_0_f_res_7072 = eta_p_7070 * eta_p_7071;\n                        defunc_0_op_res_7069 = defunc_0_f_res_7072 + redout_10453;\n                        redout_tmp_11041 = defunc_0_op_res_7069;\n                        redout_10453 = redout_tmp_11041;\n                    }\n                    defunc_0_f_res_7066 = redout_10453;\n                    mem_10802[i_10451] = defunc_0_f_res_7066;\n                }\n                for (int64_t i_0 = 0; i_0 < (int64_t) 16; i_0++) {\n                    mem_10788[i_10441 * (int64_t) 16 + i_0] = mem_10802[i_0];\n                }\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 16; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 16; i_1++) {\n                    ((__global uint16_t *) mem_10820)[gtid_7050 + (i_0 * (m_6594 * (int64_t) 16) + i_1 * m_6594)] = futrts_to_bits16(mem_10788[i_0 * (int64_t) 16 + i_1]);\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_7046\n}\nFUT", "HARK_KERNEL_SIZED(run16zisegmap_7497_dim1, 1, 1)\nvoid run16zisegmap_7497(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t num_tblocks_7475, int64_t num_threads_10888, int32_t virt_num_tblocks_11111, __global unsigned char *K_mem_10473, __global unsigned char *mem_10695, __global unsigned char *mem_10705, __global unsigned char *mem_10736, __global unsigned char *color_10859)\n{\n    #define segmap_tblock_sizze_7474 (run16zisegmap_7497zisegmap_tblock_sizze_7474)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11113;\n    int32_t tblock_sizze_11116;\n    int32_t wave_sizze_11115;\n    int32_t block_id_11114;\n    int32_t global_tid_11112;\n    int64_t phys_tid_7497;\n    int32_t phys_tblock_id_11117;\n    int32_t iterations_11118;\n    \n    local_tid_11113 = get_local_id(0);\n    tblock_sizze_11116 = get_local_size(0);\n    wave_sizze_11115 = LOCKSTEP_WIDTH;\n    block_id_11114 = get_tblock_id(0);\n    global_tid_11112 = block_id_11114 * tblock_sizze_11116 + local_tid_11113;\n    phys_tid_7497 = sext_i32_i64(global_tid_11112);\n    phys_tblock_id_11117 = get_tblock_id(0);\n    iterations_11118 = sdiv_up32(virt_num_tblocks_11111 - phys_tblock_id_11117, sext_i64_i32(num_tblocks_7475));\n    for (int32_t i_11119 = 0; i_11119 < iterations_11118; i_11119++) {\n        int32_t virt_tblock_id_11120;\n        int64_t global_tid_11121;\n        int64_t slice_11122;\n        int64_t slice_11123;\n        int64_t gtid_7495;\n        int64_t remnant_11124;\n        int64_t gtid_7496;\n        int64_t remnant_11125;\n        \n        virt_tblock_id_11120 = phys_tblock_id_11117 + i_11119 * sext_i64_i32(num_tblocks_7475);\n        global_tid_11121 = sext_i32_i64(virt_tblock_id_11120) * segmap_tblock_sizze_7474 + sext_i32_i64(local_tid_11113);\n        slice_11122 = (int64_t) 16;\n        slice_11123 = m_6594 * slice_11122;\n        gtid_7495 = squot64(global_tid_11121, slice_11122);\n        remnant_11124 = global_tid_11121 - gtid_7495 * sl",
                                    "ice_11122;\n        gtid_7496 = remnant_11124;\n        remnant_11125 = remnant_11124 - gtid_7496;\n        if (slt64(gtid_7495, m_6594) && slt64(gtid_7496, (int64_t) 16)) {\n            f16 mem_10719[(int64_t) 16];\n            \n            for (int64_t i_10457 = 0; i_10457 < dzlz7bUZLztZRz20Umz20U16z7dUzg_6595; i_10457++) {\n                f16 defunc_0_f_res_7501;\n                f16 redout_10459 = (f16) 0.0F;\n                \n                for (int64_t i_10460 = 0; i_10460 < (int64_t) 16; i_10460++) {\n                    f16 eta_p_7505;\n                    f16 eta_p_7506;\n                    f16 defunc_0_f_res_7507;\n                    f16 defunc_0_op_res_7504;\n                    f16 redout_tmp_11127;\n                    \n                    eta_p_7505 = futrts_from_bits16(((__global uint16_t *) mem_10695)[gtid_7495 * (int64_t) 16 + gtid_7496 + i_10460 * ((int64_t) 16 * m_6594)]);\n                    eta_p_7506 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10457 * (int64_t) 16 + i_10460]);\n                    defunc_0_f_res_7507 = eta_p_7505 * eta_p_7506;\n                    defunc_0_op_res_7504 = defunc_0_f_res_7507 + redout_10459;\n                    redout_tmp_11127 = defunc_0_op_res_7504;\n                    redout_10459 = redout_tmp_11127;\n                }\n                defunc_0_f_res_7501 = redout_10459;\n                ((__global uint16_t *) color_10859)[phys_tid_7497 + i_10457 * num_threads_10888] = futrts_to_bits16(defunc_0_f_res_7501);\n            }\n            for (int64_t i_10463 = 0; i_10463 < (int64_t) 16; i_10463++) {\n                f16 defunc_0_f_res_7510;\n                f16 redout_10465 = (f16) 0.0F;\n                \n                for (int64_t i_10466 = 0; i_10466 < dzlz7bUZLztZRz20Umz20U16z7dUzg_6595; i_10466++) {\n                    f16 eta_p_7514;\n                    f16 eta_p_7515;\n                    f16 defunc_0_f_res_7516;\n                    f16 defunc_0_op_res_7513;\n                    f16 redout_tmp_11129;\n            ", "        \n                    eta_p_7514 = futrts_from_bits16(((__global uint16_t *) color_10859)[phys_tid_7497 + i_10466 * num_threads_10888]);\n                    eta_p_7515 = futrts_from_bits16(((__global uint16_t *) mem_10705)[i_10466 + i_10463 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595]);\n                    defunc_0_f_res_7516 = eta_p_7514 * eta_p_7515;\n                    defunc_0_op_res_7513 = defunc_0_f_res_7516 + redout_10465;\n                    redout_tmp_11129 = defunc_0_op_res_7513;\n                    redout_10465 = redout_tmp_11129;\n                }\n                defunc_0_f_res_7510 = redout_10465;\n                mem_10719[i_10463] = defunc_0_f_res_7510;\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 16; i_0++) {\n                ((__global uint16_t *) mem_10736)[gtid_7495 * (int64_t) 16 + gtid_7496 + i_0 * ((int64_t) 16 * m_6594)] = futrts_to_bits16(mem_10719[i_0]);\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_7474\n}\nFUTHARK_KERNEL_SIZED(run16zisegmap_intrablock_10048_dim1, 1, 1)\nvoid run16zisegmap_intrablock_10048(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t one_intra_par_min_7480, int64_t full_tiles_10076, int64_t kk_10234, __global unsigned char *V_mem_10474, __global unsigned char *ext_mem_10569, __global unsigned char *mem_10670)\n{\n    volatile __local unsigned char *color_10865_backing_1 = &shared_mem[0];\n    const int64_t color_10865_backing_1_offset = 0 + (int64_t) 256;\n    volatile __local unsigned char *color_10864_backing_0 = &shared_mem[color_10865_backing_1_offset];\n    const int64_t color_10864_backing_0_offset = color_10865_backing_1_offset + (int64_t) 256;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11354;\n    int32_t tblock_sizze_11357;\n    int32_t wave_sizze_11356;\n    int32_t block_id_11355;\n    int32_t global_tid_11353;\n    in", "t64_t gid_flat_10048;\n    int64_t slice_11360;\n    int64_t slice_11361;\n    int64_t ltid_pre_11358;\n    int64_t remnant_11362;\n    int64_t ltid_pre_11359;\n    int64_t remnant_11363;\n    int64_t slice_11364;\n    int64_t slice_11365;\n    int64_t slice_11366;\n    int64_t gtid_7604;\n    int64_t remnant_11367;\n    int64_t gid_y_10046;\n    int64_t remnant_11368;\n    int64_t gid_x_10047;\n    int64_t remnant_11369;\n    __local unsigned char *color_10864;\n    __local unsigned char *color_10865;\n    int64_t iii_10049;\n    int64_t jjj_10050;\n    f16 mem_10611[(int64_t) 2 * (int64_t) 2];\n    int64_t ltid_flat_10064;\n    int64_t ltid_y_10063;\n    int64_t ltid_x_10062;\n    f16 mem_10594[(int64_t) 2 * (int64_t) 2];\n    f16 ext_mem_10646[(int64_t) 2 * (int64_t) 2];\n    f16 mem_param_10614[(int64_t) 2 * (int64_t) 2];\n    int64_t ltid_flat_10256;\n    int64_t ltid_flat_10301;\n    f16 mem_10666[(int64_t) 2 * (int64_t) 2];\n    int64_t ltid_flat_10362;\n    int64_t ltid_y_10361;\n    int64_t ltid_x_10360;\n    int64_t binop_x_10377;\n    int64_t binop_y_10382;\n    int64_t slice_11393;\n    int64_t slice_11394;\n    int64_t slice_11395;\n    int64_t reg_tile_i_11390;\n    int64_t remnant_11396;\n    int64_t reg_tile_i_11391;\n    int64_t remnant_11397;\n    int64_t reg_tile_i_11392;\n    int64_t remnant_11398;\n    int64_t tile_dim_start_11399;\n    int64_t tile_dim_start_11400;\n    int64_t tile_dim_start_11401;\n    \n    local_tid_11354 = get_local_id(0);\n    tblock_sizze_11357 = get_local_size(0);\n    wave_sizze_11356 = LOCKSTEP_WIDTH;\n    block_id_11355 = get_tblock_id(0);\n    global_tid_11353 = block_id_11355 * tblock_sizze_11357 + local_tid_11354;\n    gid_flat_10048 = sext_i32_i64(block_id_11355);\n    slice_11360 = (int64_t) 8;\n    slice_11361 = (int64_t) 8 * slice_11360;\n    ltid_pre_11358 = squot64(sext_i32_i64(local_tid_11354), slice_11360);\n    remnant_11362 = sext_i32_i64(local_tid_11354) - ltid_pre_11358 * slice_11360;\n    ltid_pre_11359 = remnant_11362;\n    remnant_11363 = remnant_11362 - lt",
                                    "id_pre_11359;\n    slice_11364 = (int64_t) 1;\n    slice_11365 = slice_11364;\n    slice_11366 = m_6594 * slice_11365;\n    gtid_7604 = squot64(sext_i32_i64(block_id_11355), slice_11365);\n    remnant_11367 = sext_i32_i64(block_id_11355) - gtid_7604 * slice_11365;\n    gid_y_10046 = squot64(remnant_11367, slice_11364);\n    remnant_11368 = remnant_11367 - gid_y_10046 * slice_11364;\n    gid_x_10047 = remnant_11368;\n    remnant_11369 = remnant_11368 - gid_x_10047;\n    color_10864 = (__local unsigned char *) color_10864_backing_0;\n    color_10865 = (__local unsigned char *) color_10865_backing_1;\n    iii_10049 = (int64_t) 16 * gid_y_10046;\n    jjj_10050 = (int64_t) 16 * gid_x_10047;\n    ltid_flat_10064 = sext_i32_i64(local_tid_11354);\n    ltid_y_10063 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10062 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    for (int64_t i_10067 = 0; i_10067 < (int64_t) 2; i_10067++) {\n        for (int64_t i_10070 = 0; i_10070 < (int64_t) 2; i_10070++) {\n            mem_10594[i_10067 * (int64_t) 2 + i_10070] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n            mem_10611[i_0 * (int64_t) 2 + i_1] = mem_10594[i_0 * (int64_t) 2 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < (int64_t) 2 * (int64_t) 2; i_2++)\n        mem_param_10614[i_2] = mem_10611[i_2];\n    for (int64_t i_10077 = 0; i_10077 < full_tiles_10076; i_10077++) {\n        int64_t kk_10081;\n        int64_t ltid_flat_10101;\n        int64_t ltid_flat_10142;\n        f16 mem_10639[(int64_t) 2 * (int64_t) 2];\n        int64_t ltid_flat_10199;\n        int64_t ltid_y_10198;\n        int64_t ltid_x_10197;\n        int64_t binop_x_10212;\n        int64_t binop_y_10217;\n        f16 mem_param_tmp_11372[(int64_t) 2 * (int64_t) 2];\n        \n        kk_10081 = (int64_t) 8 * i_10077;\n        ltid_flat_10101 = sext_i32_i64(local_", "tid_11354);\n        for (int64_t nest_i_11376 = 0; nest_i_11376 < (int64_t) 2; nest_i_11376++) {\n            for (int64_t nest_i_11377 = 0; nest_i_11377 < (int64_t) 1; nest_i_11377++) {\n                int64_t ltid_seq_10104;\n                int64_t ltid_seq_10105;\n                int64_t ltid_y_10102;\n                int64_t ltid_x_10103;\n                int64_t binop_y_10106;\n                int64_t k_10107;\n                int64_t binop_y_10108;\n                int64_t i_10109;\n                int64_t gtid_10110;\n                int64_t defunc_0_map_res_seqdim_idx_10111;\n                bool cond_10112;\n                f16 defunc_0_map_res_elem_10113;\n                bool cond_10117;\n                int64_t defunc_0_map_res_loc_ind_10118;\n                \n                ltid_seq_10104 = nest_i_11376;\n                ltid_seq_10105 = nest_i_11377;\n                ltid_y_10102 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10103 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10106 = (int64_t) 8 * ltid_seq_10105;\n                k_10107 = ltid_x_10103 + binop_y_10106;\n                binop_y_10108 = (int64_t) 8 * ltid_seq_10104;\n                i_10109 = ltid_y_10102 + binop_y_10108;\n                gtid_10110 = iii_10049 + i_10109;\n                defunc_0_map_res_seqdim_idx_10111 = kk_10081 + k_10107;\n                cond_10112 = slt64(gtid_10110, (int64_t) 16);\n                if (cond_10112) {\n                    f16 A_elem_10115 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_7604 * one_intra_par_min_7480 + gtid_10110 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + defunc_0_map_res_seqdim_idx_10111]);\n                    \n                    defunc_0_map_res_elem_10113 = A_elem_10115;\n                } else {\n                    defunc_0_map_res_elem_10113 = (f16) 0.0F;\n                }\n                cond_10117 = slt64(k_10107, (int64_t) 8);\n                if (cond_10117) {\n                    int64_t bi", "nop_y_10119;\n                    int64_t x_10120;\n                    \n                    binop_y_10119 = (int64_t) 8 * i_10109;\n                    x_10120 = k_10107 + binop_y_10119;\n                    defunc_0_map_res_loc_ind_10118 = x_10120;\n                } else {\n                    defunc_0_map_res_loc_ind_10118 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10118) && slt64(defunc_0_map_res_loc_ind_10118, (int64_t) 128)) {\n                    ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10118] = futrts_to_bits16(defunc_0_map_res_elem_10113);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10142 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11378 = 0; nest_i_11378 < (int64_t) 2; nest_i_11378++) {\n            for (int64_t nest_i_11379 = 0; nest_i_11379 < (int64_t) 1; nest_i_11379++) {\n                int64_t ltid_seq_10145;\n                int64_t ltid_seq_10146;\n                int64_t ltid_y_10143;\n                int64_t ltid_x_10144;\n                int64_t binop_y_10147;\n                int64_t k_10148;\n                int64_t binop_y_10149;\n                int64_t i_10150;\n                int64_t gtid_10151;\n                int64_t as_transformed_row_seqdim_idx_10152;\n                bool cond_10153;\n                f16 as_transformed_row_elem_10154;\n                bool cond_10158;\n                int64_t as_transformed_row_loc_ind_10159;\n                \n                ltid_seq_10145 = nest_i_11378;\n                ltid_seq_10146 = nest_i_11379;\n                ltid_y_10143 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10144 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10147 = (int64_t) 8 * ltid_seq_10146;\n                k_10148 = ltid_y_10143 + binop_y_10147;\n                binop_y_10149 = (int64_t) 8 * ltid_seq_10145;\n                i_10150 = ltid_x_10144 + binop_y_1014",
                                    "9;\n                gtid_10151 = jjj_10050 + i_10150;\n                as_transformed_row_seqdim_idx_10152 = kk_10081 + k_10148;\n                cond_10153 = slt64(gtid_10151, (int64_t) 16);\n                if (cond_10153) {\n                    f16 A_elem_10156 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10152 * (int64_t) 16 + gtid_10151]);\n                    \n                    as_transformed_row_elem_10154 = A_elem_10156;\n                } else {\n                    as_transformed_row_elem_10154 = (f16) 0.0F;\n                }\n                cond_10158 = slt64(k_10148, (int64_t) 8);\n                if (cond_10158) {\n                    int64_t binop_y_10160;\n                    int64_t x_10161;\n                    \n                    binop_y_10160 = (int64_t) 16 * k_10148;\n                    x_10161 = i_10150 + binop_y_10160;\n                    as_transformed_row_loc_ind_10159 = x_10161;\n                } else {\n                    as_transformed_row_loc_ind_10159 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_10159) && slt64(as_transformed_row_loc_ind_10159, (int64_t) 128)) {\n                    ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10159] = futrts_to_bits16(as_transformed_row_elem_10154);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10199 = sext_i32_i64(local_tid_11354);\n        ltid_y_10198 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n        ltid_x_10197 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n        binop_x_10212 = (int64_t) 2 * ltid_y_10198;\n        binop_y_10217 = (int64_t) 2 * ltid_x_10197;\n        for (int64_t i_10202 = 0; i_10202 < (int64_t) 8; i_10202++) {\n            int64_t binop_y_10219 = (int64_t) 16 * i_10202;\n            \n            for (int64_t i_10206 = 0; i_10206 < (int64_t) 2; i_10206++) {\n                int64_t binop_x_10213;\n                int64_t binop_y_1", "0214;\n                int64_t defunc_0_map_res_loc_ind_64_10215;\n                f16 x_10431;\n                \n                binop_x_10213 = i_10206 + binop_x_10212;\n                binop_y_10214 = (int64_t) 8 * binop_x_10213;\n                defunc_0_map_res_loc_ind_64_10215 = i_10202 + binop_y_10214;\n                x_10431 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10215]);\n                for (int64_t i_10209 = 0; i_10209 < (int64_t) 2; i_10209++) {\n                    int64_t binop_x_10218;\n                    int64_t as_transformed_row_loc_ind_64_10220;\n                    f16 as_transformed_row_loc_elem_10221;\n                    f16 c_10222;\n                    f16 defunc_0_f_res_10225;\n                    f16 defunc_0_op_res_10228;\n                    \n                    binop_x_10218 = i_10209 + binop_y_10217;\n                    as_transformed_row_loc_ind_64_10220 = binop_x_10218 + binop_y_10219;\n                    as_transformed_row_loc_elem_10221 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10220]);\n                    c_10222 = mem_param_10614[i_10206 * (int64_t) 2 + i_10209];\n                    defunc_0_f_res_10225 = as_transformed_row_loc_elem_10221 * x_10431;\n                    defunc_0_op_res_10228 = c_10222 + defunc_0_f_res_10225;\n                    mem_param_10614[i_10206 * (int64_t) 2 + i_10209] = defunc_0_op_res_10228;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n            for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n                mem_10639[i_0 * (int64_t) 2 + i_1] = mem_param_10614[i_0 * (int64_t) 2 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < (int64_t) 2 * (int64_t) 2; i_3++)\n            mem_param_tmp_11372[i_3] = mem_10639[i_3];\n        for (int32_t i_4 = 0; i_4 < (int64_t) 2 * (int64_t) 2; i_4++)\n            mem_param_10614[i_4] =", " mem_param_tmp_11372[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < (int64_t) 2 * (int64_t) 2; i_5++)\n        ext_mem_10646[i_5] = mem_param_10614[i_5];\n    ltid_flat_10256 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11383 = 0; nest_i_11383 < (int64_t) 2; nest_i_11383++) {\n        for (int64_t nest_i_11384 = 0; nest_i_11384 < (int64_t) 1; nest_i_11384++) {\n            int64_t ltid_seq_10259;\n            int64_t ltid_seq_10260;\n            int64_t ltid_y_10257;\n            int64_t ltid_x_10258;\n            int64_t binop_y_10261;\n            int64_t k_10262;\n            int64_t binop_y_10263;\n            int64_t i_10264;\n            int64_t gtid_10265;\n            int64_t defunc_0_map_res_seqdim_idx_10266;\n            bool binop_x_10267;\n            bool binop_y_10268;\n            bool cond_10269;\n            f16 defunc_0_map_res_elem_10270;\n            bool cond_10274;\n            int64_t defunc_0_map_res_loc_ind_10275;\n            \n            ltid_seq_10259 = nest_i_11383;\n            ltid_seq_10260 = nest_i_11384;\n            ltid_y_10257 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10258 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10261 = (int64_t) 8 * ltid_seq_10260;\n            k_10262 = ltid_x_10258 + binop_y_10261;\n            binop_y_10263 = (int64_t) 8 * ltid_seq_10259;\n            i_10264 = ltid_y_10257 + binop_y_10263;\n            gtid_10265 = iii_10049 + i_10264;\n            defunc_0_map_res_seqdim_idx_10266 = kk_10234 + k_10262;\n            binop_x_10267 = slt64(gtid_10265, (int64_t) 16);\n            binop_y_10268 = slt64(defunc_0_map_res_seqdim_idx_10266, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n            cond_10269 = binop_x_10267 && binop_y_10268;\n            if (cond_10269) {\n                f16 A_elem_10272 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_7604 * one_intra_par_min_7480 + gtid_10265 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + defunc_0_map_res_seqdim_idx_10266]);\n          ",
                                    "      \n                defunc_0_map_res_elem_10270 = A_elem_10272;\n            } else {\n                defunc_0_map_res_elem_10270 = (f16) 0.0F;\n            }\n            cond_10274 = slt64(k_10262, (int64_t) 8);\n            if (cond_10274) {\n                int64_t binop_y_10276;\n                int64_t x_10277;\n                \n                binop_y_10276 = (int64_t) 8 * i_10264;\n                x_10277 = k_10262 + binop_y_10276;\n                defunc_0_map_res_loc_ind_10275 = x_10277;\n            } else {\n                defunc_0_map_res_loc_ind_10275 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10275) && slt64(defunc_0_map_res_loc_ind_10275, (int64_t) 128)) {\n                ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10275] = futrts_to_bits16(defunc_0_map_res_elem_10270);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10301 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11385 = 0; nest_i_11385 < (int64_t) 2; nest_i_11385++) {\n        for (int64_t nest_i_11386 = 0; nest_i_11386 < (int64_t) 1; nest_i_11386++) {\n            int64_t ltid_seq_10304;\n            int64_t ltid_seq_10305;\n            int64_t ltid_y_10302;\n            int64_t ltid_x_10303;\n            int64_t binop_y_10306;\n            int64_t k_10307;\n            int64_t binop_y_10308;\n            int64_t i_10309;\n            int64_t gtid_10310;\n            int64_t as_transformed_row_seqdim_idx_10311;\n            bool binop_x_10312;\n            bool binop_y_10313;\n            bool cond_10314;\n            f16 as_transformed_row_elem_10315;\n            bool cond_10319;\n            int64_t as_transformed_row_loc_ind_10320;\n            \n            ltid_seq_10304 = nest_i_11385;\n            ltid_seq_10305 = nest_i_11386;\n            ltid_y_10302 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10303 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10306 = (int64_t) 8 * l", "tid_seq_10305;\n            k_10307 = ltid_y_10302 + binop_y_10306;\n            binop_y_10308 = (int64_t) 8 * ltid_seq_10304;\n            i_10309 = ltid_x_10303 + binop_y_10308;\n            gtid_10310 = jjj_10050 + i_10309;\n            as_transformed_row_seqdim_idx_10311 = kk_10234 + k_10307;\n            binop_x_10312 = slt64(gtid_10310, (int64_t) 16);\n            binop_y_10313 = slt64(as_transformed_row_seqdim_idx_10311, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n            cond_10314 = binop_x_10312 && binop_y_10313;\n            if (cond_10314) {\n                f16 A_elem_10317 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10311 * (int64_t) 16 + gtid_10310]);\n                \n                as_transformed_row_elem_10315 = A_elem_10317;\n            } else {\n                as_transformed_row_elem_10315 = (f16) 0.0F;\n            }\n            cond_10319 = slt64(k_10307, (int64_t) 8);\n            if (cond_10319) {\n                int64_t binop_y_10321;\n                int64_t x_10322;\n                \n                binop_y_10321 = (int64_t) 16 * k_10307;\n                x_10322 = i_10309 + binop_y_10321;\n                as_transformed_row_loc_ind_10320 = x_10322;\n            } else {\n                as_transformed_row_loc_ind_10320 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_10320) && slt64(as_transformed_row_loc_ind_10320, (int64_t) 128)) {\n                ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10320] = futrts_to_bits16(as_transformed_row_elem_10315);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10362 = sext_i32_i64(local_tid_11354);\n    ltid_y_10361 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10360 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    binop_x_10377 = (int64_t) 2 * ltid_y_10361;\n    binop_y_10382 = (int64_t) 2 * ltid_x_10360;\n    for (int64_t i_10365 = 0; i_10365 < (int64_t) 8; i_10365++) {\n        ", "int64_t cmpop_x_10367;\n        bool cond_10368;\n        int64_t binop_y_10384;\n        \n        cmpop_x_10367 = kk_10234 + i_10365;\n        cond_10368 = slt64(cmpop_x_10367, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n        binop_y_10384 = (int64_t) 16 * i_10365;\n        if (cond_10368) {\n            for (int64_t i_10371 = 0; i_10371 < (int64_t) 2; i_10371++) {\n                int64_t binop_x_10378;\n                int64_t binop_y_10379;\n                int64_t defunc_0_map_res_loc_ind_64_10380;\n                f16 x_10428;\n                \n                binop_x_10378 = i_10371 + binop_x_10377;\n                binop_y_10379 = (int64_t) 8 * binop_x_10378;\n                defunc_0_map_res_loc_ind_64_10380 = i_10365 + binop_y_10379;\n                x_10428 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10380]);\n                for (int64_t i_10374 = 0; i_10374 < (int64_t) 2; i_10374++) {\n                    int64_t binop_x_10383;\n                    int64_t as_transformed_row_loc_ind_64_10385;\n                    f16 as_transformed_row_loc_elem_10386;\n                    f16 c_10387;\n                    f16 defunc_0_f_res_10390;\n                    f16 defunc_0_op_res_10393;\n                    \n                    binop_x_10383 = i_10374 + binop_y_10382;\n                    as_transformed_row_loc_ind_64_10385 = binop_x_10383 + binop_y_10384;\n                    as_transformed_row_loc_elem_10386 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10385]);\n                    c_10387 = ext_mem_10646[i_10371 * (int64_t) 2 + i_10374];\n                    defunc_0_f_res_10390 = as_transformed_row_loc_elem_10386 * x_10428;\n                    defunc_0_op_res_10393 = c_10387 + defunc_0_f_res_10390;\n                    ext_mem_10646[i_10371 * (int64_t) 2 + i_10374] = defunc_0_op_res_10393;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n        for (int64",
                                    "_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n            mem_10666[i_0 * (int64_t) 2 + i_1] = ext_mem_10646[i_0 * (int64_t) 2 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11393 = (int64_t) 8;\n    slice_11394 = (int64_t) 8 * slice_11393;\n    slice_11395 = slice_11394;\n    reg_tile_i_11390 = squot64(sext_i32_i64(local_tid_11354), slice_11394);\n    remnant_11396 = sext_i32_i64(local_tid_11354) - reg_tile_i_11390 * slice_11394;\n    reg_tile_i_11391 = squot64(remnant_11396, slice_11393);\n    remnant_11397 = remnant_11396 - reg_tile_i_11391 * slice_11393;\n    reg_tile_i_11392 = remnant_11397;\n    remnant_11398 = remnant_11397 - reg_tile_i_11392;\n    tile_dim_start_11399 = gtid_7604 + reg_tile_i_11390;\n    tile_dim_start_11400 = (int64_t) 2 * ((int64_t) 8 * gid_y_10046 + reg_tile_i_11391);\n    tile_dim_start_11401 = (int64_t) 2 * ((int64_t) 8 * gid_x_10047 + reg_tile_i_11392);\n    for (int64_t nest_i_11402 = 0; nest_i_11402 < (int64_t) 1; nest_i_11402++) {\n        for (int64_t nest_i_11403 = 0; nest_i_11403 < (int64_t) 2; nest_i_11403++) {\n            for (int64_t nest_i_11404 = 0; nest_i_11404 < (int64_t) 2; nest_i_11404++) {\n                if ((slt64(tile_dim_start_11399 + nest_i_11402, m_6594) && slt64(tile_dim_start_11400 + nest_i_11403, (int64_t) 16)) && slt64(tile_dim_start_11401 + nest_i_11404, (int64_t) 16)) {\n                    f16 tmp_11405 = mem_10666[nest_i_11403 * (int64_t) 2 + nest_i_11404];\n                    \n                    ((__global uint16_t *) mem_10670)[(tile_dim_start_11399 + nest_i_11402) * (int64_t) 256 + (tile_dim_start_11400 + nest_i_11403) * (int64_t) 16 + (tile_dim_start_11401 + nest_i_11404)] = futrts_to_bits16(tmp_11405);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n}\nFUTHARK_KERNEL\nvoid run16zisegmap_intrablock_7080(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t one_intra_par_min_7002, int64_t bytes_10743, __global unsigned char *Q_mem_", "10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10749)\n{\n    volatile __local unsigned char *red_arr_mem_11089_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11089_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11070_backing_2 = &shared_mem[red_arr_mem_11089_backing_3_offset];\n    const int64_t red_arr_mem_11070_backing_2_offset = red_arr_mem_11089_backing_3_offset + ((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10858_backing_1 = &shared_mem[red_arr_mem_11070_backing_2_offset];\n    const int64_t color_10858_backing_1_offset = red_arr_mem_11070_backing_2_offset + (bytes_10743 + srem64((int64_t) 8 - srem64(bytes_10743, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10857_backing_0 = &shared_mem[color_10858_backing_1_offset];\n    const int64_t color_10857_backing_0_offset = color_10858_backing_1_offset + (int64_t) 512;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11046;\n    int32_t tblock_sizze_11049;\n    int32_t wave_sizze_11048;\n    int32_t block_id_11047;\n    int32_t global_tid_11045;\n    int64_t phys_tblock_id_7080;\n    int64_t slice_11053;\n    int64_t slice_11054;\n    int64_t slice_11055;\n    int64_t ltid_pre_11050;\n    int64_t remnant_11056;\n    int64_t ltid_pre_11051;\n    int64_t remnant_11057;\n    int64_t ltid_pre_11052;\n    int64_t remnant_11058;\n    int64_t slice_11062;\n    int64_t slice_11063;\n    int64_t slice_11064;\n    int64_t ltid_pre_11059;\n    int64_t remnant_11065;\n    int64_t ltid_pre_11060", ";\n    int64_t remnant_11066;\n    int64_t ltid_pre_11061;\n    int64_t remnant_11067;\n    int64_t slice_11068;\n    int64_t gtid_7079;\n    int64_t remnant_11069;\n    __local unsigned char *color_10857;\n    __local unsigned char *color_10858;\n    int64_t phys_tid_7087;\n    __local unsigned char *red_arr_mem_11070;\n    int64_t gtid_7084;\n    int64_t gtid_7085;\n    int64_t gtid_7086;\n    int64_t dims_flat_11072;\n    f16 eta_p_7088;\n    f16 eta_p_7089;\n    f16 eta_p_11074;\n    f16 eta_p_11075;\n    bool ltid_in_bounds_11077;\n    int32_t skip_threads_11078;\n    bool no_carry_in_11084;\n    int64_t phys_tid_7100;\n    __local unsigned char *red_arr_mem_11089;\n    int64_t gtid_7097;\n    int64_t gtid_7098;\n    int64_t gtid_7099;\n    int64_t dims_flat_11091;\n    f16 eta_p_7101;\n    f16 eta_p_7102;\n    f16 eta_p_11093;\n    f16 eta_p_11094;\n    bool ltid_in_bounds_11096;\n    int32_t skip_threads_11097;\n    bool no_carry_in_11103;\n    int32_t num_chunks_11108;\n    \n    local_tid_11046 = get_local_id(0);\n    tblock_sizze_11049 = get_local_size(0);\n    wave_sizze_11048 = LOCKSTEP_WIDTH;\n    block_id_11047 = get_tblock_id(0);\n    global_tid_11045 = block_id_11047 * tblock_sizze_11049 + local_tid_11046;\n    phys_tblock_id_7080 = sext_i32_i64(block_id_11047);\n    slice_11053 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;\n    slice_11054 = (int64_t) 16 * slice_11053;\n    slice_11055 = (int64_t) 16 * slice_11054;\n    ltid_pre_11050 = squot64(sext_i32_i64(local_tid_11046), slice_11054);\n    remnant_11056 = sext_i32_i64(local_tid_11046) - ltid_pre_11050 * slice_11054;\n    ltid_pre_11051 = squot64(remnant_11056, slice_11053);\n    remnant_11057 = remnant_11056 - ltid_pre_11051 * slice_11053;\n    ltid_pre_11052 = remnant_11057;\n    remnant_11058 = remnant_11057 - ltid_pre_11052;\n    slice_11062 = (int64_t) 16;\n    slice_11063 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * slice_11062;\n    slice_11064 = (int64_t) 16 * slice_11063;\n    ltid_pre_11059 = squot64(sext_i32_i64(local_tid_11046), slice_11063);\n    rem",
                                    "nant_11065 = sext_i32_i64(local_tid_11046) - ltid_pre_11059 * slice_11063;\n    ltid_pre_11060 = squot64(remnant_11065, slice_11062);\n    remnant_11066 = remnant_11065 - ltid_pre_11060 * slice_11062;\n    ltid_pre_11061 = remnant_11066;\n    remnant_11067 = remnant_11066 - ltid_pre_11061;\n    slice_11068 = m_6594;\n    gtid_7079 = sext_i32_i64(block_id_11047);\n    remnant_11069 = sext_i32_i64(block_id_11047) - gtid_7079;\n    color_10857 = (__local unsigned char *) color_10857_backing_0;\n    color_10858 = (__local unsigned char *) color_10858_backing_1;\n    phys_tid_7087 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11070 = (__local unsigned char *) red_arr_mem_11070_backing_2;\n    gtid_7084 = sext_i32_i64(sext_i64_i32(ltid_pre_11059));\n    gtid_7085 = sext_i32_i64(sext_i64_i32(ltid_pre_11060));\n    gtid_7086 = sext_i32_i64(sext_i64_i32(ltid_pre_11061));\n    if ((slt64(gtid_7084, (int64_t) 16) && slt64(gtid_7085, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) && slt64(gtid_7086, (int64_t) 16)) {\n        f16 eta_p_7093;\n        f16 eta_p_7094;\n        f16 defunc_0_f_res_7095;\n        \n        eta_p_7093 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7079 * (int64_t) 256 + gtid_7084 * (int64_t) 16 + gtid_7086]);\n        eta_p_7094 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_7085 * (int64_t) 16 + gtid_7086]);\n        defunc_0_f_res_7095 = eta_p_7093 * eta_p_7094;\n        ((__local uint16_t *) red_arr_mem_11070)[gtid_7084 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) + gtid_7085 * (int64_t) 16 + gtid_7086] = futrts_to_bits16(defunc_0_f_res_7095);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11072 = (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16;\n    ltid_in_bounds_11077 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11077) {\n            eta_p_7089 = futrts_from_bits16(((volatile __loca", "l uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_7088 = eta_p_7089;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11078 = 1;\n        while (slt32(skip_threads_11078, 32)) {\n            bool thread_active_11079 = sle32(skip_threads_11078, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11077;\n            \n            if (thread_active_11079) {\n                // read operands\n                {\n                    eta_p_7088 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11078)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11080 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 16), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11078));\n                \n                if (thread_active_11079 && inactive_11080) {\n                    eta_p_7088 = eta_p_7089;\n                }\n                if (thread_active_11079) {\n                    if (!inactive_11080) {\n                        f16 defunc_0_op_res_7090 = eta_p_7088 + eta_p_7089;\n                        \n                        eta_p_7088 = defunc_0_op_res_7090;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11079) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7088);\n                    eta_p_7089 = eta_p_7088;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE)", ";\n            }\n            skip_threads_11078 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11077) {\n            ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_7088);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11081;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n                eta_p_11075 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11074 = eta_p_11075;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11081 = 1;\n            while (slt32(skip_threads_11081, 32)) {\n                bool thread_active_11082 = sle32(skip_threads_11081, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077);\n                \n                if (thread_active_11082) {\n                    // read operands\n                    {\n                        eta_p_11074 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11081)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11083 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), (int64_t) 16), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11081) * 32 + 32 - 1));\n              ",
                                    "      \n                    if (thread_active_11082 && inactive_11083) {\n                        eta_p_11074 = eta_p_11075;\n                    }\n                    if (thread_active_11082) {\n                        if (!inactive_11083) {\n                            f16 defunc_0_op_res_11076 = eta_p_11074 + eta_p_11075;\n                            \n                            eta_p_11074 = defunc_0_op_res_11076;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11082) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11074);\n                        eta_p_11075 = eta_p_11074;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11081 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11084 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11077;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11084) {\n                eta_p_7089 = eta_p_7088;\n                eta_p_7088 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11085 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 16), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11084) {\n                if (inactive_11085) {\n                    eta_p_7088 = eta_p_7089;\n                }\n            }\n   ", "         if (!no_carry_in_11084) {\n                if (!inactive_11085) {\n                    f16 defunc_0_op_res_7090 = eta_p_7088 + eta_p_7089;\n                    \n                    eta_p_7088 = defunc_0_op_res_7090;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11084) {\n                ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7088);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n            ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7089);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11086 = sdiv_up32(16 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i64_i32(one_intra_par_min_7002));\n        \n        for (int32_t chunk_i_11087 = 0; chunk_i_11087 < num_chunks_11086; chunk_i_11087++) {\n            int32_t i_11088 = chunk_i_11087 * sext_i64_i32(one_intra_par_min_7002) + local_tid_11046;\n            \n            if (slt32(i_11088, 16 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595))) {\n                ((__local uint16_t *) color_10858)[sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595))) * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) * sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595))] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[(int64_t) 15 + sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595))) * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) * sext_i64_i32(dzlz7b", "UZLztZRz20Umz20U16z7dUzg_6595)) * (int64_t) 16]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_7100 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11089 = (__local unsigned char *) red_arr_mem_11089_backing_3;\n    gtid_7097 = sext_i32_i64(sext_i64_i32(ltid_pre_11050));\n    gtid_7098 = sext_i32_i64(sext_i64_i32(ltid_pre_11051));\n    gtid_7099 = sext_i32_i64(sext_i64_i32(ltid_pre_11052));\n    if ((slt64(gtid_7097, (int64_t) 16) && slt64(gtid_7098, (int64_t) 16)) && slt64(gtid_7099, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) {\n        f16 eta_p_7106;\n        f16 eta_p_7107;\n        f16 defunc_0_f_res_7108;\n        \n        eta_p_7106 = futrts_from_bits16(((__local uint16_t *) color_10858)[gtid_7097 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7099]);\n        eta_p_7107 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_7099 * (int64_t) 16 + gtid_7098]);\n        defunc_0_f_res_7108 = eta_p_7106 * eta_p_7107;\n        ((__local uint16_t *) red_arr_mem_11089)[gtid_7097 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + gtid_7098 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7099] = futrts_to_bits16(defunc_0_f_res_7108);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11091 = (int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;\n    ltid_in_bounds_11096 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11096) {\n            eta_p_7102 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_7101 = eta_p_7102;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11097 = 1;\n        while (slt32(skip_threads_11097, 32)) {\n            bool thread_active_11098 = sle32(skip_threads_11",
                                    "097, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11096;\n            \n            if (thread_active_11098) {\n                // read operands\n                {\n                    eta_p_7101 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11097)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11099 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11097));\n                \n                if (thread_active_11098 && inactive_11099) {\n                    eta_p_7101 = eta_p_7102;\n                }\n                if (thread_active_11098) {\n                    if (!inactive_11099) {\n                        f16 defunc_0_op_res_7103 = eta_p_7101 + eta_p_7102;\n                        \n                        eta_p_7101 = defunc_0_op_res_7103;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11098) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7101);\n                    eta_p_7102 = eta_p_7101;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11097 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11096) {\n            ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_", "bits16(eta_p_7101);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11100;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n                eta_p_11094 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11093 = eta_p_11094;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11100 = 1;\n            while (slt32(skip_threads_11100, 32)) {\n                bool thread_active_11101 = sle32(skip_threads_11100, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096);\n                \n                if (thread_active_11101) {\n                    // read operands\n                    {\n                        eta_p_11093 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11100)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11102 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11100) * 32 + 32 - 1));\n                    \n                    if (thread_active_11101 && inactive_11102) {\n                        eta_p_11093 = eta_p_11094;\n                    }\n                    if (thread_active_11101) {\n                        if (!inactive_11102) {\n                            f16 defunc_0_op_res_11095 = eta_p_11093 + eta_p_11094;\n                            \n                ", "            eta_p_11093 = defunc_0_op_res_11095;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11101) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11093);\n                        eta_p_11094 = eta_p_11093;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11100 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11103 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11096;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11103) {\n                eta_p_7102 = eta_p_7101;\n                eta_p_7101 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11104 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11103) {\n                if (inactive_11104) {\n                    eta_p_7101 = eta_p_7102;\n                }\n            }\n            if (!no_carry_in_11103) {\n                if (!inactive_11104) {\n                    f16 defunc_0_op_res_7103 = eta_p_7101 + eta_p_7102;\n                    \n                    eta_p_7101 = defunc_0_op_res_7103;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11103) {\n  ",
                                    "              ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7101);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n            ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7102);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11105 = sdiv_up32(256, sext_i64_i32(one_intra_par_min_7002));\n        \n        for (int32_t chunk_i_11106 = 0; chunk_i_11106 < num_chunks_11105; chunk_i_11106++) {\n            int32_t i_11107 = chunk_i_11106 * sext_i64_i32(one_intra_par_min_7002) + local_tid_11046;\n            \n            if (slt32(i_11107, 256)) {\n                ((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11107, 16)) * (int64_t) 16 + sext_i32_i64(i_11107 - squot32(i_11107, 16) * 16)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 - (int64_t) 1 + sext_i32_i64(squot32(i_11107, 16)) * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + sext_i32_i64(i_11107 - squot32(i_11107, 16) * 16) * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11108 = sdiv_up32(256, sext_i64_i32(one_intra_par_min_7002));\n    for (int32_t chunk_i_11109 = 0; chunk_i_11109 < num_chunks_11108; chunk_i_11109++) {\n        int32_t i_11110 = chunk_i_11109 * sext_i64_i32(one_intra_par_min_7002) + local_tid_11046;\n        \n        if (slt32(i_11110, 256)) {\n            ((__global uint16_t *) mem_10749)[gtid_7079 * (int64_t) 256 + sext_i32_i64(squot32(i_11110, 16)) * (int64_t) 16 + sext_i32_i64(i_11110 - squot32(i_11110, 16) * 16)] = futrts_to_bits16(futrts_from_bits16(((__local uint1", "6_t *) color_10857)[sext_i32_i64(squot32(i_11110, 16)) * (int64_t) 16 + sext_i32_i64(i_11110 - squot32(i_11110, 16) * 16)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL\nvoid run16zisegmap_intrablock_7521(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t one_intra_par_min_7480, int64_t bytes_10673, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10679)\n{\n    volatile __local unsigned char *red_arr_mem_11173_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11173_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11154_backing_2 = &shared_mem[red_arr_mem_11173_backing_3_offset];\n    const int64_t red_arr_mem_11154_backing_2_offset = red_arr_mem_11173_backing_3_offset + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10861_backing_1 = &shared_mem[red_arr_mem_11154_backing_2_offset];\n    const int64_t color_10861_backing_1_offset = red_arr_mem_11154_backing_2_offset + (bytes_10673 + srem64((int64_t) 8 - srem64(bytes_10673, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10860_backing_0 = &shared_mem[color_10861_backing_1_offset];\n    const int64_t color_10860_backing_0_offset = color_10861_backing_1_offset + (int64_t) 32;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11134;\n    int32_t tblock_sizze_11137;\n    int32_t wave_sizze_11136;\n    int32_t block_id_11135;\n    int32_t global_tid_11133;\n    int64_t phys_tblock_id_7521;", "\n    int64_t slice_11140;\n    int64_t slice_11141;\n    int64_t ltid_pre_11138;\n    int64_t remnant_11142;\n    int64_t ltid_pre_11139;\n    int64_t remnant_11143;\n    int64_t slice_11146;\n    int64_t slice_11147;\n    int64_t ltid_pre_11144;\n    int64_t remnant_11148;\n    int64_t ltid_pre_11145;\n    int64_t remnant_11149;\n    int64_t slice_11150;\n    int64_t slice_11151;\n    int64_t gtid_7519;\n    int64_t remnant_11152;\n    int64_t gtid_7520;\n    int64_t remnant_11153;\n    __local unsigned char *color_10860;\n    __local unsigned char *color_10861;\n    int64_t phys_tid_7527;\n    __local unsigned char *red_arr_mem_11154;\n    int64_t gtid_7525;\n    int64_t gtid_7526;\n    int64_t dims_flat_11156;\n    f16 eta_p_7528;\n    f16 eta_p_7529;\n    f16 eta_p_11158;\n    f16 eta_p_11159;\n    bool ltid_in_bounds_11161;\n    int32_t skip_threads_11162;\n    bool no_carry_in_11168;\n    int64_t phys_tid_7538;\n    __local unsigned char *red_arr_mem_11173;\n    int64_t gtid_7536;\n    int64_t gtid_7537;\n    int64_t dims_flat_11175;\n    f16 eta_p_7539;\n    f16 eta_p_7540;\n    f16 eta_p_11177;\n    f16 eta_p_11178;\n    bool ltid_in_bounds_11180;\n    int32_t skip_threads_11181;\n    bool no_carry_in_11187;\n    int32_t num_chunks_11192;\n    \n    local_tid_11134 = get_local_id(0);\n    tblock_sizze_11137 = get_local_size(0);\n    wave_sizze_11136 = LOCKSTEP_WIDTH;\n    block_id_11135 = get_tblock_id(0);\n    global_tid_11133 = block_id_11135 * tblock_sizze_11137 + local_tid_11134;\n    phys_tblock_id_7521 = sext_i32_i64(block_id_11135);\n    slice_11140 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;\n    slice_11141 = (int64_t) 16 * slice_11140;\n    ltid_pre_11138 = squot64(sext_i32_i64(local_tid_11134), slice_11140);\n    remnant_11142 = sext_i32_i64(local_tid_11134) - ltid_pre_11138 * slice_11140;\n    ltid_pre_11139 = remnant_11142;\n    remnant_11143 = remnant_11142 - ltid_pre_11139;\n    slice_11146 = (int64_t) 16;\n    slice_11147 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * slice_11146;\n    ltid_pre_11144 = squot64(se",
                                    "xt_i32_i64(local_tid_11134), slice_11146);\n    remnant_11148 = sext_i32_i64(local_tid_11134) - ltid_pre_11144 * slice_11146;\n    ltid_pre_11145 = remnant_11148;\n    remnant_11149 = remnant_11148 - ltid_pre_11145;\n    slice_11150 = (int64_t) 16;\n    slice_11151 = m_6594 * slice_11150;\n    gtid_7519 = squot64(sext_i32_i64(block_id_11135), slice_11150);\n    remnant_11152 = sext_i32_i64(block_id_11135) - gtid_7519 * slice_11150;\n    gtid_7520 = remnant_11152;\n    remnant_11153 = remnant_11152 - gtid_7520;\n    color_10860 = (__local unsigned char *) color_10860_backing_0;\n    color_10861 = (__local unsigned char *) color_10861_backing_1;\n    phys_tid_7527 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_11154 = (__local unsigned char *) red_arr_mem_11154_backing_2;\n    gtid_7525 = sext_i32_i64(sext_i64_i32(ltid_pre_11144));\n    gtid_7526 = sext_i32_i64(sext_i64_i32(ltid_pre_11145));\n    if (slt64(gtid_7525, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) && slt64(gtid_7526, (int64_t) 16)) {\n        f16 eta_p_7532;\n        f16 eta_p_7533;\n        f16 defunc_0_f_res_7534;\n        \n        eta_p_7532 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7519 * (int64_t) 256 + gtid_7520 * (int64_t) 16 + gtid_7526]);\n        eta_p_7533 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_7525 * (int64_t) 16 + gtid_7526]);\n        defunc_0_f_res_7534 = eta_p_7532 * eta_p_7533;\n        ((__local uint16_t *) red_arr_mem_11154)[gtid_7525 * (int64_t) 16 + gtid_7526] = futrts_to_bits16(defunc_0_f_res_7534);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11156 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16;\n    ltid_in_bounds_11161 = slt64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11161) {\n            eta_p_7529 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot3", "2(local_tid_11134, 32) * 32) == 0) {\n                eta_p_7528 = eta_p_7529;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11162 = 1;\n        while (slt32(skip_threads_11162, 32)) {\n            bool thread_active_11163 = sle32(skip_threads_11162, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11161;\n            \n            if (thread_active_11163) {\n                // read operands\n                {\n                    eta_p_7528 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11162)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11164 = slt64(srem64(sext_i32_i64(local_tid_11134), (int64_t) 16), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11162));\n                \n                if (thread_active_11163 && inactive_11164) {\n                    eta_p_7528 = eta_p_7529;\n                }\n                if (thread_active_11163) {\n                    if (!inactive_11164) {\n                        f16 defunc_0_op_res_7530 = eta_p_7528 + eta_p_7529;\n                        \n                        eta_p_7528 = defunc_0_op_res_7530;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11163) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_7528);\n                    eta_p_7529 = eta_p_7528;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11162 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ", "// last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11161) {\n            ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_7528);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11165;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n                eta_p_11159 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11158 = eta_p_11159;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11165 = 1;\n            while (slt32(skip_threads_11165, 32)) {\n                bool thread_active_11166 = sle32(skip_threads_11165, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161);\n                \n                if (thread_active_11166) {\n                    // read operands\n                    {\n                        eta_p_11158 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11165)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11167 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), (int64_t) 16), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11165) * 32 + 32 - 1));\n                    \n                    if (thread_active_11166 && inactive_11167) {\n                        eta_p_11158",
                                    " = eta_p_11159;\n                    }\n                    if (thread_active_11166) {\n                        if (!inactive_11167) {\n                            f16 defunc_0_op_res_11160 = eta_p_11158 + eta_p_11159;\n                            \n                            eta_p_11158 = defunc_0_op_res_11160;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11166) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11158);\n                        eta_p_11159 = eta_p_11158;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11165 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11168 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11161;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11168) {\n                eta_p_7529 = eta_p_7528;\n                eta_p_7528 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11169 = slt64(srem64(sext_i32_i64(local_tid_11134), (int64_t) 16), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11168) {\n                if (inactive_11169) {\n                    eta_p_7528 = eta_p_7529;\n                }\n            }\n            if (!no_carry_in_11168) {\n                if (!inactive_11169) {\n                    f16 defunc_0_", "op_res_7530 = eta_p_7528 + eta_p_7529;\n                    \n                    eta_p_7528 = defunc_0_op_res_7530;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11168) {\n                ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_7528);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n            ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_7529);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11170 = sdiv_up32(sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i64_i32(one_intra_par_min_7480));\n        \n        for (int32_t chunk_i_11171 = 0; chunk_i_11171 < num_chunks_11170; chunk_i_11171++) {\n            int32_t i_11172 = chunk_i_11171 * sext_i64_i32(one_intra_par_min_7480) + local_tid_11134;\n            \n            if (slt32(i_11172, sext_i64_i32(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595))) {\n                ((__local uint16_t *) color_10861)[sext_i32_i64(i_11172)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[(int64_t) 15 + sext_i32_i64(i_11172) * (int64_t) 16]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_7538 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_11173 = (__local unsigned char *) red_arr_mem_11173_backing_3;\n    gtid_7536 = sext_i32_i64(sext_i64_i32(ltid_pre_11138));\n    gtid_7537 = sext_i32_i64(sext_i64_i32(ltid_pre_11139));\n    if (slt64(gtid_7536, (int64_t) 16) && slt64(gtid_7537, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) {\n        f16 eta_p_7543;\n        f16 eta_p_7544;\n        f16 defunc_0_f_res_7545;\n        \n        eta_p_7543 = futrts_fr", "om_bits16(((__local uint16_t *) color_10861)[gtid_7537]);\n        eta_p_7544 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_7537 * (int64_t) 16 + gtid_7536]);\n        defunc_0_f_res_7545 = eta_p_7543 * eta_p_7544;\n        ((__local uint16_t *) red_arr_mem_11173)[gtid_7536 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7537] = futrts_to_bits16(defunc_0_f_res_7545);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11175 = (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;\n    ltid_in_bounds_11180 = slt64(sext_i32_i64(local_tid_11134), (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11180) {\n            eta_p_7540 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_7539 = eta_p_7540;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11181 = 1;\n        while (slt32(skip_threads_11181, 32)) {\n            bool thread_active_11182 = sle32(skip_threads_11181, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11180;\n            \n            if (thread_active_11182) {\n                // read operands\n                {\n                    eta_p_7539 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11181)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11183 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11181));\n                \n                if (thread_active_11182 && inactive_11183) {\n                    eta_p_7539 = eta_p_7540;\n                }\n                if (thread_active_11182) {\n             ",
                                    "       if (!inactive_11183) {\n                        f16 defunc_0_op_res_7541 = eta_p_7539 + eta_p_7540;\n                        \n                        eta_p_7539 = defunc_0_op_res_7541;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11182) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_7539);\n                    eta_p_7540 = eta_p_7539;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11181 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11180) {\n            ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_7539);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11184;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n                eta_p_11178 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11177 = eta_p_11178;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11184 = 1;\n            while (slt32(skip_threads_11184, 32)) {\n                bool thread_active_11185 = sle", "32(skip_threads_11184, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180);\n                \n                if (thread_active_11185) {\n                    // read operands\n                    {\n                        eta_p_11177 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11184)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11186 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11184) * 32 + 32 - 1));\n                    \n                    if (thread_active_11185 && inactive_11186) {\n                        eta_p_11177 = eta_p_11178;\n                    }\n                    if (thread_active_11185) {\n                        if (!inactive_11186) {\n                            f16 defunc_0_op_res_11179 = eta_p_11177 + eta_p_11178;\n                            \n                            eta_p_11177 = defunc_0_op_res_11179;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11185) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11177);\n                        eta_p_11178 = eta_p_11177;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11184 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_1", "1187 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11180;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11187) {\n                eta_p_7540 = eta_p_7539;\n                eta_p_7539 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11188 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11187) {\n                if (inactive_11188) {\n                    eta_p_7539 = eta_p_7540;\n                }\n            }\n            if (!no_carry_in_11187) {\n                if (!inactive_11188) {\n                    f16 defunc_0_op_res_7541 = eta_p_7539 + eta_p_7540;\n                    \n                    eta_p_7539 = defunc_0_op_res_7541;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11187) {\n                ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_7539);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n            ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_7540);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11189 = sdiv_up32(16, sext_i64_i32(one_intra_par_min_7480));\n        \n        for (int32_t chunk_i_11190 = 0; chunk_i_11190 < num_chunks_11189; chunk_i_11190++) {\n            int32_t i_11191 = chunk_i_11190 * sext_i64_i32(one_intra_par_min_7480) + local_tid_11134;",
                                    "\n            \n            if (slt32(i_11191, 16)) {\n                ((__local uint16_t *) color_10860)[sext_i32_i64(i_11191)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 - (int64_t) 1 + sext_i32_i64(i_11191) * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11192 = sdiv_up32(16, sext_i64_i32(one_intra_par_min_7480));\n    for (int32_t chunk_i_11193 = 0; chunk_i_11193 < num_chunks_11192; chunk_i_11193++) {\n        int32_t i_11194 = chunk_i_11193 * sext_i64_i32(one_intra_par_min_7480) + local_tid_11134;\n        \n        if (slt32(i_11194, 16)) {\n            ((__global uint16_t *) mem_10679)[gtid_7519 * (int64_t) 256 + gtid_7520 * (int64_t) 16 + sext_i32_i64(i_11194)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10860)[sext_i32_i64(i_11194)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run16zisegmap_intrablock_9688_dim1, 1, 1)\nvoid run16zisegmap_intrablock_9688(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t gridDim_x_9682, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10565)\n{\n    volatile __local unsigned char *color_10863_backing_1 = &shared_mem[0];\n    const int64_t color_10863_backing_1_offset = 0 + (int64_t) 256;\n    volatile __local unsigned char *color_10862_backing_0 = &shared_mem[color_10863_backing_1_offset];\n    const int64_t color_10862_backing_0_offset = color_10863_backing_1_offset + (int64_t) 288;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11198;\n    int32_t tblock_sizze_11201;\n    int32_t wave_sizze_11200;\n    int32_t block_id_11199;\n    int32_t global_tid_11197;\n    int64_t gid_flat_9688;\n    int64_t slice_11204;\n    int64_t slice_11205;\n    int64_t ltid_pre", "_11202;\n    int64_t remnant_11206;\n    int64_t ltid_pre_11203;\n    int64_t remnant_11207;\n    int64_t slice_11208;\n    int64_t slice_11209;\n    int64_t slice_11210;\n    int64_t gtid_7557;\n    int64_t remnant_11211;\n    int64_t gid_y_9686;\n    int64_t remnant_11212;\n    int64_t gid_x_9687;\n    int64_t remnant_11213;\n    __local unsigned char *color_10862;\n    __local unsigned char *color_10863;\n    int64_t iii_9689;\n    int64_t jjj_9690;\n    f16 mem_10506[(int64_t) 2 * (int64_t) 2];\n    int64_t ltid_flat_9704;\n    int64_t ltid_y_9703;\n    int64_t ltid_x_9702;\n    f16 mem_10489[(int64_t) 2 * (int64_t) 2];\n    f16 ext_mem_10541[(int64_t) 2 * (int64_t) 2];\n    f16 mem_param_10509[(int64_t) 2 * (int64_t) 2];\n    int64_t ltid_flat_9896;\n    int64_t ltid_flat_9941;\n    f16 mem_10561[(int64_t) 2 * (int64_t) 2];\n    int64_t ltid_flat_10002;\n    int64_t ltid_y_10001;\n    int64_t ltid_x_10000;\n    int64_t binop_x_10017;\n    int64_t binop_x_10022;\n    int64_t slice_11237;\n    int64_t slice_11238;\n    int64_t slice_11239;\n    int64_t reg_tile_i_11234;\n    int64_t remnant_11240;\n    int64_t reg_tile_i_11235;\n    int64_t remnant_11241;\n    int64_t reg_tile_i_11236;\n    int64_t remnant_11242;\n    int64_t tile_dim_start_11243;\n    int64_t tile_dim_start_11244;\n    int64_t tile_dim_start_11245;\n    \n    local_tid_11198 = get_local_id(0);\n    tblock_sizze_11201 = get_local_size(0);\n    wave_sizze_11200 = LOCKSTEP_WIDTH;\n    block_id_11199 = get_tblock_id(0);\n    global_tid_11197 = block_id_11199 * tblock_sizze_11201 + local_tid_11198;\n    gid_flat_9688 = sext_i32_i64(block_id_11199);\n    slice_11204 = (int64_t) 8;\n    slice_11205 = (int64_t) 8 * slice_11204;\n    ltid_pre_11202 = squot64(sext_i32_i64(local_tid_11198), slice_11204);\n    remnant_11206 = sext_i32_i64(local_tid_11198) - ltid_pre_11202 * slice_11204;\n    ltid_pre_11203 = remnant_11206;\n    remnant_11207 = remnant_11206 - ltid_pre_11203;\n    slice_11208 = gridDim_x_9682;\n    slice_11209 = slice_11208;\n    slice_11210 = m_659", "4 * slice_11209;\n    gtid_7557 = squot64(sext_i32_i64(block_id_11199), slice_11209);\n    remnant_11211 = sext_i32_i64(block_id_11199) - gtid_7557 * slice_11209;\n    gid_y_9686 = squot64(remnant_11211, slice_11208);\n    remnant_11212 = remnant_11211 - gid_y_9686 * slice_11208;\n    gid_x_9687 = remnant_11212;\n    remnant_11213 = remnant_11212 - gid_x_9687;\n    color_10862 = (__local unsigned char *) color_10862_backing_0;\n    color_10863 = (__local unsigned char *) color_10863_backing_1;\n    iii_9689 = (int64_t) 16 * gid_y_9686;\n    jjj_9690 = (int64_t) 16 * gid_x_9687;\n    ltid_flat_9704 = sext_i32_i64(local_tid_11198);\n    ltid_y_9703 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_9702 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    for (int64_t i_9707 = 0; i_9707 < (int64_t) 2; i_9707++) {\n        for (int64_t i_9710 = 0; i_9710 < (int64_t) 2; i_9710++) {\n            mem_10489[i_9707 * (int64_t) 2 + i_9710] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n            mem_10506[i_0 * (int64_t) 2 + i_1] = mem_10489[i_0 * (int64_t) 2 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < (int64_t) 2 * (int64_t) 2; i_2++)\n        mem_param_10509[i_2] = mem_10506[i_2];\n    for (int64_t i_9717 = 0; i_9717 < (int64_t) 2; i_9717++) {\n        int64_t kk_9721;\n        int64_t ltid_flat_9741;\n        int64_t ltid_flat_9782;\n        f16 mem_10534[(int64_t) 2 * (int64_t) 2];\n        int64_t ltid_flat_9839;\n        int64_t ltid_y_9838;\n        int64_t ltid_x_9837;\n        int64_t binop_x_9852;\n        int64_t binop_x_9857;\n        f16 mem_param_tmp_11216[(int64_t) 2 * (int64_t) 2];\n        \n        kk_9721 = (int64_t) 8 * i_9717;\n        ltid_flat_9741 = sext_i32_i64(local_tid_11198);\n        for (int64_t nest_i_11220 = 0; nest_i_11220 < (int64_t) 2; nest_i_11220++) {\n            for (int64_t nest_i_11221 = ",
                                    "0; nest_i_11221 < (int64_t) 1; nest_i_11221++) {\n                int64_t ltid_seq_9744;\n                int64_t ltid_seq_9745;\n                int64_t ltid_y_9742;\n                int64_t ltid_x_9743;\n                int64_t binop_y_9746;\n                int64_t k_9747;\n                int64_t binop_y_9748;\n                int64_t i_9749;\n                int64_t gtid_9750;\n                int64_t as_transformed_row_seqdim_idx_9751;\n                bool cond_9752;\n                f16 as_transformed_row_elem_9753;\n                bool cond_9757;\n                int64_t as_transformed_row_loc_ind_9758;\n                \n                ltid_seq_9744 = nest_i_11220;\n                ltid_seq_9745 = nest_i_11221;\n                ltid_y_9742 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9743 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9746 = (int64_t) 8 * ltid_seq_9745;\n                k_9747 = ltid_x_9743 + binop_y_9746;\n                binop_y_9748 = (int64_t) 8 * ltid_seq_9744;\n                i_9749 = ltid_y_9742 + binop_y_9748;\n                gtid_9750 = iii_9689 + i_9749;\n                as_transformed_row_seqdim_idx_9751 = kk_9721 + k_9747;\n                cond_9752 = slt64(gtid_9750, (int64_t) 16);\n                if (cond_9752) {\n                    f16 A_elem_9755 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7557 * (int64_t) 256 + gtid_9750 * (int64_t) 16 + as_transformed_row_seqdim_idx_9751]);\n                    \n                    as_transformed_row_elem_9753 = A_elem_9755;\n                } else {\n                    as_transformed_row_elem_9753 = (f16) 0.0F;\n                }\n                cond_9757 = slt64(k_9747, (int64_t) 8);\n                if (cond_9757) {\n                    int64_t binop_y_9759;\n                    int64_t x_9760;\n                    \n                    binop_y_9759 = (int64_t) 8 * i_9749;\n                    x_9760 = k_9747 + binop_y_9759;\n                    as_tr", "ansformed_row_loc_ind_9758 = x_9760;\n                } else {\n                    as_transformed_row_loc_ind_9758 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9758) && slt64(as_transformed_row_loc_ind_9758, (int64_t) 128)) {\n                    ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9758] = futrts_to_bits16(as_transformed_row_elem_9753);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9782 = sext_i32_i64(local_tid_11198);\n        for (int64_t nest_i_11222 = 0; nest_i_11222 < (int64_t) 2; nest_i_11222++) {\n            for (int64_t nest_i_11223 = 0; nest_i_11223 < (int64_t) 1; nest_i_11223++) {\n                int64_t ltid_seq_9785;\n                int64_t ltid_seq_9786;\n                int64_t ltid_y_9783;\n                int64_t ltid_x_9784;\n                int64_t binop_y_9787;\n                int64_t k_9788;\n                int64_t binop_y_9789;\n                int64_t i_9790;\n                int64_t gtid_9791;\n                int64_t as_transformed_row_seqdim_idx_9792;\n                bool cond_9793;\n                f16 as_transformed_row_elem_9794;\n                bool cond_9798;\n                int64_t as_transformed_row_loc_ind_9799;\n                \n                ltid_seq_9785 = nest_i_11222;\n                ltid_seq_9786 = nest_i_11223;\n                ltid_y_9783 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9784 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9787 = (int64_t) 8 * ltid_seq_9786;\n                k_9788 = ltid_x_9784 + binop_y_9787;\n                binop_y_9789 = (int64_t) 8 * ltid_seq_9785;\n                i_9790 = ltid_y_9783 + binop_y_9789;\n                gtid_9791 = jjj_9690 + i_9790;\n                as_transformed_row_seqdim_idx_9792 = kk_9721 + k_9788;\n                cond_9793 = slt64(gtid_9791, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n                if (cond_9793)", " {\n                    f16 A_elem_9796 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9791 * (int64_t) 16 + as_transformed_row_seqdim_idx_9792]);\n                    \n                    as_transformed_row_elem_9794 = A_elem_9796;\n                } else {\n                    as_transformed_row_elem_9794 = (f16) 0.0F;\n                }\n                cond_9798 = slt64(k_9788, (int64_t) 8);\n                if (cond_9798) {\n                    int64_t binop_y_9800;\n                    int64_t x_9801;\n                    \n                    binop_y_9800 = (int64_t) 9 * i_9790;\n                    x_9801 = k_9788 + binop_y_9800;\n                    as_transformed_row_loc_ind_9799 = x_9801;\n                } else {\n                    as_transformed_row_loc_ind_9799 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9799) && slt64(as_transformed_row_loc_ind_9799, (int64_t) 144)) {\n                    ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9799] = futrts_to_bits16(as_transformed_row_elem_9794);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9839 = sext_i32_i64(local_tid_11198);\n        ltid_y_9838 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n        ltid_x_9837 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n        binop_x_9852 = (int64_t) 2 * ltid_y_9838;\n        binop_x_9857 = (int64_t) 2 * ltid_x_9837;\n        for (int64_t i_9842 = 0; i_9842 < (int64_t) 8; i_9842++) {\n            for (int64_t i_9846 = 0; i_9846 < (int64_t) 2; i_9846++) {\n                int64_t binop_x_9853;\n                int64_t binop_y_9854;\n                int64_t as_transformed_row_loc_ind_64_9855;\n                f16 x_10437;\n                \n                binop_x_9853 = i_9846 + binop_x_9852;\n                binop_y_9854 = (int64_t) 8 * binop_x_9853;\n                as_transformed_row_loc_ind_64_9855 = i_9842 + binop_y_9854;\n                x_10437 = futrt",
                                    "s_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_9855]);\n                for (int64_t i_9849 = 0; i_9849 < (int64_t) 2; i_9849++) {\n                    int64_t binop_x_9858;\n                    int64_t binop_y_9859;\n                    int64_t as_transformed_row_loc_ind_64_9860;\n                    f16 as_transformed_row_loc_elem_9861;\n                    f16 c_9862;\n                    f16 defunc_0_f_res_9865;\n                    f16 defunc_0_op_res_9868;\n                    \n                    binop_x_9858 = i_9849 + binop_x_9857;\n                    binop_y_9859 = (int64_t) 9 * binop_x_9858;\n                    as_transformed_row_loc_ind_64_9860 = i_9842 + binop_y_9859;\n                    as_transformed_row_loc_elem_9861 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_9860]);\n                    c_9862 = mem_param_10509[i_9846 * (int64_t) 2 + i_9849];\n                    defunc_0_f_res_9865 = as_transformed_row_loc_elem_9861 * x_10437;\n                    defunc_0_op_res_9868 = c_9862 + defunc_0_f_res_9865;\n                    mem_param_10509[i_9846 * (int64_t) 2 + i_9849] = defunc_0_op_res_9868;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n            for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n                mem_10534[i_0 * (int64_t) 2 + i_1] = mem_param_10509[i_0 * (int64_t) 2 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < (int64_t) 2 * (int64_t) 2; i_3++)\n            mem_param_tmp_11216[i_3] = mem_10534[i_3];\n        for (int32_t i_4 = 0; i_4 < (int64_t) 2 * (int64_t) 2; i_4++)\n            mem_param_10509[i_4] = mem_param_tmp_11216[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < (int64_t) 2 * (int64_t) 2; i_5++)\n        ext_mem_10541[i_5] = mem_param_10509[i_5];\n    ltid_flat_9896 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11227 = 0; nest_i_11227 < (int64_t) 2; ", "nest_i_11227++) {\n        for (int64_t nest_i_11228 = 0; nest_i_11228 < (int64_t) 1; nest_i_11228++) {\n            int64_t ltid_seq_9899;\n            int64_t ltid_seq_9900;\n            int64_t ltid_y_9897;\n            int64_t ltid_x_9898;\n            int64_t binop_y_9901;\n            int64_t k_9902;\n            int64_t binop_y_9903;\n            int64_t i_9904;\n            int64_t gtid_9905;\n            int64_t as_transformed_row_seqdim_idx_9906;\n            bool binop_x_9907;\n            bool binop_y_9908;\n            bool cond_9909;\n            f16 as_transformed_row_elem_9910;\n            bool cond_9914;\n            int64_t as_transformed_row_loc_ind_9915;\n            \n            ltid_seq_9899 = nest_i_11227;\n            ltid_seq_9900 = nest_i_11228;\n            ltid_y_9897 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9898 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9901 = (int64_t) 8 * ltid_seq_9900;\n            k_9902 = ltid_x_9898 + binop_y_9901;\n            binop_y_9903 = (int64_t) 8 * ltid_seq_9899;\n            i_9904 = ltid_y_9897 + binop_y_9903;\n            gtid_9905 = iii_9689 + i_9904;\n            as_transformed_row_seqdim_idx_9906 = (int64_t) 16 + k_9902;\n            binop_x_9907 = slt64(gtid_9905, (int64_t) 16);\n            binop_y_9908 = slt64(as_transformed_row_seqdim_idx_9906, (int64_t) 16);\n            cond_9909 = binop_x_9907 && binop_y_9908;\n            if (cond_9909) {\n                f16 A_elem_9912 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7557 * (int64_t) 256 + gtid_9905 * (int64_t) 16 + as_transformed_row_seqdim_idx_9906]);\n                \n                as_transformed_row_elem_9910 = A_elem_9912;\n            } else {\n                as_transformed_row_elem_9910 = (f16) 0.0F;\n            }\n            cond_9914 = slt64(k_9902, (int64_t) 8);\n            if (cond_9914) {\n                int64_t binop_y_9916;\n                int64_t x_9917;\n                \n                binop_y_", "9916 = (int64_t) 8 * i_9904;\n                x_9917 = k_9902 + binop_y_9916;\n                as_transformed_row_loc_ind_9915 = x_9917;\n            } else {\n                as_transformed_row_loc_ind_9915 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_9915) && slt64(as_transformed_row_loc_ind_9915, (int64_t) 128)) {\n                ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9915] = futrts_to_bits16(as_transformed_row_elem_9910);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_9941 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11229 = 0; nest_i_11229 < (int64_t) 2; nest_i_11229++) {\n        for (int64_t nest_i_11230 = 0; nest_i_11230 < (int64_t) 1; nest_i_11230++) {\n            int64_t ltid_seq_9944;\n            int64_t ltid_seq_9945;\n            int64_t ltid_y_9942;\n            int64_t ltid_x_9943;\n            int64_t binop_y_9946;\n            int64_t k_9947;\n            int64_t binop_y_9948;\n            int64_t i_9949;\n            int64_t gtid_9950;\n            int64_t as_transformed_row_seqdim_idx_9951;\n            bool binop_x_9952;\n            bool binop_y_9953;\n            bool cond_9954;\n            f16 as_transformed_row_elem_9955;\n            bool cond_9959;\n            int64_t as_transformed_row_loc_ind_9960;\n            \n            ltid_seq_9944 = nest_i_11229;\n            ltid_seq_9945 = nest_i_11230;\n            ltid_y_9942 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9943 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9946 = (int64_t) 8 * ltid_seq_9945;\n            k_9947 = ltid_x_9943 + binop_y_9946;\n            binop_y_9948 = (int64_t) 8 * ltid_seq_9944;\n            i_9949 = ltid_y_9942 + binop_y_9948;\n            gtid_9950 = jjj_9690 + i_9949;\n            as_transformed_row_seqdim_idx_9951 = (int64_t) 16 + k_9947;\n            binop_x_9952 = slt64(gtid_9950, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n            bi",
                                    "nop_y_9953 = slt64(as_transformed_row_seqdim_idx_9951, (int64_t) 16);\n            cond_9954 = binop_x_9952 && binop_y_9953;\n            if (cond_9954) {\n                f16 A_elem_9957 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9950 * (int64_t) 16 + as_transformed_row_seqdim_idx_9951]);\n                \n                as_transformed_row_elem_9955 = A_elem_9957;\n            } else {\n                as_transformed_row_elem_9955 = (f16) 0.0F;\n            }\n            cond_9959 = slt64(k_9947, (int64_t) 8);\n            if (cond_9959) {\n                int64_t binop_y_9961;\n                int64_t x_9962;\n                \n                binop_y_9961 = (int64_t) 9 * i_9949;\n                x_9962 = k_9947 + binop_y_9961;\n                as_transformed_row_loc_ind_9960 = x_9962;\n            } else {\n                as_transformed_row_loc_ind_9960 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_9960) && slt64(as_transformed_row_loc_ind_9960, (int64_t) 144)) {\n                ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9960] = futrts_to_bits16(as_transformed_row_elem_9955);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10002 = sext_i32_i64(local_tid_11198);\n    ltid_y_10001 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_10000 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    binop_x_10017 = (int64_t) 2 * ltid_y_10001;\n    binop_x_10022 = (int64_t) 2 * ltid_x_10000;\n    for (int64_t i_10005 = 0; i_10005 < (int64_t) 8; i_10005++) {\n        int64_t cmpop_x_10007;\n        bool cond_10008;\n        \n        cmpop_x_10007 = (int64_t) 16 + i_10005;\n        cond_10008 = slt64(cmpop_x_10007, (int64_t) 16);\n        if (cond_10008) {\n            for (int64_t i_10011 = 0; i_10011 < (int64_t) 2; i_10011++) {\n                int64_t binop_x_10018;\n                int64_t binop_y_10019;\n                int64_t as_transformed_row_loc_ind_64_10020;\n                f16 ", "x_10434;\n                \n                binop_x_10018 = i_10011 + binop_x_10017;\n                binop_y_10019 = (int64_t) 8 * binop_x_10018;\n                as_transformed_row_loc_ind_64_10020 = i_10005 + binop_y_10019;\n                x_10434 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_10020]);\n                for (int64_t i_10014 = 0; i_10014 < (int64_t) 2; i_10014++) {\n                    int64_t binop_x_10023;\n                    int64_t binop_y_10024;\n                    int64_t as_transformed_row_loc_ind_64_10025;\n                    f16 as_transformed_row_loc_elem_10026;\n                    f16 c_10027;\n                    f16 defunc_0_f_res_10030;\n                    f16 defunc_0_op_res_10033;\n                    \n                    binop_x_10023 = i_10014 + binop_x_10022;\n                    binop_y_10024 = (int64_t) 9 * binop_x_10023;\n                    as_transformed_row_loc_ind_64_10025 = i_10005 + binop_y_10024;\n                    as_transformed_row_loc_elem_10026 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_10025]);\n                    c_10027 = ext_mem_10541[i_10011 * (int64_t) 2 + i_10014];\n                    defunc_0_f_res_10030 = as_transformed_row_loc_elem_10026 * x_10434;\n                    defunc_0_op_res_10033 = c_10027 + defunc_0_f_res_10030;\n                    ext_mem_10541[i_10011 * (int64_t) 2 + i_10014] = defunc_0_op_res_10033;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 2; i_1++) {\n            mem_10561[i_0 * (int64_t) 2 + i_1] = ext_mem_10541[i_0 * (int64_t) 2 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11237 = (int64_t) 8;\n    slice_11238 = (int64_t) 8 * slice_11237;\n    slice_11239 = slice_11238;\n    reg_tile_i_11234 = squot64(sext_i32_i64(local_tid_11198), slice_11238);\n    remnant_11240 = sext_i32_i64(local_tid_11198)", " - reg_tile_i_11234 * slice_11238;\n    reg_tile_i_11235 = squot64(remnant_11240, slice_11237);\n    remnant_11241 = remnant_11240 - reg_tile_i_11235 * slice_11237;\n    reg_tile_i_11236 = remnant_11241;\n    remnant_11242 = remnant_11241 - reg_tile_i_11236;\n    tile_dim_start_11243 = gtid_7557 + reg_tile_i_11234;\n    tile_dim_start_11244 = (int64_t) 2 * ((int64_t) 8 * gid_y_9686 + reg_tile_i_11235);\n    tile_dim_start_11245 = (int64_t) 2 * ((int64_t) 8 * gid_x_9687 + reg_tile_i_11236);\n    for (int64_t nest_i_11246 = 0; nest_i_11246 < (int64_t) 1; nest_i_11246++) {\n        for (int64_t nest_i_11247 = 0; nest_i_11247 < (int64_t) 2; nest_i_11247++) {\n            for (int64_t nest_i_11248 = 0; nest_i_11248 < (int64_t) 2; nest_i_11248++) {\n                if ((slt64(tile_dim_start_11243 + nest_i_11246, m_6594) && slt64(tile_dim_start_11244 + nest_i_11247, (int64_t) 16)) && slt64(tile_dim_start_11245 + nest_i_11248, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) {\n                    f16 tmp_11249 = mem_10561[nest_i_11247 * (int64_t) 2 + nest_i_11248];\n                    \n                    ((__global uint16_t *) mem_10565)[(tile_dim_start_11243 + nest_i_11246) * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + (tile_dim_start_11244 + nest_i_11247) * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + (tile_dim_start_11245 + nest_i_11248)] = futrts_to_bits16(tmp_11249);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run16zisegred_large_7582_dim1, 1, 1)\nvoid run16zisegred_large_7582(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t num_tblocks_7575, int64_t blocks_per_segment_11283, int64_t q_11284, int64_t num_virtblocks_11285, int64_t threads_per_segment_11286, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479, __global unsigned char *segred_tmp_mem_11287, __global unsigned char *counters_mem_11289)\n{\n    #define segred_tblock_sizz",
                                    "e_7574 (run16zisegred_large_7582zisegred_tblock_sizze_7574)\n    #define chunk_sizze_11250 (run16zisegred_large_7582zichunk_sizze_11250)\n    \n    volatile __local unsigned char *sync_arr_mem_11318_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11318_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11316_backing_0 = &shared_mem[sync_arr_mem_11318_backing_1_offset];\n    const int64_t red_arr_f16_mem_11316_backing_0_offset = sync_arr_mem_11318_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_7574 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7574, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11312;\n    int32_t tblock_sizze_11315;\n    int32_t wave_sizze_11314;\n    int32_t block_id_11313;\n    int32_t global_tid_11311;\n    int64_t phys_tid_7582;\n    __local unsigned char *red_arr_f16_mem_11316;\n    __local unsigned char *sync_arr_mem_11318;\n    int32_t phys_tblock_id_11320;\n    int32_t iterations_11321;\n    \n    local_tid_11312 = get_local_id(0);\n    tblock_sizze_11315 = get_local_size(0);\n    wave_sizze_11314 = LOCKSTEP_WIDTH;\n    block_id_11313 = get_tblock_id(0);\n    global_tid_11311 = block_id_11313 * tblock_sizze_11315 + local_tid_11312;\n    phys_tid_7582 = sext_i32_i64(global_tid_11311);\n    red_arr_f16_mem_11316 = (__local unsigned char *) red_arr_f16_mem_11316_backing_0;\n    sync_arr_mem_11318 = (__local unsigned char *) sync_arr_mem_11318_backing_1;\n    phys_tblock_id_11320 = get_tblock_id(0);\n    iterations_11321 = sdiv_up32(sext_i64_i32(num_virtblocks_11285) - phys_tblock_id_11320, sext_i64_i32(num_tblocks_7575));\n    for (int32_t i_11322 = 0; i_11322 < iterations_11321; i_11322++) {\n        int32_t virt_tblock_id_11323;\n        int64_t flat_segment_id_11324;\n        int64_t global_tid_11325;\n        int64_t slice_11326;\n        int64_t slice_11327;\n        int64_t slice_11328;\n        int64_t gtid_7578;\n        int64_t remnant_11329;\n   ", "     int64_t gtid_7579;\n        int64_t remnant_11330;\n        int64_t gtid_7580;\n        int64_t remnant_11331;\n        int64_t gtid_7581;\n        f16 eta_p_block_res_acc_11332;\n        f16 eta_p_7583;\n        f16 eta_p_7584;\n        int64_t tblock_id_in_segment_11336;\n        int64_t block_base_offset_11337;\n        int32_t offset_11340;\n        int32_t skip_waves_11341;\n        f16 eta_p_11333;\n        f16 eta_p_11334;\n        \n        virt_tblock_id_11323 = phys_tblock_id_11320 + i_11322 * sext_i64_i32(num_tblocks_7575);\n        flat_segment_id_11324 = squot64(sext_i32_i64(virt_tblock_id_11323), blocks_per_segment_11283);\n        global_tid_11325 = srem64(sext_i32_i64(virt_tblock_id_11323) * segred_tblock_sizze_7574 + sext_i32_i64(local_tid_11312), threads_per_segment_11286);\n        slice_11326 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;\n        slice_11327 = (int64_t) 16 * slice_11326;\n        slice_11328 = m_6594 * slice_11327;\n        gtid_7578 = squot64(flat_segment_id_11324, slice_11327);\n        remnant_11329 = flat_segment_id_11324 - gtid_7578 * slice_11327;\n        gtid_7579 = squot64(remnant_11329, slice_11326);\n        remnant_11330 = remnant_11329 - gtid_7579 * slice_11326;\n        gtid_7580 = remnant_11330;\n        remnant_11331 = remnant_11330 - gtid_7580;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11332 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11336 = squot64(global_tid_11325, segred_tblock_sizze_7574);\n        block_base_offset_11337 = tblock_id_in_segment_11336 * q_11284 * segred_tblock_sizze_7574;\n        for (int64_t i_11338 = 0; i_11338 < q_11284; i_11338++) {\n            int64_t block_offset_11339 = block_base_offset_11337 + i_11338 * segred_tblock_sizze_7574;\n            \n            gtid_7581 = global_tid_11325 + threads_per_segment_11286 * i_11338;\n            if (slt64(gtid_7581, (int64_t) 16)) {\n                // apply map function(s)\n                {\n                ", "    // apply map function\n                    {\n                        f16 eta_p_7589 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7578 * (int64_t) 256 + gtid_7579 * (int64_t) 16 + gtid_7581]);\n                        f16 eta_p_7590 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_7580 * (int64_t) 16 + gtid_7581]);\n                        f16 defunc_0_f_res_7591 = eta_p_7589 * eta_p_7590;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_7583 = eta_p_block_res_acc_11332;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_7584 = defunc_0_f_res_7591;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_7585 = eta_p_7583 + eta_p_7584;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11332 = defunc_0_op_res_7585;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11341 = 1;\n        offset_11340 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_7574))) {\n                eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n            }\n        }\n        offset_11340 = 1;\n        while (slt32(offset_11340, wave_si",
                                    "zze_11314)) {\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_7574)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11340 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            offset_11340 *= 2;\n        }\n        while (slt32(skip_waves_11341, squot32(sext_i64_i32(segred_tblock_sizze_7574) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11340 = skip_waves_11341 * wave_sizze_11314;\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_7574)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11341 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n         ", "           ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            skip_waves_11341 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11312) == (int64_t) 0) {\n                eta_p_block_res_acc_11332 = eta_p_11333;\n            } else {\n                eta_p_block_res_acc_11332 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11283 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) mem_10479)[gtid_7578 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + gtid_7579 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7580] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                }\n            }\n        } else {\n            int32_t old_counter_11342;\n            bool is_last_block_11343;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11287)[sext_i32_i64(virt_tblock_id_11323)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                    mem_fence_global();\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11318)[(int64_t) 0] = old_counter_11342 == sext_i64_i32(blocks_per_segment_11283 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11343 = ((__local bool *) sync_arr_mem_11318)[(int64_t) 0];\n            if (is_last_block_11343) {\n                if (local_t", "id_11312 == 0) {\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11283));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11344 = sdiv_up64(blocks_per_segment_11283, segred_tblock_sizze_7574);\n                    \n                    eta_p_7583 = (f16) 0.0F;\n                    for (int64_t i_11345 = 0; i_11345 < read_per_thread_11344; i_11345++) {\n                        int64_t block_res_id_11346 = sext_i32_i64(local_tid_11312) * read_per_thread_11344 + i_11345;\n                        int64_t index_of_block_res_11347 = flat_segment_id_11324 * blocks_per_segment_11283 + block_res_id_11346;\n                        \n                        if (slt64(block_res_id_11346, blocks_per_segment_11283)) {\n                            eta_p_7584 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11287)[index_of_block_res_11347]);\n                            \n                            f16 defunc_0_op_res_7585 = eta_p_7583 + eta_p_7584;\n                            \n                            eta_p_7583 = defunc_0_op_res_7585;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_7583);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11348;\n                    int32_t skip_waves_11349 = 1;\n                    f16 eta_p_11333;\n                    f16 eta_p_11334;\n                    \n                    offset_11348 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_7574))) {\n  ",
                                    "                          eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                        }\n                    }\n                    offset_11348 = 1;\n                    while (slt32(offset_11348, wave_sizze_11314)) {\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_7574)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11348 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        offset_11348 *= 2;\n                    }\n                    while (slt32(skip_waves_11349, squot32(sext_i64_i32(segred_tblock_sizze_7574) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11348 = skip_waves_11349 * wave_sizze_11314;\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_7574)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * sk", "ip_waves_11349 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        skip_waves_11349 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11312 == 0) {\n                            ((__global uint16_t *) mem_10479)[gtid_7578 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + gtid_7579 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7580] = futrts_to_bits16(eta_p_11333);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_7574\n    #undef chunk_sizze_11250\n}\nFUTHARK_KERNEL_SIZED(run16zisegred_large_7629_dim1, 1, 1)\nvoid run16zisegred_large_7629(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t one_intra_par_min_7480, int64_t num_tblocks_7622, int64_t blocks_per_segment_11439, int64_t q_11440, int64_t num_virtblocks_11441, int64_t threads_per_segment_11442, __global unsigned char *ext", "_mem_10569, __global unsigned char *mem_10579, __global unsigned char *mem_10584, __global unsigned char *segred_tmp_mem_11443, __global unsigned char *counters_mem_11445)\n{\n    #define segred_tblock_sizze_7621 (run16zisegred_large_7629zisegred_tblock_sizze_7621)\n    #define chunk_sizze_11406 (run16zisegred_large_7629zichunk_sizze_11406)\n    \n    volatile __local unsigned char *sync_arr_mem_11454_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11454_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11452_backing_0 = &shared_mem[sync_arr_mem_11454_backing_1_offset];\n    const int64_t red_arr_f16_mem_11452_backing_0_offset = sync_arr_mem_11454_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_7621 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7621, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11448;\n    int32_t tblock_sizze_11451;\n    int32_t wave_sizze_11450;\n    int32_t block_id_11449;\n    int32_t global_tid_11447;\n    int64_t phys_tid_7629;\n    __local unsigned char *red_arr_f16_mem_11452;\n    __local unsigned char *sync_arr_mem_11454;\n    int32_t phys_tblock_id_11456;\n    int32_t iterations_11457;\n    \n    local_tid_11448 = get_local_id(0);\n    tblock_sizze_11451 = get_local_size(0);\n    wave_sizze_11450 = LOCKSTEP_WIDTH;\n    block_id_11449 = get_tblock_id(0);\n    global_tid_11447 = block_id_11449 * tblock_sizze_11451 + local_tid_11448;\n    phys_tid_7629 = sext_i32_i64(global_tid_11447);\n    red_arr_f16_mem_11452 = (__local unsigned char *) red_arr_f16_mem_11452_backing_0;\n    sync_arr_mem_11454 = (__local unsigned char *) sync_arr_mem_11454_backing_1;\n    phys_tblock_id_11456 = get_tblock_id(0);\n    iterations_11457 = sdiv_up32(sext_i64_i32(num_virtblocks_11441) - phys_tblock_id_11456, sext_i64_i32(num_tblocks_7622));\n    for (int32_t i_11458 = 0; i_11458 < iterations_11457; i_11458++) {\n        int32_t virt_tblock_id_11459;\n        int64_t f",
                                    "lat_segment_id_11460;\n        int64_t global_tid_11461;\n        int64_t slice_11462;\n        int64_t slice_11463;\n        int64_t slice_11464;\n        int64_t gtid_7625;\n        int64_t remnant_11465;\n        int64_t gtid_7626;\n        int64_t remnant_11466;\n        int64_t gtid_7627;\n        int64_t remnant_11467;\n        int64_t gtid_7628;\n        f16 eta_p_block_res_acc_11468;\n        f16 eta_p_7630;\n        f16 eta_p_7631;\n        int64_t tblock_id_in_segment_11472;\n        int64_t block_base_offset_11473;\n        int32_t offset_11476;\n        int32_t skip_waves_11477;\n        f16 eta_p_11469;\n        f16 eta_p_11470;\n        \n        virt_tblock_id_11459 = phys_tblock_id_11456 + i_11458 * sext_i64_i32(num_tblocks_7622);\n        flat_segment_id_11460 = squot64(sext_i32_i64(virt_tblock_id_11459), blocks_per_segment_11439);\n        global_tid_11461 = srem64(sext_i32_i64(virt_tblock_id_11459) * segred_tblock_sizze_7621 + sext_i32_i64(local_tid_11448), threads_per_segment_11442);\n        slice_11462 = (int64_t) 16;\n        slice_11463 = (int64_t) 16 * slice_11462;\n        slice_11464 = m_6594 * slice_11463;\n        gtid_7625 = squot64(flat_segment_id_11460, slice_11463);\n        remnant_11465 = flat_segment_id_11460 - gtid_7625 * slice_11463;\n        gtid_7626 = squot64(remnant_11465, slice_11462);\n        remnant_11466 = remnant_11465 - gtid_7626 * slice_11462;\n        gtid_7627 = remnant_11466;\n        remnant_11467 = remnant_11466 - gtid_7627;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11468 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11472 = squot64(global_tid_11461, segred_tblock_sizze_7621);\n        block_base_offset_11473 = tblock_id_in_segment_11472 * q_11440 * segred_tblock_sizze_7621;\n        for (int64_t i_11474 = 0; i_11474 < q_11440; i_11474++) {\n            int64_t block_offset_11475 = block_base_offset_11473 + i_11474 * segred_tblock_sizze_7621;\n            \n            gtid_7628 = ", "global_tid_11461 + threads_per_segment_11442 * i_11474;\n            if (slt64(gtid_7628, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_7636 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_7625 * one_intra_par_min_7480 + gtid_7626 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7628]);\n                        f16 eta_p_7637 = futrts_from_bits16(((__global uint16_t *) mem_10579)[gtid_7628 + gtid_7627 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595]);\n                        f16 defunc_0_f_res_7638 = eta_p_7636 * eta_p_7637;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_7630 = eta_p_block_res_acc_11468;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_7631 = defunc_0_f_res_7638;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_7632 = eta_p_7630 + eta_p_7631;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11468 = defunc_0_op_res_7632;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11477 = 1;\n        offset_11476 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11448, sext_i64_i32(segre", "d_tblock_sizze_7621))) {\n                eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n            }\n        }\n        offset_11476 = 1;\n        while (slt32(offset_11476, wave_sizze_11450)) {\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_7621)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11476 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            offset_11476 *= 2;\n        }\n        while (slt32(skip_waves_11477, squot32(sext_i64_i32(segred_tblock_sizze_7621) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11476 = skip_waves_11477 * wave_sizze_11450;\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_7621)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11477 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n  ",
                                    "              {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            skip_waves_11477 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11448) == (int64_t) 0) {\n                eta_p_block_res_acc_11468 = eta_p_11469;\n            } else {\n                eta_p_block_res_acc_11468 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11439 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) mem_10584)[gtid_7625 * (int64_t) 256 + gtid_7626 * (int64_t) 16 + gtid_7627] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                }\n            }\n        } else {\n            int32_t old_counter_11478;\n            bool is_last_block_11479;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11443)[sext_i32_i64(virt_tblock_id_11459)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                    mem_fence_global();\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11454)[(int64_t) 0] = old_counter_11478 == sext_i64_i32(blocks_per_segment_11439 - (int64_t) 1);\n                }\n            }\n            barrier(", "CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11479 = ((__local bool *) sync_arr_mem_11454)[(int64_t) 0];\n            if (is_last_block_11479) {\n                if (local_tid_11448 == 0) {\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11439));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11480 = sdiv_up64(blocks_per_segment_11439, segred_tblock_sizze_7621);\n                    \n                    eta_p_7630 = (f16) 0.0F;\n                    for (int64_t i_11481 = 0; i_11481 < read_per_thread_11480; i_11481++) {\n                        int64_t block_res_id_11482 = sext_i32_i64(local_tid_11448) * read_per_thread_11480 + i_11481;\n                        int64_t index_of_block_res_11483 = flat_segment_id_11460 * blocks_per_segment_11439 + block_res_id_11482;\n                        \n                        if (slt64(block_res_id_11482, blocks_per_segment_11439)) {\n                            eta_p_7631 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11443)[index_of_block_res_11483]);\n                            \n                            f16 defunc_0_op_res_7632 = eta_p_7630 + eta_p_7631;\n                            \n                            eta_p_7630 = defunc_0_op_res_7632;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_7630);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11484;\n                    int32_t skip_waves_11485 = 1;\n                    f16 eta_p_11469;\n                    f16 eta_p_11470;\n                    \n                    offset_11", "484 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_7621))) {\n                            eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                        }\n                    }\n                    offset_11484 = 1;\n                    while (slt32(offset_11484, wave_sizze_11450)) {\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_7621)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11484 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        offset_11484 *= 2;\n                    }\n                    while (slt32(skip_waves_11485, squot32(sext_i64_i32(segred_tblock_sizze_7621) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11484 = skip_waves_11485 * wave_sizze_11450;\n                        if (slt32(local_tid_11448 + offs",
                                    "et_11484, sext_i64_i32(segred_tblock_sizze_7621)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11485 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        skip_waves_11485 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11448 == 0) {\n                            ((__global uint16_t *) mem_10584)[gtid_7625 * (int64_t) 256 + gtid_7626 * (int64_t) 16 + gtid_7627] = futrts_to_bits16(eta_p_11469);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_7621\n    #undef chunk_sizze_11406\n}\nFUTHARK_KERNEL_SIZED(run16zisegred_small_7582_dim1, 1, 1)\nvoid run16zisegred_small_7582(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t num_tblocks_7575, int64_t segment_sizze_nonzzero_11251, __", "global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479)\n{\n    #define segred_tblock_sizze_7574 (run16zisegred_small_7582zisegred_tblock_sizze_7574)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11258_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11258_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_7574 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7574, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11254;\n    int32_t tblock_sizze_11257;\n    int32_t wave_sizze_11256;\n    int32_t block_id_11255;\n    int32_t global_tid_11253;\n    int64_t phys_tid_7582;\n    __local unsigned char *red_arr_f16_mem_11258;\n    int32_t phys_tblock_id_11260;\n    int32_t iterations_11261;\n    \n    local_tid_11254 = get_local_id(0);\n    tblock_sizze_11257 = get_local_size(0);\n    wave_sizze_11256 = LOCKSTEP_WIDTH;\n    block_id_11255 = get_tblock_id(0);\n    global_tid_11253 = block_id_11255 * tblock_sizze_11257 + local_tid_11254;\n    phys_tid_7582 = sext_i32_i64(global_tid_11253);\n    red_arr_f16_mem_11258 = (__local unsigned char *) red_arr_f16_mem_11258_backing_0;\n    phys_tblock_id_11260 = get_tblock_id(0);\n    iterations_11261 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251))) - phys_tblock_id_11260, sext_i64_i32(num_tblocks_7575));\n    for (int32_t i_11262 = 0; i_11262 < iterations_11261; i_11262++) {\n        int32_t virt_tblock_id_11263;\n        int64_t slice_11264;\n        int64_t slice_11265;\n        int64_t slice_11266;\n        int64_t gtid_7578;\n        int64_t remnant_11267;\n        int64_t gtid_7579;\n        int64_t remnant_11268;\n        int64_t gtid_7580;\n        int64_t remnant_11269;\n        int64_t gtid_7581;\n        \n        virt_tblock_id_11263 = phys_tblock_id_11260 + i_11262 * sext_i64_i32(num_tblocks", "_7575);\n        slice_11264 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;\n        slice_11265 = (int64_t) 16 * slice_11264;\n        slice_11266 = m_6594 * slice_11265;\n        gtid_7578 = squot64(squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251), slice_11265);\n        remnant_11267 = squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) - gtid_7578 * slice_11265;\n        gtid_7579 = squot64(remnant_11267, slice_11264);\n        remnant_11268 = remnant_11267 - gtid_7579 * slice_11264;\n        gtid_7580 = remnant_11268;\n        remnant_11269 = remnant_11268 - gtid_7580;\n        gtid_7581 = srem64(sext_i32_i64(local_tid_11254), (int64_t) 16);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, (int64_t) 16) && (((slt64(gtid_7578, m_6594) && slt64(gtid_7579, (int64_t) 16)) && slt64(gtid_7580, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) && slt64(sext_i32_i64(local_tid_11254), (int64_t) 16 * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251)))) {\n                // apply map function\n                {\n                    f16 eta_p_7589 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7578 * (int64_t) 256 + gtid_7579 * (int64_t) 16 + gtid_7581]);\n                    f16 eta_p_7590 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_7580 * (int64_t) 16 + gtid_7581]);\n                    f16 defunc_0_f_res_7591 = eta_p_7589 * eta_p_7590;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(defunc_0_f_res_7591);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11",
                                    "258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, (int64_t) 16)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_7583;\n                f16 eta_p_7584;\n                f16 eta_p_11270;\n                f16 eta_p_11271;\n                bool ltid_in_bounds_11273 = slt64(sext_i32_i64(local_tid_11254), (int64_t) 16 * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251));\n                int32_t skip_threads_11274;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11273) {\n                        eta_p_7584 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                        if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                            eta_p_7583 = eta_p_7584;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11274 = 1;\n                    while (slt32(skip_threads_11274, 32)) {\n                        bool thread_active_11275 = sle32(skip_threads_11274, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && ltid_in_bounds_11273;\n                        \n                        if (thread_active_11275) {\n                            // read operands\n                            {\n                                eta_p_7583 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11274)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11276 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 16), sext_i32_i64(loc", "al_tid_11254) - sext_i32_i64(local_tid_11254 - skip_threads_11274));\n                            \n                            if (thread_active_11275 && inactive_11276) {\n                                eta_p_7583 = eta_p_7584;\n                            }\n                            if (thread_active_11275) {\n                                if (!inactive_11276) {\n                                    f16 defunc_0_op_res_7585 = eta_p_7583 + eta_p_7584;\n                                    \n                                    eta_p_7583 = defunc_0_op_res_7585;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11275) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_7583);\n                                eta_p_7584 = eta_p_7583;\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11274 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 31 && ltid_in_bounds_11273) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32))] = futrts_to_bits16(eta_p_7583);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset '", "i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11277;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                            eta_p_11271 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                            if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                                eta_p_11270 = eta_p_11271;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11277 = 1;\n                        while (slt32(skip_threads_11277, 32)) {\n                            bool thread_active_11278 = sle32(skip_threads_11277, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273);\n                            \n                            if (thread_active_11278) {\n                                // read operands\n                                {\n                                    eta_p_11270 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11277)]);\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_11279 = slt64(srem64(sext_i32_i64(local_tid_11254 * 32 + 32 - 1), (int64_t) 16), sext_i32_i64(local_tid_11254 * 32 + 32 - 1) - sext_i32_i64((local_tid_11254 - skip_threads_11277) * 32 + 32 - 1));\n                                \n                                if (thread_active_11278 && inactive_11279) {\n                                    eta_p_11270 = eta_p_11271;\n                  ",
                                    "              }\n                                if (thread_active_11278) {\n                                    if (!inactive_11279) {\n                                        f16 defunc_0_op_res_11272 = eta_p_11270 + eta_p_11271;\n                                        \n                                        eta_p_11270 = defunc_0_op_res_11272;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11278) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_11270);\n                                    eta_p_11271 = eta_p_11270;\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11277 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11280 = squot32(local_tid_11254, 32) == 0 || !ltid_in_bounds_11273;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11280) {\n                            eta_p_7584 = eta_p_7583;\n                            eta_p_7583 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operat", "ion\n                    {\n                        bool inactive_11281 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 16), sext_i32_i64(local_tid_11254) - sext_i32_i64(squot32(local_tid_11254, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11280) {\n                            if (inactive_11281) {\n                                eta_p_7583 = eta_p_7584;\n                            }\n                        }\n                        if (!no_carry_in_11280) {\n                            if (!inactive_11281) {\n                                f16 defunc_0_op_res_7585 = eta_p_7583 + eta_p_7584;\n                                \n                                eta_p_7583 = defunc_0_op_res_7585;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11280) {\n                            ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_7583);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_7584);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) && slt64(sext_i32_i64(local_tid_11254), squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251))) {\n   ", "             f16 tmp_11282 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[(sext_i32_i64(local_tid_11254) + (int64_t) 1) * segment_sizze_nonzzero_11251 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10479)[squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + (sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)] = futrts_to_bits16(tmp_11282);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  e",
                                    "rror_3:\n    return;\n    #undef segred_tblock_sizze_7574\n}\nFUTHARK_KERNEL_SIZED(run16zisegred_small_7629_dim1, 1, 1)\nvoid run16zisegred_small_7629(__global int *global_failure, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, int64_t one_intra_par_min_7480, int64_t num_tblocks_7622, int64_t segment_sizze_nonzzero_11407, __global unsigned char *ext_mem_10569, __global unsigned char *mem_10579, __global unsigned char *mem_10584)\n{\n    #define segred_tblock_sizze_7621 (run16zisegred_small_7629zisegred_tblock_sizze_7621)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11414_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11414_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_7621 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7621, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11410;\n    int32_t tblock_sizze_11413;\n    int32_t wave_sizze_11412;\n    int32_t block_id_11411;\n    int32_t global_tid_11409;\n    int64_t phys_tid_7629;\n    __local unsigned char *red_arr_f16_mem_11414;\n    int32_t phys_tblock_id_11416;\n    int32_t iterations_11417;\n    \n    local_tid_11410 = get_local_id(0);\n    tblock_sizze_11413 = get_local_size(0);\n    wave_sizze_11412 = LOCKSTEP_WIDTH;\n    block_id_11411 = get_tblock_id(0);\n    global_tid_11409 = block_id_11411 * tblock_sizze_11413 + local_tid_11410;\n    phys_tid_7629 = sext_i32_i64(global_tid_11409);\n    red_arr_f16_mem_11414 = (__local unsigned char *) red_arr_f16_mem_11414_backing_0;\n    phys_tblock_id_11416 = get_tblock_id(0);\n    iterations_11417 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6594 * (int64_t) 16 * (int64_t) 16, squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407))) - phys_tblock_id_11416, sext_i64_i32(num_tblocks_7622));\n    for (int32_t i_11418 = 0; i_11418 < iterations_11417; i_11418++) {\n        int32_t virt_tblock_id_11419;\n        int64_t slice_11420;\n        int64_t slice_11421;\n        int64_t", " slice_11422;\n        int64_t gtid_7625;\n        int64_t remnant_11423;\n        int64_t gtid_7626;\n        int64_t remnant_11424;\n        int64_t gtid_7627;\n        int64_t remnant_11425;\n        int64_t gtid_7628;\n        \n        virt_tblock_id_11419 = phys_tblock_id_11416 + i_11418 * sext_i64_i32(num_tblocks_7622);\n        slice_11420 = (int64_t) 16;\n        slice_11421 = (int64_t) 16 * slice_11420;\n        slice_11422 = m_6594 * slice_11421;\n        gtid_7625 = squot64(squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407), slice_11421);\n        remnant_11423 = squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) - gtid_7625 * slice_11421;\n        gtid_7626 = squot64(remnant_11423, slice_11420);\n        remnant_11424 = remnant_11423 - gtid_7626 * slice_11420;\n        gtid_7627 = remnant_11424;\n        remnant_11425 = remnant_11424 - gtid_7627;\n        gtid_7628 = srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) && (((slt64(gtid_7625, m_6594) && slt64(gtid_7626, (int64_t) 16)) && slt64(gtid_7627, (int64_t) 16)) && slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407)))) {\n                // apply map function\n                {\n                    f16 eta_p_7636 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_7625 * one_intra_par_min_7480 + gtid_7626 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 + gtid_7628]);\n                    f16 eta_p_7637 = futrts_from_bits16(((__global uint16_t *) mem_10579)[gtid_7628 + gtid_7627 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595]);\n                    f16 defunc_0", "_f_res_7638 = eta_p_7636 * eta_p_7637;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(defunc_0_f_res_7638);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_7630;\n                f16 eta_p_7631;\n                f16 eta_p_11426;\n                f16 eta_p_11427;\n                bool ltid_in_bounds_11429 = slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407));\n                int32_t skip_threads_11430;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11429) {\n                        eta_p_7631 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                        if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                            eta_p_7630 = eta_p_7631;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11430 = 1;\n                    while (slt32(skip_threads_11430, 32)) {\n                        bool thread_active_11431 = sle32(skip_threads_11430, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && ltid_in_bounds_11429;\n                        \n                        if (thread_active_11431) {\n                            // read operands\n                            {\n  ",
                                    "                              eta_p_7630 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11430)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11432 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11410) - sext_i32_i64(local_tid_11410 - skip_threads_11430));\n                            \n                            if (thread_active_11431 && inactive_11432) {\n                                eta_p_7630 = eta_p_7631;\n                            }\n                            if (thread_active_11431) {\n                                if (!inactive_11432) {\n                                    f16 defunc_0_op_res_7632 = eta_p_7630 + eta_p_7631;\n                                    \n                                    eta_p_7630 = defunc_0_op_res_7632;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11431) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_7630);\n                                eta_p_7631 = eta_p_7630;\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11430 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' wri", "tes its result to offset 'i'\n                {\n                    if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 31 && ltid_in_bounds_11429) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32))] = futrts_to_bits16(eta_p_7630);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11433;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                            eta_p_11427 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                            if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                                eta_p_11426 = eta_p_11427;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11433 = 1;\n                        while (slt32(skip_threads_11433, 32)) {\n                            bool thread_active_11434 = sle32(skip_threads_11433, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429);\n                            \n                            if (thread_active_11434) {\n                                // read operands\n                                {\n                                    eta_p_11426 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11433)]);\n                                }\n                            }\n                            // perform operation\n    ", "                        {\n                                bool inactive_11435 = slt64(srem64(sext_i32_i64(local_tid_11410 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11410 * 32 + 32 - 1) - sext_i32_i64((local_tid_11410 - skip_threads_11433) * 32 + 32 - 1));\n                                \n                                if (thread_active_11434 && inactive_11435) {\n                                    eta_p_11426 = eta_p_11427;\n                                }\n                                if (thread_active_11434) {\n                                    if (!inactive_11435) {\n                                        f16 defunc_0_op_res_11428 = eta_p_11426 + eta_p_11427;\n                                        \n                                        eta_p_11426 = defunc_0_op_res_11428;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11434) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_11426);\n                                    eta_p_11427 = eta_p_11426;\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11433 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11436 = squot32(local_tid_11410, 32) == 0 || !ltid_in_bounds_11429;\n                \n         ",
                                    "       // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11436) {\n                            eta_p_7631 = eta_p_7630;\n                            eta_p_7630 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_11437 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), sext_i32_i64(local_tid_11410) - sext_i32_i64(squot32(local_tid_11410, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11436) {\n                            if (inactive_11437) {\n                                eta_p_7630 = eta_p_7631;\n                            }\n                        }\n                        if (!no_carry_in_11436) {\n                            if (!inactive_11437) {\n                                f16 defunc_0_op_res_7632 = eta_p_7630 + eta_p_7631;\n                                \n                                eta_p_7630 = defunc_0_op_res_7632;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11436) {\n                            ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_7630);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_7631);\n                    }\n", "                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), m_6594 * (int64_t) 16 * (int64_t) 16) && slt64(sext_i32_i64(local_tid_11410), squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407))) {\n                f16 tmp_11438 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[(sext_i32_i64(local_tid_11410) + (int64_t) 1) * segment_sizze_nonzzero_11407 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10584)[squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 256) * (int64_t) 256 + squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 256) * (int64_t) 256, (int64_t) 16) * (int64_t) 16 + (sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 256) * (int64_t) 256 - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 256) * (int64_t) 256, (int64_t) 16) * (int64_t) 16)] = futrts_to_bits16(tmp_11438);\n            }\n        }\n        barrier(CLK_LOCAL_M", "EM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_7621\n}\nFUTHARK_KERNEL_SIZED(run32zisegmap_7729_dim1, 1, 1)\nvoid run32zisegmap_7729(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t num_tblocks_7725, int64_t num_threads_10902, int32_t virt_num_tblocks_11024, __global unsigned char *K_mem_10473, __global unsigned char *mem_10768, __global unsigned char *mem_10778, __global unsigned char *mem_10820, __global unsigned char *color_10856)\n{\n    #define segmap_tblock_sizze_7724 (run32zisegmap_7729zisegmap_tblock_sizze_7724)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11026;\n    int32_t tblock_sizze_11029;\n    int32_t wave_sizze_11028;\n    int32_t block_id_11027;\n    int32_t global_tid_11025;\n    int64_t phys_tid_7729;\n    int32_t phys_tblock_id_11030;\n    int32_t iterations_11031;\n    \n    local_tid_11026 = get_local_id(0);\n    tblock_sizze_11029 = get_local_size(0);\n    wave_sizze_11028 = LOCKSTEP_WIDTH;\n    block_id_11027 = get_tblock_id(0);\n    global_tid_11025 = block_id_11027 * tblock_sizze_11029 + local_tid_11026;\n    phys_tid_7729 = sext_i32_i64(global_tid_11025);\n    phys_tblock_id_11030 = get_tblock_id(0);\n    iterations_11031 = sdiv_up32(virt_num_tblocks_11024 - phys_tblock_id_11030, sext_i64_i32(num_tblocks_7725));\n    for (int32_t i_11032 = 0; i_11032 < iterations_11031; i_11032++) {\n        int32_t virt_tblock_id_11033;\n        int64_t global_tid_11034;\n        int64_t slice_11035;\n        int64_t gtid_7728;\n        int64_t remnant_11036;\n        \n        virt_tblock_id_11033 = phys_tblock_id_11030 + i_11032 * sext_i64_i32(num_tblocks_7725);\n        global_tid_11034 = sext_i32_i64(virt_tblock_id_11033) * segmap_tblock_sizze_7724 + sext_i32_i64(local_tid_11026);\n        slice_11035 = m_6610;\n        gtid_7728 = global_tid_11034;\n        remnant_11036 = global_tid_11034 - gtid_7728;\n        if (slt",
                                    "64(gtid_7728, m_6610)) {\n            f16 mem_10788[(int64_t) 32 * (int64_t) 32];\n            f16 mem_10802[(int64_t) 32];\n            \n            for (int64_t i_10441 = 0; i_10441 < (int64_t) 32; i_10441++) {\n                for (int64_t i_10445 = 0; i_10445 < dzlz7bUZLztZRz20Umz20U32z7dUzg_6611; i_10445++) {\n                    f16 defunc_0_f_res_7735;\n                    f16 redout_10447 = (f16) 0.0F;\n                    \n                    for (int64_t i_10448 = 0; i_10448 < (int64_t) 32; i_10448++) {\n                        f16 eta_p_7739;\n                        f16 eta_p_7740;\n                        f16 defunc_0_f_res_7741;\n                        f16 defunc_0_op_res_7738;\n                        f16 redout_tmp_11039;\n                        \n                        eta_p_7739 = futrts_from_bits16(((__global uint16_t *) mem_10768)[gtid_7728 + i_10441 * (m_6610 * (int64_t) 32) + i_10448 * m_6610]);\n                        eta_p_7740 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10445 * (int64_t) 32 + i_10448]);\n                        defunc_0_f_res_7741 = eta_p_7739 * eta_p_7740;\n                        defunc_0_op_res_7738 = defunc_0_f_res_7741 + redout_10447;\n                        redout_tmp_11039 = defunc_0_op_res_7738;\n                        redout_10447 = redout_tmp_11039;\n                    }\n                    defunc_0_f_res_7735 = redout_10447;\n                    ((__global uint16_t *) color_10856)[phys_tid_7729 + i_10445 * num_threads_10902] = futrts_to_bits16(defunc_0_f_res_7735);\n                }\n                for (int64_t i_10451 = 0; i_10451 < (int64_t) 32; i_10451++) {\n                    f16 defunc_0_f_res_7744;\n                    f16 redout_10453 = (f16) 0.0F;\n                    \n                    for (int64_t i_10454 = 0; i_10454 < dzlz7bUZLztZRz20Umz20U32z7dUzg_6611; i_10454++) {\n                        f16 eta_p_7748;\n                        f16 eta_p_7749;\n                        f16 defunc_0_f_res_7750;\n       ", "                 f16 defunc_0_op_res_7747;\n                        f16 redout_tmp_11041;\n                        \n                        eta_p_7748 = futrts_from_bits16(((__global uint16_t *) color_10856)[phys_tid_7729 + i_10454 * num_threads_10902]);\n                        eta_p_7749 = futrts_from_bits16(((__global uint16_t *) mem_10778)[i_10454 + i_10451 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611]);\n                        defunc_0_f_res_7750 = eta_p_7748 * eta_p_7749;\n                        defunc_0_op_res_7747 = defunc_0_f_res_7750 + redout_10453;\n                        redout_tmp_11041 = defunc_0_op_res_7747;\n                        redout_10453 = redout_tmp_11041;\n                    }\n                    defunc_0_f_res_7744 = redout_10453;\n                    mem_10802[i_10451] = defunc_0_f_res_7744;\n                }\n                for (int64_t i_0 = 0; i_0 < (int64_t) 32; i_0++) {\n                    mem_10788[i_10441 * (int64_t) 32 + i_0] = mem_10802[i_0];\n                }\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 32; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 32; i_1++) {\n                    ((__global uint16_t *) mem_10820)[gtid_7728 + (i_0 * (m_6610 * (int64_t) 32) + i_1 * m_6610)] = futrts_to_bits16(mem_10788[i_0 * (int64_t) 32 + i_1]);\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_7724\n}\nFUTHARK_KERNEL_SIZED(run32zisegmap_8175_dim1, 1, 1)\nvoid run32zisegmap_8175(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t num_tblocks_8153, int64_t num_threads_10924, int32_t virt_num_tblocks_11111, __global unsigned char *K_mem_10473, __global unsigned char *mem_10695, __global unsigned char *mem_10705, __global unsigned char *mem_10736, __global unsigned char *color_10859)\n{\n    #define segmap_tblock_sizze_8152 (run32zisegmap_8175zisegmap_tblock_sizze_", "8152)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11113;\n    int32_t tblock_sizze_11116;\n    int32_t wave_sizze_11115;\n    int32_t block_id_11114;\n    int32_t global_tid_11112;\n    int64_t phys_tid_8175;\n    int32_t phys_tblock_id_11117;\n    int32_t iterations_11118;\n    \n    local_tid_11113 = get_local_id(0);\n    tblock_sizze_11116 = get_local_size(0);\n    wave_sizze_11115 = LOCKSTEP_WIDTH;\n    block_id_11114 = get_tblock_id(0);\n    global_tid_11112 = block_id_11114 * tblock_sizze_11116 + local_tid_11113;\n    phys_tid_8175 = sext_i32_i64(global_tid_11112);\n    phys_tblock_id_11117 = get_tblock_id(0);\n    iterations_11118 = sdiv_up32(virt_num_tblocks_11111 - phys_tblock_id_11117, sext_i64_i32(num_tblocks_8153));\n    for (int32_t i_11119 = 0; i_11119 < iterations_11118; i_11119++) {\n        int32_t virt_tblock_id_11120;\n        int64_t global_tid_11121;\n        int64_t slice_11122;\n        int64_t slice_11123;\n        int64_t gtid_8173;\n        int64_t remnant_11124;\n        int64_t gtid_8174;\n        int64_t remnant_11125;\n        \n        virt_tblock_id_11120 = phys_tblock_id_11117 + i_11119 * sext_i64_i32(num_tblocks_8153);\n        global_tid_11121 = sext_i32_i64(virt_tblock_id_11120) * segmap_tblock_sizze_8152 + sext_i32_i64(local_tid_11113);\n        slice_11122 = (int64_t) 32;\n        slice_11123 = m_6610 * slice_11122;\n        gtid_8173 = squot64(global_tid_11121, slice_11122);\n        remnant_11124 = global_tid_11121 - gtid_8173 * slice_11122;\n        gtid_8174 = remnant_11124;\n        remnant_11125 = remnant_11124 - gtid_8174;\n        if (slt64(gtid_8173, m_6610) && slt64(gtid_8174, (int64_t) 32)) {\n            f16 mem_10719[(int64_t) 32];\n            \n            for (int64_t i_10457 = 0; i_10457 < dzlz7bUZLztZRz20Umz20U32z7dUzg_6611; i_10457++) {\n                f16 defunc_0_f_res_8179;\n                f16 redout_10459 = (f16) 0.0F;\n                \n                for (int64_t i_10460 = 0; i_10460 < (int64_t) 32; i_10460++) {\n ",
                                    "                   f16 eta_p_8183;\n                    f16 eta_p_8184;\n                    f16 defunc_0_f_res_8185;\n                    f16 defunc_0_op_res_8182;\n                    f16 redout_tmp_11127;\n                    \n                    eta_p_8183 = futrts_from_bits16(((__global uint16_t *) mem_10695)[gtid_8173 * (int64_t) 32 + gtid_8174 + i_10460 * ((int64_t) 32 * m_6610)]);\n                    eta_p_8184 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10457 * (int64_t) 32 + i_10460]);\n                    defunc_0_f_res_8185 = eta_p_8183 * eta_p_8184;\n                    defunc_0_op_res_8182 = defunc_0_f_res_8185 + redout_10459;\n                    redout_tmp_11127 = defunc_0_op_res_8182;\n                    redout_10459 = redout_tmp_11127;\n                }\n                defunc_0_f_res_8179 = redout_10459;\n                ((__global uint16_t *) color_10859)[phys_tid_8175 + i_10457 * num_threads_10924] = futrts_to_bits16(defunc_0_f_res_8179);\n            }\n            for (int64_t i_10463 = 0; i_10463 < (int64_t) 32; i_10463++) {\n                f16 defunc_0_f_res_8188;\n                f16 redout_10465 = (f16) 0.0F;\n                \n                for (int64_t i_10466 = 0; i_10466 < dzlz7bUZLztZRz20Umz20U32z7dUzg_6611; i_10466++) {\n                    f16 eta_p_8192;\n                    f16 eta_p_8193;\n                    f16 defunc_0_f_res_8194;\n                    f16 defunc_0_op_res_8191;\n                    f16 redout_tmp_11129;\n                    \n                    eta_p_8192 = futrts_from_bits16(((__global uint16_t *) color_10859)[phys_tid_8175 + i_10466 * num_threads_10924]);\n                    eta_p_8193 = futrts_from_bits16(((__global uint16_t *) mem_10705)[i_10466 + i_10463 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611]);\n                    defunc_0_f_res_8194 = eta_p_8192 * eta_p_8193;\n                    defunc_0_op_res_8191 = defunc_0_f_res_8194 + redout_10465;\n                    redout_tmp_11129 = defunc_0_op_res_8191;\n            ", "        redout_10465 = redout_tmp_11129;\n                }\n                defunc_0_f_res_8188 = redout_10465;\n                mem_10719[i_10463] = defunc_0_f_res_8188;\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 32; i_0++) {\n                ((__global uint16_t *) mem_10736)[gtid_8173 * (int64_t) 32 + gtid_8174 + i_0 * ((int64_t) 32 * m_6610)] = futrts_to_bits16(mem_10719[i_0]);\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_8152\n}\nFUTHARK_KERNEL_SIZED(run32zisegmap_intrablock_10048_dim1, 1, 1)\nvoid run32zisegmap_intrablock_10048(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t one_intra_par_min_8158, int64_t full_tiles_10076, int64_t kk_10234, __global unsigned char *V_mem_10474, __global unsigned char *ext_mem_10569, __global unsigned char *mem_10670)\n{\n    volatile __local unsigned char *color_10865_backing_1 = &shared_mem[0];\n    const int64_t color_10865_backing_1_offset = 0 + (int64_t) 512;\n    volatile __local unsigned char *color_10864_backing_0 = &shared_mem[color_10865_backing_1_offset];\n    const int64_t color_10864_backing_0_offset = color_10865_backing_1_offset + (int64_t) 512;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11354;\n    int32_t tblock_sizze_11357;\n    int32_t wave_sizze_11356;\n    int32_t block_id_11355;\n    int32_t global_tid_11353;\n    int64_t gid_flat_10048;\n    int64_t slice_11360;\n    int64_t slice_11361;\n    int64_t ltid_pre_11358;\n    int64_t remnant_11362;\n    int64_t ltid_pre_11359;\n    int64_t remnant_11363;\n    int64_t slice_11364;\n    int64_t slice_11365;\n    int64_t slice_11366;\n    int64_t gtid_8282;\n    int64_t remnant_11367;\n    int64_t gid_y_10046;\n    int64_t remnant_11368;\n    int64_t gid_x_10047;\n    int64_t remnant_11369;\n    __local unsigned char *color_10864;\n    __local unsigned char *color_10865;\n    int64_t iii_1", "0049;\n    int64_t jjj_10050;\n    f16 mem_10611[(int64_t) 4 * (int64_t) 4];\n    int64_t ltid_flat_10064;\n    int64_t ltid_y_10063;\n    int64_t ltid_x_10062;\n    f16 mem_10594[(int64_t) 4 * (int64_t) 4];\n    f16 ext_mem_10646[(int64_t) 4 * (int64_t) 4];\n    f16 mem_param_10614[(int64_t) 4 * (int64_t) 4];\n    int64_t ltid_flat_10256;\n    int64_t ltid_flat_10301;\n    f16 mem_10666[(int64_t) 4 * (int64_t) 4];\n    int64_t ltid_flat_10362;\n    int64_t ltid_y_10361;\n    int64_t ltid_x_10360;\n    int64_t binop_x_10377;\n    int64_t binop_y_10382;\n    int64_t slice_11393;\n    int64_t slice_11394;\n    int64_t slice_11395;\n    int64_t reg_tile_i_11390;\n    int64_t remnant_11396;\n    int64_t reg_tile_i_11391;\n    int64_t remnant_11397;\n    int64_t reg_tile_i_11392;\n    int64_t remnant_11398;\n    int64_t tile_dim_start_11399;\n    int64_t tile_dim_start_11400;\n    int64_t tile_dim_start_11401;\n    \n    local_tid_11354 = get_local_id(0);\n    tblock_sizze_11357 = get_local_size(0);\n    wave_sizze_11356 = LOCKSTEP_WIDTH;\n    block_id_11355 = get_tblock_id(0);\n    global_tid_11353 = block_id_11355 * tblock_sizze_11357 + local_tid_11354;\n    gid_flat_10048 = sext_i32_i64(block_id_11355);\n    slice_11360 = (int64_t) 8;\n    slice_11361 = (int64_t) 8 * slice_11360;\n    ltid_pre_11358 = squot64(sext_i32_i64(local_tid_11354), slice_11360);\n    remnant_11362 = sext_i32_i64(local_tid_11354) - ltid_pre_11358 * slice_11360;\n    ltid_pre_11359 = remnant_11362;\n    remnant_11363 = remnant_11362 - ltid_pre_11359;\n    slice_11364 = (int64_t) 1;\n    slice_11365 = slice_11364;\n    slice_11366 = m_6610 * slice_11365;\n    gtid_8282 = squot64(sext_i32_i64(block_id_11355), slice_11365);\n    remnant_11367 = sext_i32_i64(block_id_11355) - gtid_8282 * slice_11365;\n    gid_y_10046 = squot64(remnant_11367, slice_11364);\n    remnant_11368 = remnant_11367 - gid_y_10046 * slice_11364;\n    gid_x_10047 = remnant_11368;\n    remnant_11369 = remnant_11368 - gid_x_10047;\n    color_10864 = (__local unsigned char *) colo",
                                    "r_10864_backing_0;\n    color_10865 = (__local unsigned char *) color_10865_backing_1;\n    iii_10049 = (int64_t) 32 * gid_y_10046;\n    jjj_10050 = (int64_t) 32 * gid_x_10047;\n    ltid_flat_10064 = sext_i32_i64(local_tid_11354);\n    ltid_y_10063 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10062 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    for (int64_t i_10067 = 0; i_10067 < (int64_t) 4; i_10067++) {\n        for (int64_t i_10070 = 0; i_10070 < (int64_t) 4; i_10070++) {\n            mem_10594[i_10067 * (int64_t) 4 + i_10070] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 4; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 4; i_1++) {\n            mem_10611[i_0 * (int64_t) 4 + i_1] = mem_10594[i_0 * (int64_t) 4 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < (int64_t) 4 * (int64_t) 4; i_2++)\n        mem_param_10614[i_2] = mem_10611[i_2];\n    for (int64_t i_10077 = 0; i_10077 < full_tiles_10076; i_10077++) {\n        int64_t kk_10081;\n        int64_t ltid_flat_10101;\n        int64_t ltid_flat_10142;\n        f16 mem_10639[(int64_t) 4 * (int64_t) 4];\n        int64_t ltid_flat_10199;\n        int64_t ltid_y_10198;\n        int64_t ltid_x_10197;\n        int64_t binop_x_10212;\n        int64_t binop_y_10217;\n        f16 mem_param_tmp_11372[(int64_t) 4 * (int64_t) 4];\n        \n        kk_10081 = (int64_t) 8 * i_10077;\n        ltid_flat_10101 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11376 = 0; nest_i_11376 < (int64_t) 4; nest_i_11376++) {\n            for (int64_t nest_i_11377 = 0; nest_i_11377 < (int64_t) 1; nest_i_11377++) {\n                int64_t ltid_seq_10104;\n                int64_t ltid_seq_10105;\n                int64_t ltid_y_10102;\n                int64_t ltid_x_10103;\n                int64_t binop_y_10106;\n                int64_t k_10107;\n                int64_t binop_y_10108;\n                int64_t i_10109;\n                int64_", "t gtid_10110;\n                int64_t defunc_0_map_res_seqdim_idx_10111;\n                bool cond_10112;\n                f16 defunc_0_map_res_elem_10113;\n                bool cond_10117;\n                int64_t defunc_0_map_res_loc_ind_10118;\n                \n                ltid_seq_10104 = nest_i_11376;\n                ltid_seq_10105 = nest_i_11377;\n                ltid_y_10102 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10103 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10106 = (int64_t) 8 * ltid_seq_10105;\n                k_10107 = ltid_x_10103 + binop_y_10106;\n                binop_y_10108 = (int64_t) 8 * ltid_seq_10104;\n                i_10109 = ltid_y_10102 + binop_y_10108;\n                gtid_10110 = iii_10049 + i_10109;\n                defunc_0_map_res_seqdim_idx_10111 = kk_10081 + k_10107;\n                cond_10112 = slt64(gtid_10110, (int64_t) 32);\n                if (cond_10112) {\n                    f16 A_elem_10115 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_8282 * one_intra_par_min_8158 + gtid_10110 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + defunc_0_map_res_seqdim_idx_10111]);\n                    \n                    defunc_0_map_res_elem_10113 = A_elem_10115;\n                } else {\n                    defunc_0_map_res_elem_10113 = (f16) 0.0F;\n                }\n                cond_10117 = slt64(k_10107, (int64_t) 8);\n                if (cond_10117) {\n                    int64_t binop_y_10119;\n                    int64_t x_10120;\n                    \n                    binop_y_10119 = (int64_t) 8 * i_10109;\n                    x_10120 = k_10107 + binop_y_10119;\n                    defunc_0_map_res_loc_ind_10118 = x_10120;\n                } else {\n                    defunc_0_map_res_loc_ind_10118 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10118) && slt64(defunc_0_map_res_loc_ind_10118, (int64_t) 256)) {\n                    (", "(__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10118] = futrts_to_bits16(defunc_0_map_res_elem_10113);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10142 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11378 = 0; nest_i_11378 < (int64_t) 4; nest_i_11378++) {\n            for (int64_t nest_i_11379 = 0; nest_i_11379 < (int64_t) 1; nest_i_11379++) {\n                int64_t ltid_seq_10145;\n                int64_t ltid_seq_10146;\n                int64_t ltid_y_10143;\n                int64_t ltid_x_10144;\n                int64_t binop_y_10147;\n                int64_t k_10148;\n                int64_t binop_y_10149;\n                int64_t i_10150;\n                int64_t gtid_10151;\n                int64_t as_transformed_row_seqdim_idx_10152;\n                bool cond_10153;\n                f16 as_transformed_row_elem_10154;\n                bool cond_10158;\n                int64_t as_transformed_row_loc_ind_10159;\n                \n                ltid_seq_10145 = nest_i_11378;\n                ltid_seq_10146 = nest_i_11379;\n                ltid_y_10143 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10144 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10147 = (int64_t) 8 * ltid_seq_10146;\n                k_10148 = ltid_y_10143 + binop_y_10147;\n                binop_y_10149 = (int64_t) 8 * ltid_seq_10145;\n                i_10150 = ltid_x_10144 + binop_y_10149;\n                gtid_10151 = jjj_10050 + i_10150;\n                as_transformed_row_seqdim_idx_10152 = kk_10081 + k_10148;\n                cond_10153 = slt64(gtid_10151, (int64_t) 32);\n                if (cond_10153) {\n                    f16 A_elem_10156 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10152 * (int64_t) 32 + gtid_10151]);\n                    \n                    as_transformed_row_elem_10154 = A_elem_10156;\n                } else {\n            ",
                                    "        as_transformed_row_elem_10154 = (f16) 0.0F;\n                }\n                cond_10158 = slt64(k_10148, (int64_t) 8);\n                if (cond_10158) {\n                    int64_t binop_y_10160;\n                    int64_t x_10161;\n                    \n                    binop_y_10160 = (int64_t) 32 * k_10148;\n                    x_10161 = i_10150 + binop_y_10160;\n                    as_transformed_row_loc_ind_10159 = x_10161;\n                } else {\n                    as_transformed_row_loc_ind_10159 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_10159) && slt64(as_transformed_row_loc_ind_10159, (int64_t) 256)) {\n                    ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10159] = futrts_to_bits16(as_transformed_row_elem_10154);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10199 = sext_i32_i64(local_tid_11354);\n        ltid_y_10198 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n        ltid_x_10197 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n        binop_x_10212 = (int64_t) 4 * ltid_y_10198;\n        binop_y_10217 = (int64_t) 4 * ltid_x_10197;\n        for (int64_t i_10202 = 0; i_10202 < (int64_t) 8; i_10202++) {\n            int64_t binop_y_10219 = (int64_t) 32 * i_10202;\n            \n            for (int64_t i_10206 = 0; i_10206 < (int64_t) 4; i_10206++) {\n                int64_t binop_x_10213;\n                int64_t binop_y_10214;\n                int64_t defunc_0_map_res_loc_ind_64_10215;\n                f16 x_10431;\n                \n                binop_x_10213 = i_10206 + binop_x_10212;\n                binop_y_10214 = (int64_t) 8 * binop_x_10213;\n                defunc_0_map_res_loc_ind_64_10215 = i_10202 + binop_y_10214;\n                x_10431 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10215]);\n                for (int64_t i_10209 = 0; i_10209 < (int64_t) 4; i_10209++) {\n       ", "             int64_t binop_x_10218;\n                    int64_t as_transformed_row_loc_ind_64_10220;\n                    f16 as_transformed_row_loc_elem_10221;\n                    f16 c_10222;\n                    f16 defunc_0_f_res_10225;\n                    f16 defunc_0_op_res_10228;\n                    \n                    binop_x_10218 = i_10209 + binop_y_10217;\n                    as_transformed_row_loc_ind_64_10220 = binop_x_10218 + binop_y_10219;\n                    as_transformed_row_loc_elem_10221 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10220]);\n                    c_10222 = mem_param_10614[i_10206 * (int64_t) 4 + i_10209];\n                    defunc_0_f_res_10225 = as_transformed_row_loc_elem_10221 * x_10431;\n                    defunc_0_op_res_10228 = c_10222 + defunc_0_f_res_10225;\n                    mem_param_10614[i_10206 * (int64_t) 4 + i_10209] = defunc_0_op_res_10228;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < (int64_t) 4; i_0++) {\n            for (int64_t i_1 = 0; i_1 < (int64_t) 4; i_1++) {\n                mem_10639[i_0 * (int64_t) 4 + i_1] = mem_param_10614[i_0 * (int64_t) 4 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < (int64_t) 4 * (int64_t) 4; i_3++)\n            mem_param_tmp_11372[i_3] = mem_10639[i_3];\n        for (int32_t i_4 = 0; i_4 < (int64_t) 4 * (int64_t) 4; i_4++)\n            mem_param_10614[i_4] = mem_param_tmp_11372[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < (int64_t) 4 * (int64_t) 4; i_5++)\n        ext_mem_10646[i_5] = mem_param_10614[i_5];\n    ltid_flat_10256 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11383 = 0; nest_i_11383 < (int64_t) 4; nest_i_11383++) {\n        for (int64_t nest_i_11384 = 0; nest_i_11384 < (int64_t) 1; nest_i_11384++) {\n            int64_t ltid_seq_10259;\n            int64_t ltid_seq_10260;\n            int64_t ltid_y_10257;\n            int64_t ltid_x_10258;", "\n            int64_t binop_y_10261;\n            int64_t k_10262;\n            int64_t binop_y_10263;\n            int64_t i_10264;\n            int64_t gtid_10265;\n            int64_t defunc_0_map_res_seqdim_idx_10266;\n            bool binop_x_10267;\n            bool binop_y_10268;\n            bool cond_10269;\n            f16 defunc_0_map_res_elem_10270;\n            bool cond_10274;\n            int64_t defunc_0_map_res_loc_ind_10275;\n            \n            ltid_seq_10259 = nest_i_11383;\n            ltid_seq_10260 = nest_i_11384;\n            ltid_y_10257 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10258 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10261 = (int64_t) 8 * ltid_seq_10260;\n            k_10262 = ltid_x_10258 + binop_y_10261;\n            binop_y_10263 = (int64_t) 8 * ltid_seq_10259;\n            i_10264 = ltid_y_10257 + binop_y_10263;\n            gtid_10265 = iii_10049 + i_10264;\n            defunc_0_map_res_seqdim_idx_10266 = kk_10234 + k_10262;\n            binop_x_10267 = slt64(gtid_10265, (int64_t) 32);\n            binop_y_10268 = slt64(defunc_0_map_res_seqdim_idx_10266, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n            cond_10269 = binop_x_10267 && binop_y_10268;\n            if (cond_10269) {\n                f16 A_elem_10272 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_8282 * one_intra_par_min_8158 + gtid_10265 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + defunc_0_map_res_seqdim_idx_10266]);\n                \n                defunc_0_map_res_elem_10270 = A_elem_10272;\n            } else {\n                defunc_0_map_res_elem_10270 = (f16) 0.0F;\n            }\n            cond_10274 = slt64(k_10262, (int64_t) 8);\n            if (cond_10274) {\n                int64_t binop_y_10276;\n                int64_t x_10277;\n                \n                binop_y_10276 = (int64_t) 8 * i_10264;\n                x_10277 = k_10262 + binop_y_10276;\n                defunc_0_map_res_loc_ind_10275 = x_10277;\n           ",
                                    " } else {\n                defunc_0_map_res_loc_ind_10275 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10275) && slt64(defunc_0_map_res_loc_ind_10275, (int64_t) 256)) {\n                ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10275] = futrts_to_bits16(defunc_0_map_res_elem_10270);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10301 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11385 = 0; nest_i_11385 < (int64_t) 4; nest_i_11385++) {\n        for (int64_t nest_i_11386 = 0; nest_i_11386 < (int64_t) 1; nest_i_11386++) {\n            int64_t ltid_seq_10304;\n            int64_t ltid_seq_10305;\n            int64_t ltid_y_10302;\n            int64_t ltid_x_10303;\n            int64_t binop_y_10306;\n            int64_t k_10307;\n            int64_t binop_y_10308;\n            int64_t i_10309;\n            int64_t gtid_10310;\n            int64_t as_transformed_row_seqdim_idx_10311;\n            bool binop_x_10312;\n            bool binop_y_10313;\n            bool cond_10314;\n            f16 as_transformed_row_elem_10315;\n            bool cond_10319;\n            int64_t as_transformed_row_loc_ind_10320;\n            \n            ltid_seq_10304 = nest_i_11385;\n            ltid_seq_10305 = nest_i_11386;\n            ltid_y_10302 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10303 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10306 = (int64_t) 8 * ltid_seq_10305;\n            k_10307 = ltid_y_10302 + binop_y_10306;\n            binop_y_10308 = (int64_t) 8 * ltid_seq_10304;\n            i_10309 = ltid_x_10303 + binop_y_10308;\n            gtid_10310 = jjj_10050 + i_10309;\n            as_transformed_row_seqdim_idx_10311 = kk_10234 + k_10307;\n            binop_x_10312 = slt64(gtid_10310, (int64_t) 32);\n            binop_y_10313 = slt64(as_transformed_row_seqdim_idx_10311, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n            cond_10314 = binop_x_10312 && bin", "op_y_10313;\n            if (cond_10314) {\n                f16 A_elem_10317 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10311 * (int64_t) 32 + gtid_10310]);\n                \n                as_transformed_row_elem_10315 = A_elem_10317;\n            } else {\n                as_transformed_row_elem_10315 = (f16) 0.0F;\n            }\n            cond_10319 = slt64(k_10307, (int64_t) 8);\n            if (cond_10319) {\n                int64_t binop_y_10321;\n                int64_t x_10322;\n                \n                binop_y_10321 = (int64_t) 32 * k_10307;\n                x_10322 = i_10309 + binop_y_10321;\n                as_transformed_row_loc_ind_10320 = x_10322;\n            } else {\n                as_transformed_row_loc_ind_10320 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_10320) && slt64(as_transformed_row_loc_ind_10320, (int64_t) 256)) {\n                ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10320] = futrts_to_bits16(as_transformed_row_elem_10315);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10362 = sext_i32_i64(local_tid_11354);\n    ltid_y_10361 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10360 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    binop_x_10377 = (int64_t) 4 * ltid_y_10361;\n    binop_y_10382 = (int64_t) 4 * ltid_x_10360;\n    for (int64_t i_10365 = 0; i_10365 < (int64_t) 8; i_10365++) {\n        int64_t cmpop_x_10367;\n        bool cond_10368;\n        int64_t binop_y_10384;\n        \n        cmpop_x_10367 = kk_10234 + i_10365;\n        cond_10368 = slt64(cmpop_x_10367, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n        binop_y_10384 = (int64_t) 32 * i_10365;\n        if (cond_10368) {\n            for (int64_t i_10371 = 0; i_10371 < (int64_t) 4; i_10371++) {\n                int64_t binop_x_10378;\n                int64_t binop_y_10379;\n                int64_t defunc_0_map_res_loc_ind_64_10380;\n           ", "     f16 x_10428;\n                \n                binop_x_10378 = i_10371 + binop_x_10377;\n                binop_y_10379 = (int64_t) 8 * binop_x_10378;\n                defunc_0_map_res_loc_ind_64_10380 = i_10365 + binop_y_10379;\n                x_10428 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10380]);\n                for (int64_t i_10374 = 0; i_10374 < (int64_t) 4; i_10374++) {\n                    int64_t binop_x_10383;\n                    int64_t as_transformed_row_loc_ind_64_10385;\n                    f16 as_transformed_row_loc_elem_10386;\n                    f16 c_10387;\n                    f16 defunc_0_f_res_10390;\n                    f16 defunc_0_op_res_10393;\n                    \n                    binop_x_10383 = i_10374 + binop_y_10382;\n                    as_transformed_row_loc_ind_64_10385 = binop_x_10383 + binop_y_10384;\n                    as_transformed_row_loc_elem_10386 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10385]);\n                    c_10387 = ext_mem_10646[i_10371 * (int64_t) 4 + i_10374];\n                    defunc_0_f_res_10390 = as_transformed_row_loc_elem_10386 * x_10428;\n                    defunc_0_op_res_10393 = c_10387 + defunc_0_f_res_10390;\n                    ext_mem_10646[i_10371 * (int64_t) 4 + i_10374] = defunc_0_op_res_10393;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 4; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 4; i_1++) {\n            mem_10666[i_0 * (int64_t) 4 + i_1] = ext_mem_10646[i_0 * (int64_t) 4 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11393 = (int64_t) 8;\n    slice_11394 = (int64_t) 8 * slice_11393;\n    slice_11395 = slice_11394;\n    reg_tile_i_11390 = squot64(sext_i32_i64(local_tid_11354), slice_11394);\n    remnant_11396 = sext_i32_i64(local_tid_11354) - reg_tile_i_11390 * slice_11394;\n    reg_tile_i_11391 = squot64(remnant_11396, slice_11393);\n  ",
                                    "  remnant_11397 = remnant_11396 - reg_tile_i_11391 * slice_11393;\n    reg_tile_i_11392 = remnant_11397;\n    remnant_11398 = remnant_11397 - reg_tile_i_11392;\n    tile_dim_start_11399 = gtid_8282 + reg_tile_i_11390;\n    tile_dim_start_11400 = (int64_t) 4 * ((int64_t) 8 * gid_y_10046 + reg_tile_i_11391);\n    tile_dim_start_11401 = (int64_t) 4 * ((int64_t) 8 * gid_x_10047 + reg_tile_i_11392);\n    for (int64_t nest_i_11402 = 0; nest_i_11402 < (int64_t) 1; nest_i_11402++) {\n        for (int64_t nest_i_11403 = 0; nest_i_11403 < (int64_t) 4; nest_i_11403++) {\n            for (int64_t nest_i_11404 = 0; nest_i_11404 < (int64_t) 4; nest_i_11404++) {\n                if ((slt64(tile_dim_start_11399 + nest_i_11402, m_6610) && slt64(tile_dim_start_11400 + nest_i_11403, (int64_t) 32)) && slt64(tile_dim_start_11401 + nest_i_11404, (int64_t) 32)) {\n                    f16 tmp_11405 = mem_10666[nest_i_11403 * (int64_t) 4 + nest_i_11404];\n                    \n                    ((__global uint16_t *) mem_10670)[(tile_dim_start_11399 + nest_i_11402) * (int64_t) 1024 + (tile_dim_start_11400 + nest_i_11403) * (int64_t) 32 + (tile_dim_start_11401 + nest_i_11404)] = futrts_to_bits16(tmp_11405);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n}\nFUTHARK_KERNEL\nvoid run32zisegmap_intrablock_7758(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t one_intra_par_min_7680, int64_t bytes_10743, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10749)\n{\n    volatile __local unsigned char *red_arr_mem_11089_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11089_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_1", "1070_backing_2 = &shared_mem[red_arr_mem_11089_backing_3_offset];\n    const int64_t red_arr_mem_11070_backing_2_offset = red_arr_mem_11089_backing_3_offset + ((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10858_backing_1 = &shared_mem[red_arr_mem_11070_backing_2_offset];\n    const int64_t color_10858_backing_1_offset = red_arr_mem_11070_backing_2_offset + (bytes_10743 + srem64((int64_t) 8 - srem64(bytes_10743, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10857_backing_0 = &shared_mem[color_10858_backing_1_offset];\n    const int64_t color_10857_backing_0_offset = color_10858_backing_1_offset + (int64_t) 2048;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11046;\n    int32_t tblock_sizze_11049;\n    int32_t wave_sizze_11048;\n    int32_t block_id_11047;\n    int32_t global_tid_11045;\n    int64_t phys_tblock_id_7758;\n    int64_t slice_11053;\n    int64_t slice_11054;\n    int64_t slice_11055;\n    int64_t ltid_pre_11050;\n    int64_t remnant_11056;\n    int64_t ltid_pre_11051;\n    int64_t remnant_11057;\n    int64_t ltid_pre_11052;\n    int64_t remnant_11058;\n    int64_t slice_11062;\n    int64_t slice_11063;\n    int64_t slice_11064;\n    int64_t ltid_pre_11059;\n    int64_t remnant_11065;\n    int64_t ltid_pre_11060;\n    int64_t remnant_11066;\n    int64_t ltid_pre_11061;\n    int64_t remnant_11067;\n    int64_t slice_11068;\n    int64_t gtid_7757;\n    int64_t remnant_11069;\n    __local unsigned char *color_10857;\n    __local unsigned char *color_10858;\n    int64_t phys_tid_7765;\n    __local unsigned char *red_arr_mem_11070;\n    int64_t gtid_7762;\n    int64_t gtid_7763;\n    int64_t gtid_7764;\n    int64_t dims_flat_11072;\n    f16 eta_p_7766;\n    f16 eta_p_7767;\n    f16 eta_p_11074;\n    f16 eta_p_11075;\n    bool lti", "d_in_bounds_11077;\n    int32_t skip_threads_11078;\n    bool no_carry_in_11084;\n    int64_t phys_tid_7778;\n    __local unsigned char *red_arr_mem_11089;\n    int64_t gtid_7775;\n    int64_t gtid_7776;\n    int64_t gtid_7777;\n    int64_t dims_flat_11091;\n    f16 eta_p_7779;\n    f16 eta_p_7780;\n    f16 eta_p_11093;\n    f16 eta_p_11094;\n    bool ltid_in_bounds_11096;\n    int32_t skip_threads_11097;\n    bool no_carry_in_11103;\n    int32_t num_chunks_11108;\n    \n    local_tid_11046 = get_local_id(0);\n    tblock_sizze_11049 = get_local_size(0);\n    wave_sizze_11048 = LOCKSTEP_WIDTH;\n    block_id_11047 = get_tblock_id(0);\n    global_tid_11045 = block_id_11047 * tblock_sizze_11049 + local_tid_11046;\n    phys_tblock_id_7758 = sext_i32_i64(block_id_11047);\n    slice_11053 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;\n    slice_11054 = (int64_t) 32 * slice_11053;\n    slice_11055 = (int64_t) 32 * slice_11054;\n    ltid_pre_11050 = squot64(sext_i32_i64(local_tid_11046), slice_11054);\n    remnant_11056 = sext_i32_i64(local_tid_11046) - ltid_pre_11050 * slice_11054;\n    ltid_pre_11051 = squot64(remnant_11056, slice_11053);\n    remnant_11057 = remnant_11056 - ltid_pre_11051 * slice_11053;\n    ltid_pre_11052 = remnant_11057;\n    remnant_11058 = remnant_11057 - ltid_pre_11052;\n    slice_11062 = (int64_t) 32;\n    slice_11063 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * slice_11062;\n    slice_11064 = (int64_t) 32 * slice_11063;\n    ltid_pre_11059 = squot64(sext_i32_i64(local_tid_11046), slice_11063);\n    remnant_11065 = sext_i32_i64(local_tid_11046) - ltid_pre_11059 * slice_11063;\n    ltid_pre_11060 = squot64(remnant_11065, slice_11062);\n    remnant_11066 = remnant_11065 - ltid_pre_11060 * slice_11062;\n    ltid_pre_11061 = remnant_11066;\n    remnant_11067 = remnant_11066 - ltid_pre_11061;\n    slice_11068 = m_6610;\n    gtid_7757 = sext_i32_i64(block_id_11047);\n    remnant_11069 = sext_i32_i64(block_id_11047) - gtid_7757;\n    color_10857 = (__local unsigned char *) color_10857_backing_0;\n    color_10858 ",
                                    "= (__local unsigned char *) color_10858_backing_1;\n    phys_tid_7765 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11070 = (__local unsigned char *) red_arr_mem_11070_backing_2;\n    gtid_7762 = sext_i32_i64(sext_i64_i32(ltid_pre_11059));\n    gtid_7763 = sext_i32_i64(sext_i64_i32(ltid_pre_11060));\n    gtid_7764 = sext_i32_i64(sext_i64_i32(ltid_pre_11061));\n    if ((slt64(gtid_7762, (int64_t) 32) && slt64(gtid_7763, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) && slt64(gtid_7764, (int64_t) 32)) {\n        f16 eta_p_7771;\n        f16 eta_p_7772;\n        f16 defunc_0_f_res_7773;\n        \n        eta_p_7771 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_7757 * (int64_t) 1024 + gtid_7762 * (int64_t) 32 + gtid_7764]);\n        eta_p_7772 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_7763 * (int64_t) 32 + gtid_7764]);\n        defunc_0_f_res_7773 = eta_p_7771 * eta_p_7772;\n        ((__local uint16_t *) red_arr_mem_11070)[gtid_7762 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) + gtid_7763 * (int64_t) 32 + gtid_7764] = futrts_to_bits16(defunc_0_f_res_7773);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11072 = (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32;\n    ltid_in_bounds_11077 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11077) {\n            eta_p_7767 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_7766 = eta_p_7767;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11078 = 1;\n        while (slt32(skip_threads_11078, 32)) {\n            bool thread_active_11079 = sle32(skip_threads_11078, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11077;\n       ", "     \n            if (thread_active_11079) {\n                // read operands\n                {\n                    eta_p_7766 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11078)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11080 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 32), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11078));\n                \n                if (thread_active_11079 && inactive_11080) {\n                    eta_p_7766 = eta_p_7767;\n                }\n                if (thread_active_11079) {\n                    if (!inactive_11080) {\n                        f16 defunc_0_op_res_7768 = eta_p_7766 + eta_p_7767;\n                        \n                        eta_p_7766 = defunc_0_op_res_7768;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11079) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7766);\n                    eta_p_7767 = eta_p_7766;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11078 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11077) {\n            ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_7766);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which of", "fset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11081;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n                eta_p_11075 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11074 = eta_p_11075;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11081 = 1;\n            while (slt32(skip_threads_11081, 32)) {\n                bool thread_active_11082 = sle32(skip_threads_11081, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077);\n                \n                if (thread_active_11082) {\n                    // read operands\n                    {\n                        eta_p_11074 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11081)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11083 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), (int64_t) 32), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11081) * 32 + 32 - 1));\n                    \n                    if (thread_active_11082 && inactive_11083) {\n                        eta_p_11074 = eta_p_11075;\n                    }\n                    if (thread_active_11082) {\n                        if (!inactive_11083) {\n                            f16 defunc_0_op_res_11076 = eta_p_11074 + eta_p_11075;\n                            \n                            eta_p_11074 = defunc_0_op_res_11076;\n                        }\n                    }\n                }\n                if (s",
                                    "le32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11082) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11074);\n                        eta_p_11075 = eta_p_11074;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11081 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11084 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11077;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11084) {\n                eta_p_7767 = eta_p_7766;\n                eta_p_7766 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11085 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 32), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11084) {\n                if (inactive_11085) {\n                    eta_p_7766 = eta_p_7767;\n                }\n            }\n            if (!no_carry_in_11084) {\n                if (!inactive_11085) {\n                    f16 defunc_0_op_res_7768 = eta_p_7766 + eta_p_7767;\n                    \n                    eta_p_7766 = defunc_0_op_res_7768;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11084) {\n                ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7766);\n            }\n        }\n    }\n    barrier", "(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n            ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7767);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11086 = sdiv_up32(32 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i64_i32(one_intra_par_min_7680));\n        \n        for (int32_t chunk_i_11087 = 0; chunk_i_11087 < num_chunks_11086; chunk_i_11087++) {\n            int32_t i_11088 = chunk_i_11087 * sext_i64_i32(one_intra_par_min_7680) + local_tid_11046;\n            \n            if (slt32(i_11088, 32 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611))) {\n                ((__local uint16_t *) color_10858)[sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611))) * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) * sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611))] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[(int64_t) 31 + sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611))) * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) * sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) * (int64_t) 32]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_7778 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11089 = (__local unsigned char *) red_arr_mem_11089_backing_3;\n    gtid_7775 = sext_i32_i64(sext_i64_i32(ltid_pre_11050));\n    gtid_7776 = sext_i32_i64(sext_i64_i32(ltid_pre_11051));\n    gtid_7777 = sext_i32_i64(sext_i64_i32(ltid_pre_11052));\n    if ((slt64(gtid_7775, (int64_t) 32) ", "&& slt64(gtid_7776, (int64_t) 32)) && slt64(gtid_7777, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) {\n        f16 eta_p_7784;\n        f16 eta_p_7785;\n        f16 defunc_0_f_res_7786;\n        \n        eta_p_7784 = futrts_from_bits16(((__local uint16_t *) color_10858)[gtid_7775 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_7777]);\n        eta_p_7785 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_7777 * (int64_t) 32 + gtid_7776]);\n        defunc_0_f_res_7786 = eta_p_7784 * eta_p_7785;\n        ((__local uint16_t *) red_arr_mem_11089)[gtid_7775 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + gtid_7776 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_7777] = futrts_to_bits16(defunc_0_f_res_7786);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11091 = (int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;\n    ltid_in_bounds_11096 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11096) {\n            eta_p_7780 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_7779 = eta_p_7780;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11097 = 1;\n        while (slt32(skip_threads_11097, 32)) {\n            bool thread_active_11098 = sle32(skip_threads_11097, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11096;\n            \n            if (thread_active_11098) {\n                // read operands\n                {\n                    eta_p_7779 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11097)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11099 = slt64(srem64(sext_i32_i64(lo",
                                    "cal_tid_11046), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11097));\n                \n                if (thread_active_11098 && inactive_11099) {\n                    eta_p_7779 = eta_p_7780;\n                }\n                if (thread_active_11098) {\n                    if (!inactive_11099) {\n                        f16 defunc_0_op_res_7781 = eta_p_7779 + eta_p_7780;\n                        \n                        eta_p_7779 = defunc_0_op_res_7781;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11098) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7779);\n                    eta_p_7780 = eta_p_7779;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11097 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11096) {\n            ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_7779);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11100;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n                eta_p_11094 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_1104", "6 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11093 = eta_p_11094;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11100 = 1;\n            while (slt32(skip_threads_11100, 32)) {\n                bool thread_active_11101 = sle32(skip_threads_11100, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096);\n                \n                if (thread_active_11101) {\n                    // read operands\n                    {\n                        eta_p_11093 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11100)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11102 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11100) * 32 + 32 - 1));\n                    \n                    if (thread_active_11101 && inactive_11102) {\n                        eta_p_11093 = eta_p_11094;\n                    }\n                    if (thread_active_11101) {\n                        if (!inactive_11102) {\n                            f16 defunc_0_op_res_11095 = eta_p_11093 + eta_p_11094;\n                            \n                            eta_p_11093 = defunc_0_op_res_11095;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11101) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11093);\n            ", "            eta_p_11094 = eta_p_11093;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11100 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11103 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11096;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11103) {\n                eta_p_7780 = eta_p_7779;\n                eta_p_7779 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11104 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11103) {\n                if (inactive_11104) {\n                    eta_p_7779 = eta_p_7780;\n                }\n            }\n            if (!no_carry_in_11103) {\n                if (!inactive_11104) {\n                    f16 defunc_0_op_res_7781 = eta_p_7779 + eta_p_7780;\n                    \n                    eta_p_7779 = defunc_0_op_res_7781;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11103) {\n                ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7779);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n            ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_7780);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FE",
                                    "NCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11105 = sdiv_up32(1024, sext_i64_i32(one_intra_par_min_7680));\n        \n        for (int32_t chunk_i_11106 = 0; chunk_i_11106 < num_chunks_11105; chunk_i_11106++) {\n            int32_t i_11107 = chunk_i_11106 * sext_i64_i32(one_intra_par_min_7680) + local_tid_11046;\n            \n            if (slt32(i_11107, 1024)) {\n                ((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11107, 32)) * (int64_t) 32 + sext_i32_i64(i_11107 - squot32(i_11107, 32) * 32)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 - (int64_t) 1 + sext_i32_i64(squot32(i_11107, 32)) * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + sext_i32_i64(i_11107 - squot32(i_11107, 32) * 32) * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11108 = sdiv_up32(1024, sext_i64_i32(one_intra_par_min_7680));\n    for (int32_t chunk_i_11109 = 0; chunk_i_11109 < num_chunks_11108; chunk_i_11109++) {\n        int32_t i_11110 = chunk_i_11109 * sext_i64_i32(one_intra_par_min_7680) + local_tid_11046;\n        \n        if (slt32(i_11110, 1024)) {\n            ((__global uint16_t *) mem_10749)[gtid_7757 * (int64_t) 1024 + sext_i32_i64(squot32(i_11110, 32)) * (int64_t) 32 + sext_i32_i64(i_11110 - squot32(i_11110, 32) * 32)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11110, 32)) * (int64_t) 32 + sext_i32_i64(i_11110 - squot32(i_11110, 32) * 32)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL\nvoid run32zisegmap_intrablock_8199(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t one_intra_par_min_8158, int64_t bytes_10673, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char", " *V_mem_10474, __global unsigned char *mem_10679)\n{\n    volatile __local unsigned char *red_arr_mem_11173_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11173_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11154_backing_2 = &shared_mem[red_arr_mem_11173_backing_3_offset];\n    const int64_t red_arr_mem_11154_backing_2_offset = red_arr_mem_11173_backing_3_offset + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10861_backing_1 = &shared_mem[red_arr_mem_11154_backing_2_offset];\n    const int64_t color_10861_backing_1_offset = red_arr_mem_11154_backing_2_offset + (bytes_10673 + srem64((int64_t) 8 - srem64(bytes_10673, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10860_backing_0 = &shared_mem[color_10861_backing_1_offset];\n    const int64_t color_10860_backing_0_offset = color_10861_backing_1_offset + (int64_t) 64;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11134;\n    int32_t tblock_sizze_11137;\n    int32_t wave_sizze_11136;\n    int32_t block_id_11135;\n    int32_t global_tid_11133;\n    int64_t phys_tblock_id_8199;\n    int64_t slice_11140;\n    int64_t slice_11141;\n    int64_t ltid_pre_11138;\n    int64_t remnant_11142;\n    int64_t ltid_pre_11139;\n    int64_t remnant_11143;\n    int64_t slice_11146;\n    int64_t slice_11147;\n    int64_t ltid_pre_11144;\n    int64_t remnant_11148;\n    int64_t ltid_pre_11145;\n    int64_t remnant_11149;\n    int64_t slice_11150;\n    int64_t slice_11151;\n    int64_t gtid_8197;\n    int64_t remnant_11152;\n    int64_t gtid_8198;\n    int64_t remnant_11153;\n    __local unsigned char", " *color_10860;\n    __local unsigned char *color_10861;\n    int64_t phys_tid_8205;\n    __local unsigned char *red_arr_mem_11154;\n    int64_t gtid_8203;\n    int64_t gtid_8204;\n    int64_t dims_flat_11156;\n    f16 eta_p_8206;\n    f16 eta_p_8207;\n    f16 eta_p_11158;\n    f16 eta_p_11159;\n    bool ltid_in_bounds_11161;\n    int32_t skip_threads_11162;\n    bool no_carry_in_11168;\n    int64_t phys_tid_8216;\n    __local unsigned char *red_arr_mem_11173;\n    int64_t gtid_8214;\n    int64_t gtid_8215;\n    int64_t dims_flat_11175;\n    f16 eta_p_8217;\n    f16 eta_p_8218;\n    f16 eta_p_11177;\n    f16 eta_p_11178;\n    bool ltid_in_bounds_11180;\n    int32_t skip_threads_11181;\n    bool no_carry_in_11187;\n    int32_t num_chunks_11192;\n    \n    local_tid_11134 = get_local_id(0);\n    tblock_sizze_11137 = get_local_size(0);\n    wave_sizze_11136 = LOCKSTEP_WIDTH;\n    block_id_11135 = get_tblock_id(0);\n    global_tid_11133 = block_id_11135 * tblock_sizze_11137 + local_tid_11134;\n    phys_tblock_id_8199 = sext_i32_i64(block_id_11135);\n    slice_11140 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;\n    slice_11141 = (int64_t) 32 * slice_11140;\n    ltid_pre_11138 = squot64(sext_i32_i64(local_tid_11134), slice_11140);\n    remnant_11142 = sext_i32_i64(local_tid_11134) - ltid_pre_11138 * slice_11140;\n    ltid_pre_11139 = remnant_11142;\n    remnant_11143 = remnant_11142 - ltid_pre_11139;\n    slice_11146 = (int64_t) 32;\n    slice_11147 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * slice_11146;\n    ltid_pre_11144 = squot64(sext_i32_i64(local_tid_11134), slice_11146);\n    remnant_11148 = sext_i32_i64(local_tid_11134) - ltid_pre_11144 * slice_11146;\n    ltid_pre_11145 = remnant_11148;\n    remnant_11149 = remnant_11148 - ltid_pre_11145;\n    slice_11150 = (int64_t) 32;\n    slice_11151 = m_6610 * slice_11150;\n    gtid_8197 = squot64(sext_i32_i64(block_id_11135), slice_11150);\n    remnant_11152 = sext_i32_i64(block_id_11135) - gtid_8197 * slice_11150;\n    gtid_8198 = remnant_11152;\n    remnant_11153 = remnant_11152 - ",
                                    "gtid_8198;\n    color_10860 = (__local unsigned char *) color_10860_backing_0;\n    color_10861 = (__local unsigned char *) color_10861_backing_1;\n    phys_tid_8205 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_11154 = (__local unsigned char *) red_arr_mem_11154_backing_2;\n    gtid_8203 = sext_i32_i64(sext_i64_i32(ltid_pre_11144));\n    gtid_8204 = sext_i32_i64(sext_i64_i32(ltid_pre_11145));\n    if (slt64(gtid_8203, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) && slt64(gtid_8204, (int64_t) 32)) {\n        f16 eta_p_8210;\n        f16 eta_p_8211;\n        f16 defunc_0_f_res_8212;\n        \n        eta_p_8210 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8197 * (int64_t) 1024 + gtid_8198 * (int64_t) 32 + gtid_8204]);\n        eta_p_8211 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8203 * (int64_t) 32 + gtid_8204]);\n        defunc_0_f_res_8212 = eta_p_8210 * eta_p_8211;\n        ((__local uint16_t *) red_arr_mem_11154)[gtid_8203 * (int64_t) 32 + gtid_8204] = futrts_to_bits16(defunc_0_f_res_8212);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11156 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32;\n    ltid_in_bounds_11161 = slt64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11161) {\n            eta_p_8207 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_8206 = eta_p_8207;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11162 = 1;\n        while (slt32(skip_threads_11162, 32)) {\n            bool thread_active_11163 = sle32(skip_threads_11162, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11161;\n            \n            if (thread_active_11163) {\n                // read operands\n                {\n   ", "                 eta_p_8206 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11162)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11164 = slt64(srem64(sext_i32_i64(local_tid_11134), (int64_t) 32), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11162));\n                \n                if (thread_active_11163 && inactive_11164) {\n                    eta_p_8206 = eta_p_8207;\n                }\n                if (thread_active_11163) {\n                    if (!inactive_11164) {\n                        f16 defunc_0_op_res_8208 = eta_p_8206 + eta_p_8207;\n                        \n                        eta_p_8206 = defunc_0_op_res_8208;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11163) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8206);\n                    eta_p_8207 = eta_p_8206;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11162 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11161) {\n            ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_8206);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11165;\n        \n     ", "   // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n                eta_p_11159 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11158 = eta_p_11159;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11165 = 1;\n            while (slt32(skip_threads_11165, 32)) {\n                bool thread_active_11166 = sle32(skip_threads_11165, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161);\n                \n                if (thread_active_11166) {\n                    // read operands\n                    {\n                        eta_p_11158 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11165)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11167 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), (int64_t) 32), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11165) * 32 + 32 - 1));\n                    \n                    if (thread_active_11166 && inactive_11167) {\n                        eta_p_11158 = eta_p_11159;\n                    }\n                    if (thread_active_11166) {\n                        if (!inactive_11167) {\n                            f16 defunc_0_op_res_11160 = eta_p_11158 + eta_p_11159;\n                            \n                            eta_p_11158 = defunc_0_op_res_11160;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n   ",
                                    "             }\n                if (thread_active_11166) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11158);\n                        eta_p_11159 = eta_p_11158;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11165 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11168 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11161;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11168) {\n                eta_p_8207 = eta_p_8206;\n                eta_p_8206 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11169 = slt64(srem64(sext_i32_i64(local_tid_11134), (int64_t) 32), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11168) {\n                if (inactive_11169) {\n                    eta_p_8206 = eta_p_8207;\n                }\n            }\n            if (!no_carry_in_11168) {\n                if (!inactive_11169) {\n                    f16 defunc_0_op_res_8208 = eta_p_8206 + eta_p_8207;\n                    \n                    eta_p_8206 = defunc_0_op_res_8208;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11168) {\n                ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8206);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(loca", "l_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n            ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8207);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11170 = sdiv_up32(sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i64_i32(one_intra_par_min_8158));\n        \n        for (int32_t chunk_i_11171 = 0; chunk_i_11171 < num_chunks_11170; chunk_i_11171++) {\n            int32_t i_11172 = chunk_i_11171 * sext_i64_i32(one_intra_par_min_8158) + local_tid_11134;\n            \n            if (slt32(i_11172, sext_i64_i32(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611))) {\n                ((__local uint16_t *) color_10861)[sext_i32_i64(i_11172)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[(int64_t) 31 + sext_i32_i64(i_11172) * (int64_t) 32]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_8216 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_11173 = (__local unsigned char *) red_arr_mem_11173_backing_3;\n    gtid_8214 = sext_i32_i64(sext_i64_i32(ltid_pre_11138));\n    gtid_8215 = sext_i32_i64(sext_i64_i32(ltid_pre_11139));\n    if (slt64(gtid_8214, (int64_t) 32) && slt64(gtid_8215, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) {\n        f16 eta_p_8221;\n        f16 eta_p_8222;\n        f16 defunc_0_f_res_8223;\n        \n        eta_p_8221 = futrts_from_bits16(((__local uint16_t *) color_10861)[gtid_8215]);\n        eta_p_8222 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_8215 * (int64_t) 32 + gtid_8214]);\n        defunc_0_f_res_8223 = eta_p_8221 * eta_p_8222;\n        ((__local uint16_t *) red_arr_mem_11173)[gtid_8214 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_8215] = futrts_to_bits16(defunc_0_f_res_8223);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11175 = (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;\n ", "   ltid_in_bounds_11180 = slt64(sext_i32_i64(local_tid_11134), (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11180) {\n            eta_p_8218 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_8217 = eta_p_8218;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11181 = 1;\n        while (slt32(skip_threads_11181, 32)) {\n            bool thread_active_11182 = sle32(skip_threads_11181, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11180;\n            \n            if (thread_active_11182) {\n                // read operands\n                {\n                    eta_p_8217 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11181)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11183 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11181));\n                \n                if (thread_active_11182 && inactive_11183) {\n                    eta_p_8217 = eta_p_8218;\n                }\n                if (thread_active_11182) {\n                    if (!inactive_11183) {\n                        f16 defunc_0_op_res_8219 = eta_p_8217 + eta_p_8218;\n                        \n                        eta_p_8217 = defunc_0_op_res_8219;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11182) {\n                // write result\n                {\n                    ((volatile __local ",
                                    "uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8217);\n                    eta_p_8218 = eta_p_8217;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11181 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11180) {\n            ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_8217);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11184;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n                eta_p_11178 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11177 = eta_p_11178;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11184 = 1;\n            while (slt32(skip_threads_11184, 32)) {\n                bool thread_active_11185 = sle32(skip_threads_11184, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180);\n                \n                if (thread_active_11185) {\n                    // read operands\n                    {\n                        eta_p_11177 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11184)]);\n                    }\n                }\n                // pe", "rform operation\n                {\n                    bool inactive_11186 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11184) * 32 + 32 - 1));\n                    \n                    if (thread_active_11185 && inactive_11186) {\n                        eta_p_11177 = eta_p_11178;\n                    }\n                    if (thread_active_11185) {\n                        if (!inactive_11186) {\n                            f16 defunc_0_op_res_11179 = eta_p_11177 + eta_p_11178;\n                            \n                            eta_p_11177 = defunc_0_op_res_11179;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11185) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11177);\n                        eta_p_11178 = eta_p_11177;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11184 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11187 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11180;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11187) {\n                eta_p_8218 = eta_p_8217;\n                eta_p_8217 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11188 = slt64(srem64(", "sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11187) {\n                if (inactive_11188) {\n                    eta_p_8217 = eta_p_8218;\n                }\n            }\n            if (!no_carry_in_11187) {\n                if (!inactive_11188) {\n                    f16 defunc_0_op_res_8219 = eta_p_8217 + eta_p_8218;\n                    \n                    eta_p_8217 = defunc_0_op_res_8219;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11187) {\n                ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8217);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n            ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8218);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11189 = sdiv_up32(32, sext_i64_i32(one_intra_par_min_8158));\n        \n        for (int32_t chunk_i_11190 = 0; chunk_i_11190 < num_chunks_11189; chunk_i_11190++) {\n            int32_t i_11191 = chunk_i_11190 * sext_i64_i32(one_intra_par_min_8158) + local_tid_11134;\n            \n            if (slt32(i_11191, 32)) {\n                ((__local uint16_t *) color_10860)[sext_i32_i64(i_11191)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 - (int64_t) 1 + sext_i32_i64(i_11191) * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11192 = sdiv_up32(32, sext_i64_i32(one_intra_par_min_8158",
                                    "));\n    for (int32_t chunk_i_11193 = 0; chunk_i_11193 < num_chunks_11192; chunk_i_11193++) {\n        int32_t i_11194 = chunk_i_11193 * sext_i64_i32(one_intra_par_min_8158) + local_tid_11134;\n        \n        if (slt32(i_11194, 32)) {\n            ((__global uint16_t *) mem_10679)[gtid_8197 * (int64_t) 1024 + gtid_8198 * (int64_t) 32 + sext_i32_i64(i_11194)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10860)[sext_i32_i64(i_11194)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run32zisegmap_intrablock_9688_dim1, 1, 1)\nvoid run32zisegmap_intrablock_9688(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t gridDim_x_9682, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10565)\n{\n    volatile __local unsigned char *color_10863_backing_1 = &shared_mem[0];\n    const int64_t color_10863_backing_1_offset = 0 + (int64_t) 512;\n    volatile __local unsigned char *color_10862_backing_0 = &shared_mem[color_10863_backing_1_offset];\n    const int64_t color_10862_backing_0_offset = color_10863_backing_1_offset + (int64_t) 576;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11198;\n    int32_t tblock_sizze_11201;\n    int32_t wave_sizze_11200;\n    int32_t block_id_11199;\n    int32_t global_tid_11197;\n    int64_t gid_flat_9688;\n    int64_t slice_11204;\n    int64_t slice_11205;\n    int64_t ltid_pre_11202;\n    int64_t remnant_11206;\n    int64_t ltid_pre_11203;\n    int64_t remnant_11207;\n    int64_t slice_11208;\n    int64_t slice_11209;\n    int64_t slice_11210;\n    int64_t gtid_8235;\n    int64_t remnant_11211;\n    int64_t gid_y_9686;\n    int64_t remnant_11212;\n    int64_t gid_x_9687;\n    int64_t remnant_11213;\n    __local unsigned char *color_10862;\n    __local unsigned char *color_10863;\n    int64_t iii_9689;\n    int64_t jjj_9690;\n    f16 mem_10506[(int64_t) 4 * (int64_t) 4];\n    int", "64_t ltid_flat_9704;\n    int64_t ltid_y_9703;\n    int64_t ltid_x_9702;\n    f16 mem_10489[(int64_t) 4 * (int64_t) 4];\n    f16 ext_mem_10541[(int64_t) 4 * (int64_t) 4];\n    f16 mem_param_10509[(int64_t) 4 * (int64_t) 4];\n    int64_t ltid_flat_9896;\n    int64_t ltid_flat_9941;\n    f16 mem_10561[(int64_t) 4 * (int64_t) 4];\n    int64_t ltid_flat_10002;\n    int64_t ltid_y_10001;\n    int64_t ltid_x_10000;\n    int64_t binop_x_10017;\n    int64_t binop_x_10022;\n    int64_t slice_11237;\n    int64_t slice_11238;\n    int64_t slice_11239;\n    int64_t reg_tile_i_11234;\n    int64_t remnant_11240;\n    int64_t reg_tile_i_11235;\n    int64_t remnant_11241;\n    int64_t reg_tile_i_11236;\n    int64_t remnant_11242;\n    int64_t tile_dim_start_11243;\n    int64_t tile_dim_start_11244;\n    int64_t tile_dim_start_11245;\n    \n    local_tid_11198 = get_local_id(0);\n    tblock_sizze_11201 = get_local_size(0);\n    wave_sizze_11200 = LOCKSTEP_WIDTH;\n    block_id_11199 = get_tblock_id(0);\n    global_tid_11197 = block_id_11199 * tblock_sizze_11201 + local_tid_11198;\n    gid_flat_9688 = sext_i32_i64(block_id_11199);\n    slice_11204 = (int64_t) 8;\n    slice_11205 = (int64_t) 8 * slice_11204;\n    ltid_pre_11202 = squot64(sext_i32_i64(local_tid_11198), slice_11204);\n    remnant_11206 = sext_i32_i64(local_tid_11198) - ltid_pre_11202 * slice_11204;\n    ltid_pre_11203 = remnant_11206;\n    remnant_11207 = remnant_11206 - ltid_pre_11203;\n    slice_11208 = gridDim_x_9682;\n    slice_11209 = slice_11208;\n    slice_11210 = m_6610 * slice_11209;\n    gtid_8235 = squot64(sext_i32_i64(block_id_11199), slice_11209);\n    remnant_11211 = sext_i32_i64(block_id_11199) - gtid_8235 * slice_11209;\n    gid_y_9686 = squot64(remnant_11211, slice_11208);\n    remnant_11212 = remnant_11211 - gid_y_9686 * slice_11208;\n    gid_x_9687 = remnant_11212;\n    remnant_11213 = remnant_11212 - gid_x_9687;\n    color_10862 = (__local unsigned char *) color_10862_backing_0;\n    color_10863 = (__local unsigned char *) color_10863_backing_1;\n   ", " iii_9689 = (int64_t) 32 * gid_y_9686;\n    jjj_9690 = (int64_t) 32 * gid_x_9687;\n    ltid_flat_9704 = sext_i32_i64(local_tid_11198);\n    ltid_y_9703 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_9702 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    for (int64_t i_9707 = 0; i_9707 < (int64_t) 4; i_9707++) {\n        for (int64_t i_9710 = 0; i_9710 < (int64_t) 4; i_9710++) {\n            mem_10489[i_9707 * (int64_t) 4 + i_9710] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 4; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 4; i_1++) {\n            mem_10506[i_0 * (int64_t) 4 + i_1] = mem_10489[i_0 * (int64_t) 4 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < (int64_t) 4 * (int64_t) 4; i_2++)\n        mem_param_10509[i_2] = mem_10506[i_2];\n    for (int64_t i_9717 = 0; i_9717 < (int64_t) 4; i_9717++) {\n        int64_t kk_9721;\n        int64_t ltid_flat_9741;\n        int64_t ltid_flat_9782;\n        f16 mem_10534[(int64_t) 4 * (int64_t) 4];\n        int64_t ltid_flat_9839;\n        int64_t ltid_y_9838;\n        int64_t ltid_x_9837;\n        int64_t binop_x_9852;\n        int64_t binop_x_9857;\n        f16 mem_param_tmp_11216[(int64_t) 4 * (int64_t) 4];\n        \n        kk_9721 = (int64_t) 8 * i_9717;\n        ltid_flat_9741 = sext_i32_i64(local_tid_11198);\n        for (int64_t nest_i_11220 = 0; nest_i_11220 < (int64_t) 4; nest_i_11220++) {\n            for (int64_t nest_i_11221 = 0; nest_i_11221 < (int64_t) 1; nest_i_11221++) {\n                int64_t ltid_seq_9744;\n                int64_t ltid_seq_9745;\n                int64_t ltid_y_9742;\n                int64_t ltid_x_9743;\n                int64_t binop_y_9746;\n                int64_t k_9747;\n                int64_t binop_y_9748;\n                int64_t i_9749;\n                int64_t gtid_9750;\n                int64_t as_transformed_row_seqdim_idx_9751;\n                bool cond_9752;\n                f16 as_tra",
                                    "nsformed_row_elem_9753;\n                bool cond_9757;\n                int64_t as_transformed_row_loc_ind_9758;\n                \n                ltid_seq_9744 = nest_i_11220;\n                ltid_seq_9745 = nest_i_11221;\n                ltid_y_9742 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9743 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9746 = (int64_t) 8 * ltid_seq_9745;\n                k_9747 = ltid_x_9743 + binop_y_9746;\n                binop_y_9748 = (int64_t) 8 * ltid_seq_9744;\n                i_9749 = ltid_y_9742 + binop_y_9748;\n                gtid_9750 = iii_9689 + i_9749;\n                as_transformed_row_seqdim_idx_9751 = kk_9721 + k_9747;\n                cond_9752 = slt64(gtid_9750, (int64_t) 32);\n                if (cond_9752) {\n                    f16 A_elem_9755 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8235 * (int64_t) 1024 + gtid_9750 * (int64_t) 32 + as_transformed_row_seqdim_idx_9751]);\n                    \n                    as_transformed_row_elem_9753 = A_elem_9755;\n                } else {\n                    as_transformed_row_elem_9753 = (f16) 0.0F;\n                }\n                cond_9757 = slt64(k_9747, (int64_t) 8);\n                if (cond_9757) {\n                    int64_t binop_y_9759;\n                    int64_t x_9760;\n                    \n                    binop_y_9759 = (int64_t) 8 * i_9749;\n                    x_9760 = k_9747 + binop_y_9759;\n                    as_transformed_row_loc_ind_9758 = x_9760;\n                } else {\n                    as_transformed_row_loc_ind_9758 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9758) && slt64(as_transformed_row_loc_ind_9758, (int64_t) 256)) {\n                    ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9758] = futrts_to_bits16(as_transformed_row_elem_9753);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FEN", "CE);\n        ltid_flat_9782 = sext_i32_i64(local_tid_11198);\n        for (int64_t nest_i_11222 = 0; nest_i_11222 < (int64_t) 4; nest_i_11222++) {\n            for (int64_t nest_i_11223 = 0; nest_i_11223 < (int64_t) 1; nest_i_11223++) {\n                int64_t ltid_seq_9785;\n                int64_t ltid_seq_9786;\n                int64_t ltid_y_9783;\n                int64_t ltid_x_9784;\n                int64_t binop_y_9787;\n                int64_t k_9788;\n                int64_t binop_y_9789;\n                int64_t i_9790;\n                int64_t gtid_9791;\n                int64_t as_transformed_row_seqdim_idx_9792;\n                bool cond_9793;\n                f16 as_transformed_row_elem_9794;\n                bool cond_9798;\n                int64_t as_transformed_row_loc_ind_9799;\n                \n                ltid_seq_9785 = nest_i_11222;\n                ltid_seq_9786 = nest_i_11223;\n                ltid_y_9783 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9784 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9787 = (int64_t) 8 * ltid_seq_9786;\n                k_9788 = ltid_x_9784 + binop_y_9787;\n                binop_y_9789 = (int64_t) 8 * ltid_seq_9785;\n                i_9790 = ltid_y_9783 + binop_y_9789;\n                gtid_9791 = jjj_9690 + i_9790;\n                as_transformed_row_seqdim_idx_9792 = kk_9721 + k_9788;\n                cond_9793 = slt64(gtid_9791, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n                if (cond_9793) {\n                    f16 A_elem_9796 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9791 * (int64_t) 32 + as_transformed_row_seqdim_idx_9792]);\n                    \n                    as_transformed_row_elem_9794 = A_elem_9796;\n                } else {\n                    as_transformed_row_elem_9794 = (f16) 0.0F;\n                }\n                cond_9798 = slt64(k_9788, (int64_t) 8);\n                if (cond_9798) {\n                    int64_t binop_y_9800;\n          ", "          int64_t x_9801;\n                    \n                    binop_y_9800 = (int64_t) 9 * i_9790;\n                    x_9801 = k_9788 + binop_y_9800;\n                    as_transformed_row_loc_ind_9799 = x_9801;\n                } else {\n                    as_transformed_row_loc_ind_9799 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9799) && slt64(as_transformed_row_loc_ind_9799, (int64_t) 288)) {\n                    ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9799] = futrts_to_bits16(as_transformed_row_elem_9794);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9839 = sext_i32_i64(local_tid_11198);\n        ltid_y_9838 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n        ltid_x_9837 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n        binop_x_9852 = (int64_t) 4 * ltid_y_9838;\n        binop_x_9857 = (int64_t) 4 * ltid_x_9837;\n        for (int64_t i_9842 = 0; i_9842 < (int64_t) 8; i_9842++) {\n            for (int64_t i_9846 = 0; i_9846 < (int64_t) 4; i_9846++) {\n                int64_t binop_x_9853;\n                int64_t binop_y_9854;\n                int64_t as_transformed_row_loc_ind_64_9855;\n                f16 x_10437;\n                \n                binop_x_9853 = i_9846 + binop_x_9852;\n                binop_y_9854 = (int64_t) 8 * binop_x_9853;\n                as_transformed_row_loc_ind_64_9855 = i_9842 + binop_y_9854;\n                x_10437 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_9855]);\n                for (int64_t i_9849 = 0; i_9849 < (int64_t) 4; i_9849++) {\n                    int64_t binop_x_9858;\n                    int64_t binop_y_9859;\n                    int64_t as_transformed_row_loc_ind_64_9860;\n                    f16 as_transformed_row_loc_elem_9861;\n                    f16 c_9862;\n                    f16 defunc_0_f_res_9865;\n                    f16 defunc_0_op_res_9868;\n  ",
                                    "                  \n                    binop_x_9858 = i_9849 + binop_x_9857;\n                    binop_y_9859 = (int64_t) 9 * binop_x_9858;\n                    as_transformed_row_loc_ind_64_9860 = i_9842 + binop_y_9859;\n                    as_transformed_row_loc_elem_9861 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_9860]);\n                    c_9862 = mem_param_10509[i_9846 * (int64_t) 4 + i_9849];\n                    defunc_0_f_res_9865 = as_transformed_row_loc_elem_9861 * x_10437;\n                    defunc_0_op_res_9868 = c_9862 + defunc_0_f_res_9865;\n                    mem_param_10509[i_9846 * (int64_t) 4 + i_9849] = defunc_0_op_res_9868;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < (int64_t) 4; i_0++) {\n            for (int64_t i_1 = 0; i_1 < (int64_t) 4; i_1++) {\n                mem_10534[i_0 * (int64_t) 4 + i_1] = mem_param_10509[i_0 * (int64_t) 4 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < (int64_t) 4 * (int64_t) 4; i_3++)\n            mem_param_tmp_11216[i_3] = mem_10534[i_3];\n        for (int32_t i_4 = 0; i_4 < (int64_t) 4 * (int64_t) 4; i_4++)\n            mem_param_10509[i_4] = mem_param_tmp_11216[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < (int64_t) 4 * (int64_t) 4; i_5++)\n        ext_mem_10541[i_5] = mem_param_10509[i_5];\n    ltid_flat_9896 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11227 = 0; nest_i_11227 < (int64_t) 4; nest_i_11227++) {\n        for (int64_t nest_i_11228 = 0; nest_i_11228 < (int64_t) 1; nest_i_11228++) {\n            int64_t ltid_seq_9899;\n            int64_t ltid_seq_9900;\n            int64_t ltid_y_9897;\n            int64_t ltid_x_9898;\n            int64_t binop_y_9901;\n            int64_t k_9902;\n            int64_t binop_y_9903;\n            int64_t i_9904;\n            int64_t gtid_9905;\n            int64_t as_transformed_row_seqdim_idx_9906;\n            bool binop_x_9907;\n            ", "bool binop_y_9908;\n            bool cond_9909;\n            f16 as_transformed_row_elem_9910;\n            bool cond_9914;\n            int64_t as_transformed_row_loc_ind_9915;\n            \n            ltid_seq_9899 = nest_i_11227;\n            ltid_seq_9900 = nest_i_11228;\n            ltid_y_9897 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9898 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9901 = (int64_t) 8 * ltid_seq_9900;\n            k_9902 = ltid_x_9898 + binop_y_9901;\n            binop_y_9903 = (int64_t) 8 * ltid_seq_9899;\n            i_9904 = ltid_y_9897 + binop_y_9903;\n            gtid_9905 = iii_9689 + i_9904;\n            as_transformed_row_seqdim_idx_9906 = (int64_t) 32 + k_9902;\n            binop_x_9907 = slt64(gtid_9905, (int64_t) 32);\n            binop_y_9908 = slt64(as_transformed_row_seqdim_idx_9906, (int64_t) 32);\n            cond_9909 = binop_x_9907 && binop_y_9908;\n            if (cond_9909) {\n                f16 A_elem_9912 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8235 * (int64_t) 1024 + gtid_9905 * (int64_t) 32 + as_transformed_row_seqdim_idx_9906]);\n                \n                as_transformed_row_elem_9910 = A_elem_9912;\n            } else {\n                as_transformed_row_elem_9910 = (f16) 0.0F;\n            }\n            cond_9914 = slt64(k_9902, (int64_t) 8);\n            if (cond_9914) {\n                int64_t binop_y_9916;\n                int64_t x_9917;\n                \n                binop_y_9916 = (int64_t) 8 * i_9904;\n                x_9917 = k_9902 + binop_y_9916;\n                as_transformed_row_loc_ind_9915 = x_9917;\n            } else {\n                as_transformed_row_loc_ind_9915 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_9915) && slt64(as_transformed_row_loc_ind_9915, (int64_t) 256)) {\n                ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9915] = futrts_to_bits16(as_transformed_row_elem_991", "0);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_9941 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11229 = 0; nest_i_11229 < (int64_t) 4; nest_i_11229++) {\n        for (int64_t nest_i_11230 = 0; nest_i_11230 < (int64_t) 1; nest_i_11230++) {\n            int64_t ltid_seq_9944;\n            int64_t ltid_seq_9945;\n            int64_t ltid_y_9942;\n            int64_t ltid_x_9943;\n            int64_t binop_y_9946;\n            int64_t k_9947;\n            int64_t binop_y_9948;\n            int64_t i_9949;\n            int64_t gtid_9950;\n            int64_t as_transformed_row_seqdim_idx_9951;\n            bool binop_x_9952;\n            bool binop_y_9953;\n            bool cond_9954;\n            f16 as_transformed_row_elem_9955;\n            bool cond_9959;\n            int64_t as_transformed_row_loc_ind_9960;\n            \n            ltid_seq_9944 = nest_i_11229;\n            ltid_seq_9945 = nest_i_11230;\n            ltid_y_9942 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9943 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9946 = (int64_t) 8 * ltid_seq_9945;\n            k_9947 = ltid_x_9943 + binop_y_9946;\n            binop_y_9948 = (int64_t) 8 * ltid_seq_9944;\n            i_9949 = ltid_y_9942 + binop_y_9948;\n            gtid_9950 = jjj_9690 + i_9949;\n            as_transformed_row_seqdim_idx_9951 = (int64_t) 32 + k_9947;\n            binop_x_9952 = slt64(gtid_9950, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n            binop_y_9953 = slt64(as_transformed_row_seqdim_idx_9951, (int64_t) 32);\n            cond_9954 = binop_x_9952 && binop_y_9953;\n            if (cond_9954) {\n                f16 A_elem_9957 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9950 * (int64_t) 32 + as_transformed_row_seqdim_idx_9951]);\n                \n                as_transformed_row_elem_9955 = A_elem_9957;\n            } else {\n                as_transformed_row_elem_9955 = (f16) 0.0F;\n            }\n            co",
                                    "nd_9959 = slt64(k_9947, (int64_t) 8);\n            if (cond_9959) {\n                int64_t binop_y_9961;\n                int64_t x_9962;\n                \n                binop_y_9961 = (int64_t) 9 * i_9949;\n                x_9962 = k_9947 + binop_y_9961;\n                as_transformed_row_loc_ind_9960 = x_9962;\n            } else {\n                as_transformed_row_loc_ind_9960 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_9960) && slt64(as_transformed_row_loc_ind_9960, (int64_t) 288)) {\n                ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9960] = futrts_to_bits16(as_transformed_row_elem_9955);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10002 = sext_i32_i64(local_tid_11198);\n    ltid_y_10001 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_10000 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    binop_x_10017 = (int64_t) 4 * ltid_y_10001;\n    binop_x_10022 = (int64_t) 4 * ltid_x_10000;\n    for (int64_t i_10005 = 0; i_10005 < (int64_t) 8; i_10005++) {\n        int64_t cmpop_x_10007;\n        bool cond_10008;\n        \n        cmpop_x_10007 = (int64_t) 32 + i_10005;\n        cond_10008 = slt64(cmpop_x_10007, (int64_t) 32);\n        if (cond_10008) {\n            for (int64_t i_10011 = 0; i_10011 < (int64_t) 4; i_10011++) {\n                int64_t binop_x_10018;\n                int64_t binop_y_10019;\n                int64_t as_transformed_row_loc_ind_64_10020;\n                f16 x_10434;\n                \n                binop_x_10018 = i_10011 + binop_x_10017;\n                binop_y_10019 = (int64_t) 8 * binop_x_10018;\n                as_transformed_row_loc_ind_64_10020 = i_10005 + binop_y_10019;\n                x_10434 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_10020]);\n                for (int64_t i_10014 = 0; i_10014 < (int64_t) 4; i_10014++) {\n                    int64_t binop_x_10023;\n                    int64_t b", "inop_y_10024;\n                    int64_t as_transformed_row_loc_ind_64_10025;\n                    f16 as_transformed_row_loc_elem_10026;\n                    f16 c_10027;\n                    f16 defunc_0_f_res_10030;\n                    f16 defunc_0_op_res_10033;\n                    \n                    binop_x_10023 = i_10014 + binop_x_10022;\n                    binop_y_10024 = (int64_t) 9 * binop_x_10023;\n                    as_transformed_row_loc_ind_64_10025 = i_10005 + binop_y_10024;\n                    as_transformed_row_loc_elem_10026 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_10025]);\n                    c_10027 = ext_mem_10541[i_10011 * (int64_t) 4 + i_10014];\n                    defunc_0_f_res_10030 = as_transformed_row_loc_elem_10026 * x_10434;\n                    defunc_0_op_res_10033 = c_10027 + defunc_0_f_res_10030;\n                    ext_mem_10541[i_10011 * (int64_t) 4 + i_10014] = defunc_0_op_res_10033;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < (int64_t) 4; i_0++) {\n        for (int64_t i_1 = 0; i_1 < (int64_t) 4; i_1++) {\n            mem_10561[i_0 * (int64_t) 4 + i_1] = ext_mem_10541[i_0 * (int64_t) 4 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11237 = (int64_t) 8;\n    slice_11238 = (int64_t) 8 * slice_11237;\n    slice_11239 = slice_11238;\n    reg_tile_i_11234 = squot64(sext_i32_i64(local_tid_11198), slice_11238);\n    remnant_11240 = sext_i32_i64(local_tid_11198) - reg_tile_i_11234 * slice_11238;\n    reg_tile_i_11235 = squot64(remnant_11240, slice_11237);\n    remnant_11241 = remnant_11240 - reg_tile_i_11235 * slice_11237;\n    reg_tile_i_11236 = remnant_11241;\n    remnant_11242 = remnant_11241 - reg_tile_i_11236;\n    tile_dim_start_11243 = gtid_8235 + reg_tile_i_11234;\n    tile_dim_start_11244 = (int64_t) 4 * ((int64_t) 8 * gid_y_9686 + reg_tile_i_11235);\n    tile_dim_start_11245 = (int64_t) 4 * ((int64_t) 8 * gid_x_9687 + reg_tile_i_11236);\n    ", "for (int64_t nest_i_11246 = 0; nest_i_11246 < (int64_t) 1; nest_i_11246++) {\n        for (int64_t nest_i_11247 = 0; nest_i_11247 < (int64_t) 4; nest_i_11247++) {\n            for (int64_t nest_i_11248 = 0; nest_i_11248 < (int64_t) 4; nest_i_11248++) {\n                if ((slt64(tile_dim_start_11243 + nest_i_11246, m_6610) && slt64(tile_dim_start_11244 + nest_i_11247, (int64_t) 32)) && slt64(tile_dim_start_11245 + nest_i_11248, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) {\n                    f16 tmp_11249 = mem_10561[nest_i_11247 * (int64_t) 4 + nest_i_11248];\n                    \n                    ((__global uint16_t *) mem_10565)[(tile_dim_start_11243 + nest_i_11246) * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + (tile_dim_start_11244 + nest_i_11247) * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + (tile_dim_start_11245 + nest_i_11248)] = futrts_to_bits16(tmp_11249);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run32zisegred_large_8260_dim1, 1, 1)\nvoid run32zisegred_large_8260(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t num_tblocks_8253, int64_t blocks_per_segment_11283, int64_t q_11284, int64_t num_virtblocks_11285, int64_t threads_per_segment_11286, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479, __global unsigned char *segred_tmp_mem_11287, __global unsigned char *counters_mem_11289)\n{\n    #define segred_tblock_sizze_8252 (run32zisegred_large_8260zisegred_tblock_sizze_8252)\n    #define chunk_sizze_11250 (run32zisegred_large_8260zichunk_sizze_11250)\n    \n    volatile __local unsigned char *sync_arr_mem_11318_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11318_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11316_backing_0 = &shared_mem[sync_arr_mem_11318_backing_1_offset];\n    const int64_t red_arr_f16_mem_11316_backing_0_offset = sync_arr_mem_11318_backing",
                                    "_1_offset + ((int64_t) 2 * segred_tblock_sizze_8252 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8252, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11312;\n    int32_t tblock_sizze_11315;\n    int32_t wave_sizze_11314;\n    int32_t block_id_11313;\n    int32_t global_tid_11311;\n    int64_t phys_tid_8260;\n    __local unsigned char *red_arr_f16_mem_11316;\n    __local unsigned char *sync_arr_mem_11318;\n    int32_t phys_tblock_id_11320;\n    int32_t iterations_11321;\n    \n    local_tid_11312 = get_local_id(0);\n    tblock_sizze_11315 = get_local_size(0);\n    wave_sizze_11314 = LOCKSTEP_WIDTH;\n    block_id_11313 = get_tblock_id(0);\n    global_tid_11311 = block_id_11313 * tblock_sizze_11315 + local_tid_11312;\n    phys_tid_8260 = sext_i32_i64(global_tid_11311);\n    red_arr_f16_mem_11316 = (__local unsigned char *) red_arr_f16_mem_11316_backing_0;\n    sync_arr_mem_11318 = (__local unsigned char *) sync_arr_mem_11318_backing_1;\n    phys_tblock_id_11320 = get_tblock_id(0);\n    iterations_11321 = sdiv_up32(sext_i64_i32(num_virtblocks_11285) - phys_tblock_id_11320, sext_i64_i32(num_tblocks_8253));\n    for (int32_t i_11322 = 0; i_11322 < iterations_11321; i_11322++) {\n        int32_t virt_tblock_id_11323;\n        int64_t flat_segment_id_11324;\n        int64_t global_tid_11325;\n        int64_t slice_11326;\n        int64_t slice_11327;\n        int64_t slice_11328;\n        int64_t gtid_8256;\n        int64_t remnant_11329;\n        int64_t gtid_8257;\n        int64_t remnant_11330;\n        int64_t gtid_8258;\n        int64_t remnant_11331;\n        int64_t gtid_8259;\n        f16 eta_p_block_res_acc_11332;\n        f16 eta_p_8261;\n        f16 eta_p_8262;\n        int64_t tblock_id_in_segment_11336;\n        int64_t block_base_offset_11337;\n        int32_t offset_11340;\n        int32_t skip_waves_11341;\n        f16 eta_p_11333;\n        f16 eta_p_11334;\n        \n        virt_tblock_id_11323 = phys_tblock_id_11320 + i_1", "1322 * sext_i64_i32(num_tblocks_8253);\n        flat_segment_id_11324 = squot64(sext_i32_i64(virt_tblock_id_11323), blocks_per_segment_11283);\n        global_tid_11325 = srem64(sext_i32_i64(virt_tblock_id_11323) * segred_tblock_sizze_8252 + sext_i32_i64(local_tid_11312), threads_per_segment_11286);\n        slice_11326 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;\n        slice_11327 = (int64_t) 32 * slice_11326;\n        slice_11328 = m_6610 * slice_11327;\n        gtid_8256 = squot64(flat_segment_id_11324, slice_11327);\n        remnant_11329 = flat_segment_id_11324 - gtid_8256 * slice_11327;\n        gtid_8257 = squot64(remnant_11329, slice_11326);\n        remnant_11330 = remnant_11329 - gtid_8257 * slice_11326;\n        gtid_8258 = remnant_11330;\n        remnant_11331 = remnant_11330 - gtid_8258;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11332 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11336 = squot64(global_tid_11325, segred_tblock_sizze_8252);\n        block_base_offset_11337 = tblock_id_in_segment_11336 * q_11284 * segred_tblock_sizze_8252;\n        for (int64_t i_11338 = 0; i_11338 < q_11284; i_11338++) {\n            int64_t block_offset_11339 = block_base_offset_11337 + i_11338 * segred_tblock_sizze_8252;\n            \n            gtid_8259 = global_tid_11325 + threads_per_segment_11286 * i_11338;\n            if (slt64(gtid_8259, (int64_t) 32)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_8267 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8256 * (int64_t) 1024 + gtid_8257 * (int64_t) 32 + gtid_8259]);\n                        f16 eta_p_8268 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8258 * (int64_t) 32 + gtid_8259]);\n                        f16 defunc_0_f_res_8269 = eta_p_8267 * eta_p_8268;\n                        \n                        // load accumulator", "(s)\n                        {\n                            eta_p_8261 = eta_p_block_res_acc_11332;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_8262 = defunc_0_f_res_8269;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_8263 = eta_p_8261 + eta_p_8262;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11332 = defunc_0_op_res_8263;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11341 = 1;\n        offset_11340 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_8252))) {\n                eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n            }\n        }\n        offset_11340 = 1;\n        while (slt32(offset_11340, wave_sizze_11314)) {\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_8252)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11340 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction",
                                    " operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            offset_11340 *= 2;\n        }\n        while (slt32(skip_waves_11341, squot32(sext_i64_i32(segred_tblock_sizze_8252) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11340 = skip_waves_11341 * wave_sizze_11314;\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_8252)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11341 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            skip_waves_11341 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11312) == (int64_t) 0) {\n                eta_p_block_res_acc_11332 = eta_p_11333;\n            } else {\n   ", "             eta_p_block_res_acc_11332 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11283 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) mem_10479)[gtid_8256 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + gtid_8257 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_8258] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                }\n            }\n        } else {\n            int32_t old_counter_11342;\n            bool is_last_block_11343;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11287)[sext_i32_i64(virt_tblock_id_11323)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                    mem_fence_global();\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11318)[(int64_t) 0] = old_counter_11342 == sext_i64_i32(blocks_per_segment_11283 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11343 = ((__local bool *) sync_arr_mem_11318)[(int64_t) 0];\n            if (is_last_block_11343) {\n                if (local_tid_11312 == 0) {\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11283));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11344 = sdiv_up64(blocks_per_segment_11283, segred_tblock_sizze_8252);\n                    \n                    eta_p_8261 = ", "(f16) 0.0F;\n                    for (int64_t i_11345 = 0; i_11345 < read_per_thread_11344; i_11345++) {\n                        int64_t block_res_id_11346 = sext_i32_i64(local_tid_11312) * read_per_thread_11344 + i_11345;\n                        int64_t index_of_block_res_11347 = flat_segment_id_11324 * blocks_per_segment_11283 + block_res_id_11346;\n                        \n                        if (slt64(block_res_id_11346, blocks_per_segment_11283)) {\n                            eta_p_8262 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11287)[index_of_block_res_11347]);\n                            \n                            f16 defunc_0_op_res_8263 = eta_p_8261 + eta_p_8262;\n                            \n                            eta_p_8261 = defunc_0_op_res_8263;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_8261);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11348;\n                    int32_t skip_waves_11349 = 1;\n                    f16 eta_p_11333;\n                    f16 eta_p_11334;\n                    \n                    offset_11348 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_8252))) {\n                            eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                        }\n                    }\n                    offset_11348 = 1;\n                    while (slt32(offset_11348, wave_sizze_11314)) {\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_8252)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_",
                                    "11314) & (2 * offset_11348 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        offset_11348 *= 2;\n                    }\n                    while (slt32(skip_waves_11349, squot32(sext_i64_i32(segred_tblock_sizze_8252) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11348 = skip_waves_11349 * wave_sizze_11314;\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_8252)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11349 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                   ", "             \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        skip_waves_11349 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11312 == 0) {\n                            ((__global uint16_t *) mem_10479)[gtid_8256 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + gtid_8257 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_8258] = futrts_to_bits16(eta_p_11333);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_8252\n    #undef chunk_sizze_11250\n}\nFUTHARK_KERNEL_SIZED(run32zisegred_large_8307_dim1, 1, 1)\nvoid run32zisegred_large_8307(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t one_intra_par_min_8158, int64_t num_tblocks_8300, int64_t blocks_per_segment_11439, int64_t q_11440, int64_t num_virtblocks_11441, int64_t threads_per_segment_11442, __global unsigned char *ext_mem_10569, __global unsigned char *mem_10579, __global unsigned char *mem_10584, __global unsigned char *segred_tmp_mem_11443, __global unsigned char *counters_mem_11445)\n{\n    #define segred_tblock_sizze_8299 (run32zisegred_large_8307zisegred_tblock_sizze_8299)\n    #define chunk_sizze_11406 (run32zisegred_large_8307zichunk_sizze_11406)\n    \n    volatile __local unsigned char *sync_arr_mem_11454_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11454_backing_1_offset = 0 + 8;\n", "    volatile __local unsigned char *red_arr_f16_mem_11452_backing_0 = &shared_mem[sync_arr_mem_11454_backing_1_offset];\n    const int64_t red_arr_f16_mem_11452_backing_0_offset = sync_arr_mem_11454_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_8299 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8299, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11448;\n    int32_t tblock_sizze_11451;\n    int32_t wave_sizze_11450;\n    int32_t block_id_11449;\n    int32_t global_tid_11447;\n    int64_t phys_tid_8307;\n    __local unsigned char *red_arr_f16_mem_11452;\n    __local unsigned char *sync_arr_mem_11454;\n    int32_t phys_tblock_id_11456;\n    int32_t iterations_11457;\n    \n    local_tid_11448 = get_local_id(0);\n    tblock_sizze_11451 = get_local_size(0);\n    wave_sizze_11450 = LOCKSTEP_WIDTH;\n    block_id_11449 = get_tblock_id(0);\n    global_tid_11447 = block_id_11449 * tblock_sizze_11451 + local_tid_11448;\n    phys_tid_8307 = sext_i32_i64(global_tid_11447);\n    red_arr_f16_mem_11452 = (__local unsigned char *) red_arr_f16_mem_11452_backing_0;\n    sync_arr_mem_11454 = (__local unsigned char *) sync_arr_mem_11454_backing_1;\n    phys_tblock_id_11456 = get_tblock_id(0);\n    iterations_11457 = sdiv_up32(sext_i64_i32(num_virtblocks_11441) - phys_tblock_id_11456, sext_i64_i32(num_tblocks_8300));\n    for (int32_t i_11458 = 0; i_11458 < iterations_11457; i_11458++) {\n        int32_t virt_tblock_id_11459;\n        int64_t flat_segment_id_11460;\n        int64_t global_tid_11461;\n        int64_t slice_11462;\n        int64_t slice_11463;\n        int64_t slice_11464;\n        int64_t gtid_8303;\n        int64_t remnant_11465;\n        int64_t gtid_8304;\n        int64_t remnant_11466;\n        int64_t gtid_8305;\n        int64_t remnant_11467;\n        int64_t gtid_8306;\n        f16 eta_p_block_res_acc_11468;\n        f16 eta_p_8308;\n        f16 eta_p_8309;\n        int64_t tblock_id_in_segment_11472;\n        int64_t ",
                                    "block_base_offset_11473;\n        int32_t offset_11476;\n        int32_t skip_waves_11477;\n        f16 eta_p_11469;\n        f16 eta_p_11470;\n        \n        virt_tblock_id_11459 = phys_tblock_id_11456 + i_11458 * sext_i64_i32(num_tblocks_8300);\n        flat_segment_id_11460 = squot64(sext_i32_i64(virt_tblock_id_11459), blocks_per_segment_11439);\n        global_tid_11461 = srem64(sext_i32_i64(virt_tblock_id_11459) * segred_tblock_sizze_8299 + sext_i32_i64(local_tid_11448), threads_per_segment_11442);\n        slice_11462 = (int64_t) 32;\n        slice_11463 = (int64_t) 32 * slice_11462;\n        slice_11464 = m_6610 * slice_11463;\n        gtid_8303 = squot64(flat_segment_id_11460, slice_11463);\n        remnant_11465 = flat_segment_id_11460 - gtid_8303 * slice_11463;\n        gtid_8304 = squot64(remnant_11465, slice_11462);\n        remnant_11466 = remnant_11465 - gtid_8304 * slice_11462;\n        gtid_8305 = remnant_11466;\n        remnant_11467 = remnant_11466 - gtid_8305;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11468 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11472 = squot64(global_tid_11461, segred_tblock_sizze_8299);\n        block_base_offset_11473 = tblock_id_in_segment_11472 * q_11440 * segred_tblock_sizze_8299;\n        for (int64_t i_11474 = 0; i_11474 < q_11440; i_11474++) {\n            int64_t block_offset_11475 = block_base_offset_11473 + i_11474 * segred_tblock_sizze_8299;\n            \n            gtid_8306 = global_tid_11461 + threads_per_segment_11442 * i_11474;\n            if (slt64(gtid_8306, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_8314 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_8303 * one_intra_par_min_8158 + gtid_8304 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_8306]);\n                        f16 eta_p_8315 = ", "futrts_from_bits16(((__global uint16_t *) mem_10579)[gtid_8306 + gtid_8305 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611]);\n                        f16 defunc_0_f_res_8316 = eta_p_8314 * eta_p_8315;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_8308 = eta_p_block_res_acc_11468;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_8309 = defunc_0_f_res_8316;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_8310 = eta_p_8308 + eta_p_8309;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11468 = defunc_0_op_res_8310;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11477 = 1;\n        offset_11476 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_8299))) {\n                eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n            }\n        }\n        offset_11476 = 1;\n        while (slt32(offset_11476, wave_sizze_11450)) {\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_8299)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11476 - 1)) == 0) {\n    ", "            // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            offset_11476 *= 2;\n        }\n        while (slt32(skip_waves_11477, squot32(sext_i64_i32(segred_tblock_sizze_8299) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11476 = skip_waves_11477 * wave_sizze_11450;\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_8299)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11477 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            skip_waves_11477 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE",
                                    ");\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11448) == (int64_t) 0) {\n                eta_p_block_res_acc_11468 = eta_p_11469;\n            } else {\n                eta_p_block_res_acc_11468 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11439 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) mem_10584)[gtid_8303 * (int64_t) 1024 + gtid_8304 * (int64_t) 32 + gtid_8305] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                }\n            }\n        } else {\n            int32_t old_counter_11478;\n            bool is_last_block_11479;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11443)[sext_i32_i64(virt_tblock_id_11459)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                    mem_fence_global();\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11454)[(int64_t) 0] = old_counter_11478 == sext_i64_i32(blocks_per_segment_11439 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11479 = ((__local bool *) sync_arr_mem_11454)[(int64_t) 0];\n            if (is_last_block_11479) {\n                if (local_tid_11448 == 0) {\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11439));\n                }\n                // read in the per-blo", "ck-results\n                {\n                    int64_t read_per_thread_11480 = sdiv_up64(blocks_per_segment_11439, segred_tblock_sizze_8299);\n                    \n                    eta_p_8308 = (f16) 0.0F;\n                    for (int64_t i_11481 = 0; i_11481 < read_per_thread_11480; i_11481++) {\n                        int64_t block_res_id_11482 = sext_i32_i64(local_tid_11448) * read_per_thread_11480 + i_11481;\n                        int64_t index_of_block_res_11483 = flat_segment_id_11460 * blocks_per_segment_11439 + block_res_id_11482;\n                        \n                        if (slt64(block_res_id_11482, blocks_per_segment_11439)) {\n                            eta_p_8309 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11443)[index_of_block_res_11483]);\n                            \n                            f16 defunc_0_op_res_8310 = eta_p_8308 + eta_p_8309;\n                            \n                            eta_p_8308 = defunc_0_op_res_8310;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_8308);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11484;\n                    int32_t skip_waves_11485 = 1;\n                    f16 eta_p_11469;\n                    f16 eta_p_11470;\n                    \n                    offset_11484 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_8299))) {\n                            eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                        }\n                    }\n                    offset_11484 = 1;\n                    while (slt32(offset_11484, wave_siz", "ze_11450)) {\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_8299)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11484 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        offset_11484 *= 2;\n                    }\n                    while (slt32(skip_waves_11485, squot32(sext_i64_i32(segred_tblock_sizze_8299) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11484 = skip_waves_11485 * wave_sizze_11450;\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_8299)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11485 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                         ",
                                    "   }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        skip_waves_11485 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11448 == 0) {\n                            ((__global uint16_t *) mem_10584)[gtid_8303 * (int64_t) 1024 + gtid_8304 * (int64_t) 32 + gtid_8305] = futrts_to_bits16(eta_p_11469);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_8299\n    #undef chunk_sizze_11406\n}\nFUTHARK_KERNEL_SIZED(run32zisegred_small_8260_dim1, 1, 1)\nvoid run32zisegred_small_8260(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t num_tblocks_8253, int64_t segment_sizze_nonzzero_11251, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479)\n{\n    #define segred_tblock_sizze_8252 (run32zisegred_small_8260zisegred_tblock_sizze_8252)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11258_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11258_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_8252 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8252, (int64_t) 8), (int64_t) 8)", ");\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11254;\n    int32_t tblock_sizze_11257;\n    int32_t wave_sizze_11256;\n    int32_t block_id_11255;\n    int32_t global_tid_11253;\n    int64_t phys_tid_8260;\n    __local unsigned char *red_arr_f16_mem_11258;\n    int32_t phys_tblock_id_11260;\n    int32_t iterations_11261;\n    \n    local_tid_11254 = get_local_id(0);\n    tblock_sizze_11257 = get_local_size(0);\n    wave_sizze_11256 = LOCKSTEP_WIDTH;\n    block_id_11255 = get_tblock_id(0);\n    global_tid_11253 = block_id_11255 * tblock_sizze_11257 + local_tid_11254;\n    phys_tid_8260 = sext_i32_i64(global_tid_11253);\n    red_arr_f16_mem_11258 = (__local unsigned char *) red_arr_f16_mem_11258_backing_0;\n    phys_tblock_id_11260 = get_tblock_id(0);\n    iterations_11261 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251))) - phys_tblock_id_11260, sext_i64_i32(num_tblocks_8253));\n    for (int32_t i_11262 = 0; i_11262 < iterations_11261; i_11262++) {\n        int32_t virt_tblock_id_11263;\n        int64_t slice_11264;\n        int64_t slice_11265;\n        int64_t slice_11266;\n        int64_t gtid_8256;\n        int64_t remnant_11267;\n        int64_t gtid_8257;\n        int64_t remnant_11268;\n        int64_t gtid_8258;\n        int64_t remnant_11269;\n        int64_t gtid_8259;\n        \n        virt_tblock_id_11263 = phys_tblock_id_11260 + i_11262 * sext_i64_i32(num_tblocks_8253);\n        slice_11264 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;\n        slice_11265 = (int64_t) 32 * slice_11264;\n        slice_11266 = m_6610 * slice_11265;\n        gtid_8256 = squot64(squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251), slice_11265);\n        remnant_11267 = squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_", "tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) - gtid_8256 * slice_11265;\n        gtid_8257 = squot64(remnant_11267, slice_11264);\n        remnant_11268 = remnant_11267 - gtid_8257 * slice_11264;\n        gtid_8258 = remnant_11268;\n        remnant_11269 = remnant_11268 - gtid_8258;\n        gtid_8259 = srem64(sext_i32_i64(local_tid_11254), (int64_t) 32);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, (int64_t) 32) && (((slt64(gtid_8256, m_6610) && slt64(gtid_8257, (int64_t) 32)) && slt64(gtid_8258, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) && slt64(sext_i32_i64(local_tid_11254), (int64_t) 32 * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251)))) {\n                // apply map function\n                {\n                    f16 eta_p_8267 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8256 * (int64_t) 1024 + gtid_8257 * (int64_t) 32 + gtid_8259]);\n                    f16 eta_p_8268 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8258 * (int64_t) 32 + gtid_8259]);\n                    f16 defunc_0_f_res_8269 = eta_p_8267 * eta_p_8268;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(defunc_0_f_res_8269);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, (int64_t) 32)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_8261;\n                f16 eta_p_8262;\n                f16 eta_p_11270;\n                f16 eta_p_11271;\n                bool ltid_in_bounds_11273 = slt64(sext_i32_i64(local_tid_11254), (int64_t) 32 * squot64(seg",
                                    "red_tblock_sizze_8252, segment_sizze_nonzzero_11251));\n                int32_t skip_threads_11274;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11273) {\n                        eta_p_8262 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                        if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                            eta_p_8261 = eta_p_8262;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11274 = 1;\n                    while (slt32(skip_threads_11274, 32)) {\n                        bool thread_active_11275 = sle32(skip_threads_11274, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && ltid_in_bounds_11273;\n                        \n                        if (thread_active_11275) {\n                            // read operands\n                            {\n                                eta_p_8261 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11274)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11276 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 32), sext_i32_i64(local_tid_11254) - sext_i32_i64(local_tid_11254 - skip_threads_11274));\n                            \n                            if (thread_active_11275 && inactive_11276) {\n                                eta_p_8261 = eta_p_8262;\n                            }\n                            if (thread_active_11275) {\n                                if (!inactive_11276) {\n                                    f16 defunc_0_op_res_8263 = eta_p_8261 + eta_p_8262;\n                                ", "    \n                                    eta_p_8261 = defunc_0_op_res_8263;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11275) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_8261);\n                                eta_p_8262 = eta_p_8261;\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11274 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 31 && ltid_in_bounds_11273) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32))] = futrts_to_bits16(eta_p_8261);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11277;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                            eta_p_11271 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                            if ((local_tid_11254 - sq", "uot32(local_tid_11254, 32) * 32) == 0) {\n                                eta_p_11270 = eta_p_11271;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11277 = 1;\n                        while (slt32(skip_threads_11277, 32)) {\n                            bool thread_active_11278 = sle32(skip_threads_11277, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273);\n                            \n                            if (thread_active_11278) {\n                                // read operands\n                                {\n                                    eta_p_11270 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11277)]);\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_11279 = slt64(srem64(sext_i32_i64(local_tid_11254 * 32 + 32 - 1), (int64_t) 32), sext_i32_i64(local_tid_11254 * 32 + 32 - 1) - sext_i32_i64((local_tid_11254 - skip_threads_11277) * 32 + 32 - 1));\n                                \n                                if (thread_active_11278 && inactive_11279) {\n                                    eta_p_11270 = eta_p_11271;\n                                }\n                                if (thread_active_11278) {\n                                    if (!inactive_11279) {\n                                        f16 defunc_0_op_res_11272 = eta_p_11270 + eta_p_11271;\n                                        \n                                        eta_p_11270 = defunc_0_op_res_11272;\n                                    }\n                                }\n                            }\n                            if (sle32(w",
                                    "ave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11278) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_11270);\n                                    eta_p_11271 = eta_p_11270;\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11277 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11280 = squot32(local_tid_11254, 32) == 0 || !ltid_in_bounds_11273;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11280) {\n                            eta_p_8262 = eta_p_8261;\n                            eta_p_8261 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_11281 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 32), sext_i32_i64(local_tid_11254) - sext_i32_i64(squot32(local_tid_11254, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11280) {\n                            if (inactive_11281) {\n                                eta_p_8261 = eta_p_8262;\n                            }\n                        }\n                        if (!no_c", "arry_in_11280) {\n                            if (!inactive_11281) {\n                                f16 defunc_0_op_res_8263 = eta_p_8261 + eta_p_8262;\n                                \n                                eta_p_8261 = defunc_0_op_res_8263;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11280) {\n                            ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_8261);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_8262);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) && slt64(sext_i32_i64(local_tid_11254), squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251))) {\n                f16 tmp_11282 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[(sext_i32_i64(local_tid_11254) + (int64_t) 1) * segment_sizze_nonzzero_11251 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10479)[squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 *", " (int64_t) 32) + squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + (sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)] = futrts_to_bits16(tmp_11282);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_8252\n}\nFUTHARK_KERNEL_SIZED(run32zisegred_small_8307_dim1, 1, 1)\nvoid run32zisegred_small_8307(__global int *global_failure, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, int64_t one_intra_par_min_8158, int64_t num_tblocks_8300, int64_t segment_sizze_nonzzero_11407, __global unsigned char *ext_mem_10569, __global unsigned char *mem_10579, __global unsigned char *mem_10584)\n{\n    #define segred_tblock_sizze_8299 (run32z",
                                    "isegred_small_8307zisegred_tblock_sizze_8299)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11414_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11414_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_8299 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8299, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11410;\n    int32_t tblock_sizze_11413;\n    int32_t wave_sizze_11412;\n    int32_t block_id_11411;\n    int32_t global_tid_11409;\n    int64_t phys_tid_8307;\n    __local unsigned char *red_arr_f16_mem_11414;\n    int32_t phys_tblock_id_11416;\n    int32_t iterations_11417;\n    \n    local_tid_11410 = get_local_id(0);\n    tblock_sizze_11413 = get_local_size(0);\n    wave_sizze_11412 = LOCKSTEP_WIDTH;\n    block_id_11411 = get_tblock_id(0);\n    global_tid_11409 = block_id_11411 * tblock_sizze_11413 + local_tid_11410;\n    phys_tid_8307 = sext_i32_i64(global_tid_11409);\n    red_arr_f16_mem_11414 = (__local unsigned char *) red_arr_f16_mem_11414_backing_0;\n    phys_tblock_id_11416 = get_tblock_id(0);\n    iterations_11417 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6610 * (int64_t) 32 * (int64_t) 32, squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407))) - phys_tblock_id_11416, sext_i64_i32(num_tblocks_8300));\n    for (int32_t i_11418 = 0; i_11418 < iterations_11417; i_11418++) {\n        int32_t virt_tblock_id_11419;\n        int64_t slice_11420;\n        int64_t slice_11421;\n        int64_t slice_11422;\n        int64_t gtid_8303;\n        int64_t remnant_11423;\n        int64_t gtid_8304;\n        int64_t remnant_11424;\n        int64_t gtid_8305;\n        int64_t remnant_11425;\n        int64_t gtid_8306;\n        \n        virt_tblock_id_11419 = phys_tblock_id_11416 + i_11418 * sext_i64_i32(num_tblocks_8300);\n        slice_11420 = (int64_t) 32;\n        slice_11421 = (int64_t) 32 * slice_11420;\n        slice_11422 = m_6610 * slice_11421;\n        gtid_8303 = squot64(squot64(se", "xt_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407), slice_11421);\n        remnant_11423 = squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) - gtid_8303 * slice_11421;\n        gtid_8304 = squot64(remnant_11423, slice_11420);\n        remnant_11424 = remnant_11423 - gtid_8304 * slice_11420;\n        gtid_8305 = remnant_11424;\n        remnant_11425 = remnant_11424 - gtid_8305;\n        gtid_8306 = srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) && (((slt64(gtid_8303, m_6610) && slt64(gtid_8304, (int64_t) 32)) && slt64(gtid_8305, (int64_t) 32)) && slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407)))) {\n                // apply map function\n                {\n                    f16 eta_p_8314 = futrts_from_bits16(((__global uint16_t *) ext_mem_10569)[gtid_8303 * one_intra_par_min_8158 + gtid_8304 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 + gtid_8306]);\n                    f16 eta_p_8315 = futrts_from_bits16(((__global uint16_t *) mem_10579)[gtid_8306 + gtid_8305 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611]);\n                    f16 defunc_0_f_res_8316 = eta_p_8314 * eta_p_8315;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(defunc_0_f_res_8316);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n      ", "  barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_8308;\n                f16 eta_p_8309;\n                f16 eta_p_11426;\n                f16 eta_p_11427;\n                bool ltid_in_bounds_11429 = slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407));\n                int32_t skip_threads_11430;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11429) {\n                        eta_p_8309 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                        if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                            eta_p_8308 = eta_p_8309;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11430 = 1;\n                    while (slt32(skip_threads_11430, 32)) {\n                        bool thread_active_11431 = sle32(skip_threads_11430, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && ltid_in_bounds_11429;\n                        \n                        if (thread_active_11431) {\n                            // read operands\n                            {\n                                eta_p_8308 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11430)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11432 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11410) - sext_i32_i64(",
                                    "local_tid_11410 - skip_threads_11430));\n                            \n                            if (thread_active_11431 && inactive_11432) {\n                                eta_p_8308 = eta_p_8309;\n                            }\n                            if (thread_active_11431) {\n                                if (!inactive_11432) {\n                                    f16 defunc_0_op_res_8310 = eta_p_8308 + eta_p_8309;\n                                    \n                                    eta_p_8308 = defunc_0_op_res_8310;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11431) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_8308);\n                                eta_p_8309 = eta_p_8308;\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11430 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 31 && ltid_in_bounds_11429) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32))] = futrts_to_bits16(eta_p_8308);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for bloc", "k 'i+1'\n                {\n                    int32_t skip_threads_11433;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                            eta_p_11427 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                            if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                                eta_p_11426 = eta_p_11427;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11433 = 1;\n                        while (slt32(skip_threads_11433, 32)) {\n                            bool thread_active_11434 = sle32(skip_threads_11433, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429);\n                            \n                            if (thread_active_11434) {\n                                // read operands\n                                {\n                                    eta_p_11426 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11433)]);\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_11435 = slt64(srem64(sext_i32_i64(local_tid_11410 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11410 * 32 + 32 - 1) - sext_i32_i64((local_tid_11410 - skip_threads_11433) * 32 + 32 - 1));\n                                \n                                if (thread_active_11434 && inactive_11435) {\n                                    eta_p_11426 = eta_p_11427;\n                        ", "        }\n                                if (thread_active_11434) {\n                                    if (!inactive_11435) {\n                                        f16 defunc_0_op_res_11428 = eta_p_11426 + eta_p_11427;\n                                        \n                                        eta_p_11426 = defunc_0_op_res_11428;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11434) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_11426);\n                                    eta_p_11427 = eta_p_11426;\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11433 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11436 = squot32(local_tid_11410, 32) == 0 || !ltid_in_bounds_11429;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11436) {\n                            eta_p_8309 = eta_p_8308;\n                            eta_p_8308 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n  ",
                                    "                  {\n                        bool inactive_11437 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), sext_i32_i64(local_tid_11410) - sext_i32_i64(squot32(local_tid_11410, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11436) {\n                            if (inactive_11437) {\n                                eta_p_8308 = eta_p_8309;\n                            }\n                        }\n                        if (!no_carry_in_11436) {\n                            if (!inactive_11437) {\n                                f16 defunc_0_op_res_8310 = eta_p_8308 + eta_p_8309;\n                                \n                                eta_p_8308 = defunc_0_op_res_8310;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11436) {\n                            ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_8308);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_8309);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), m_6610 * (int64_t) 32 * (int64_t) 32) && slt64(sext_i32_i64(local_tid_11410), squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407))) {\n         ", "       f16 tmp_11438 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[(sext_i32_i64(local_tid_11410) + (int64_t) 1) * segment_sizze_nonzzero_11407 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10584)[squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 1024) * (int64_t) 1024 + squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 1024) * (int64_t) 1024, (int64_t) 32) * (int64_t) 32 + (sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 1024) * (int64_t) 1024 - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 1024) * (int64_t) 1024, (int64_t) 32) * (int64_t) 32)] = futrts_to_bits16(tmp_11438);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_8299\n}\nFUTHARK_KERNEL_SIZED(run64zisegmap_8407_dim1, 1, 1)\nvoid run64zisegmap_8407(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t num_tblocks_8403, int64_t num_threads_10938, int32_t virt_num_tblocks_11024, __global unsigned char *K_mem_10473, __global unsigned char *mem_10788, __global uns", "igned char *mem_10798, __global unsigned char *mem_10840, __global unsigned char *color_10856)\n{\n    #define segmap_tblock_sizze_8402 (run64zisegmap_8407zisegmap_tblock_sizze_8402)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11026;\n    int32_t tblock_sizze_11029;\n    int32_t wave_sizze_11028;\n    int32_t block_id_11027;\n    int32_t global_tid_11025;\n    int64_t phys_tid_8407;\n    int32_t phys_tblock_id_11030;\n    int32_t iterations_11031;\n    \n    local_tid_11026 = get_local_id(0);\n    tblock_sizze_11029 = get_local_size(0);\n    wave_sizze_11028 = LOCKSTEP_WIDTH;\n    block_id_11027 = get_tblock_id(0);\n    global_tid_11025 = block_id_11027 * tblock_sizze_11029 + local_tid_11026;\n    phys_tid_8407 = sext_i32_i64(global_tid_11025);\n    phys_tblock_id_11030 = get_tblock_id(0);\n    iterations_11031 = sdiv_up32(virt_num_tblocks_11024 - phys_tblock_id_11030, sext_i64_i32(num_tblocks_8403));\n    for (int32_t i_11032 = 0; i_11032 < iterations_11031; i_11032++) {\n        int32_t virt_tblock_id_11033;\n        int64_t global_tid_11034;\n        int64_t slice_11035;\n        int64_t gtid_8406;\n        int64_t remnant_11036;\n        \n        virt_tblock_id_11033 = phys_tblock_id_11030 + i_11032 * sext_i64_i32(num_tblocks_8403);\n        global_tid_11034 = sext_i32_i64(virt_tblock_id_11033) * segmap_tblock_sizze_8402 + sext_i32_i64(local_tid_11026);\n        slice_11035 = m_6626;\n        gtid_8406 = global_tid_11034;\n        remnant_11036 = global_tid_11034 - gtid_8406;\n        if (slt64(gtid_8406, m_6626)) {\n            f16 mem_10808[(int64_t) 64 * (int64_t) 64];\n            f16 mem_10822[(int64_t) 64];\n            \n            for (int64_t i_10441 = 0; i_10441 < (int64_t) 64; i_10441++) {\n                for (int64_t i_10445 = 0; i_10445 < dzlz7bUZLztZRz20Umz20U64z7dUzg_6627; i_10445++) {\n                    f16 defunc_0_f_res_8413;\n                    f16 redout_10447 = (f16) 0.0F;\n                    \n                    for (int64_t i_10448 = 0; i_104",
                                    "48 < (int64_t) 64; i_10448++) {\n                        f16 eta_p_8417;\n                        f16 eta_p_8418;\n                        f16 defunc_0_f_res_8419;\n                        f16 defunc_0_op_res_8416;\n                        f16 redout_tmp_11039;\n                        \n                        eta_p_8417 = futrts_from_bits16(((__global uint16_t *) mem_10788)[gtid_8406 + i_10441 * (m_6626 * (int64_t) 64) + i_10448 * m_6626]);\n                        eta_p_8418 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_10445 * (int64_t) 64 + i_10448]);\n                        defunc_0_f_res_8419 = eta_p_8417 * eta_p_8418;\n                        defunc_0_op_res_8416 = defunc_0_f_res_8419 + redout_10447;\n                        redout_tmp_11039 = defunc_0_op_res_8416;\n                        redout_10447 = redout_tmp_11039;\n                    }\n                    defunc_0_f_res_8413 = redout_10447;\n                    ((__global uint16_t *) color_10856)[phys_tid_8407 + i_10445 * num_threads_10938] = futrts_to_bits16(defunc_0_f_res_8413);\n                }\n                for (int64_t i_10451 = 0; i_10451 < (int64_t) 64; i_10451++) {\n                    f16 defunc_0_f_res_8422;\n                    f16 redout_10453 = (f16) 0.0F;\n                    \n                    for (int64_t i_10454 = 0; i_10454 < dzlz7bUZLztZRz20Umz20U64z7dUzg_6627; i_10454++) {\n                        f16 eta_p_8426;\n                        f16 eta_p_8427;\n                        f16 defunc_0_f_res_8428;\n                        f16 defunc_0_op_res_8425;\n                        f16 redout_tmp_11041;\n                        \n                        eta_p_8426 = futrts_from_bits16(((__global uint16_t *) color_10856)[phys_tid_8407 + i_10454 * num_threads_10938]);\n                        eta_p_8427 = futrts_from_bits16(((__global uint16_t *) mem_10798)[i_10454 + i_10451 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627]);\n                        defunc_0_f_res_8428 = eta_p_8426 * eta_p_8427;\n       ", "                 defunc_0_op_res_8425 = defunc_0_f_res_8428 + redout_10453;\n                        redout_tmp_11041 = defunc_0_op_res_8425;\n                        redout_10453 = redout_tmp_11041;\n                    }\n                    defunc_0_f_res_8422 = redout_10453;\n                    mem_10822[i_10451] = defunc_0_f_res_8422;\n                }\n                for (int64_t i_0 = 0; i_0 < (int64_t) 64; i_0++) {\n                    mem_10808[i_10441 * (int64_t) 64 + i_0] = mem_10822[i_0];\n                }\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 64; i_0++) {\n                for (int64_t i_1 = 0; i_1 < (int64_t) 64; i_1++) {\n                    ((__global uint16_t *) mem_10840)[gtid_8406 + (i_0 * (m_6626 * (int64_t) 64) + i_1 * m_6626)] = futrts_to_bits16(mem_10808[i_0 * (int64_t) 64 + i_1]);\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_8402\n}\nFUTHARK_KERNEL_SIZED(run64zisegmap_8853_dim1, 1, 1)\nvoid run64zisegmap_8853(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t num_tblocks_8831, int64_t num_threads_10960, int32_t virt_num_tblocks_11111, __global unsigned char *K_mem_10473, __global unsigned char *mem_10715, __global unsigned char *mem_10725, __global unsigned char *mem_10756, __global unsigned char *color_10859)\n{\n    #define segmap_tblock_sizze_8830 (run64zisegmap_8853zisegmap_tblock_sizze_8830)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11113;\n    int32_t tblock_sizze_11116;\n    int32_t wave_sizze_11115;\n    int32_t block_id_11114;\n    int32_t global_tid_11112;\n    int64_t phys_tid_8853;\n    int32_t phys_tblock_id_11117;\n    int32_t iterations_11118;\n    \n    local_tid_11113 = get_local_id(0);\n    tblock_sizze_11116 = get_local_size(0);\n    wave_sizze_11115 = LOCKSTEP_WIDTH;\n    block_id_11114 = get_tblock_id(0);\n    global_tid_11", "112 = block_id_11114 * tblock_sizze_11116 + local_tid_11113;\n    phys_tid_8853 = sext_i32_i64(global_tid_11112);\n    phys_tblock_id_11117 = get_tblock_id(0);\n    iterations_11118 = sdiv_up32(virt_num_tblocks_11111 - phys_tblock_id_11117, sext_i64_i32(num_tblocks_8831));\n    for (int32_t i_11119 = 0; i_11119 < iterations_11118; i_11119++) {\n        int32_t virt_tblock_id_11120;\n        int64_t global_tid_11121;\n        int64_t slice_11122;\n        int64_t slice_11123;\n        int64_t gtid_8851;\n        int64_t remnant_11124;\n        int64_t gtid_8852;\n        int64_t remnant_11125;\n        \n        virt_tblock_id_11120 = phys_tblock_id_11117 + i_11119 * sext_i64_i32(num_tblocks_8831);\n        global_tid_11121 = sext_i32_i64(virt_tblock_id_11120) * segmap_tblock_sizze_8830 + sext_i32_i64(local_tid_11113);\n        slice_11122 = (int64_t) 64;\n        slice_11123 = m_6626 * slice_11122;\n        gtid_8851 = squot64(global_tid_11121, slice_11122);\n        remnant_11124 = global_tid_11121 - gtid_8851 * slice_11122;\n        gtid_8852 = remnant_11124;\n        remnant_11125 = remnant_11124 - gtid_8852;\n        if (slt64(gtid_8851, m_6626) && slt64(gtid_8852, (int64_t) 64)) {\n            f16 mem_10739[(int64_t) 64];\n            \n            for (int64_t i_10457 = 0; i_10457 < dzlz7bUZLztZRz20Umz20U64z7dUzg_6627; i_10457++) {\n                f16 defunc_0_f_res_8857;\n                f16 redout_10459 = (f16) 0.0F;\n                \n                for (int64_t i_10460 = 0; i_10460 < (int64_t) 64; i_10460++) {\n                    f16 eta_p_8861;\n                    f16 eta_p_8862;\n                    f16 defunc_0_f_res_8863;\n                    f16 defunc_0_op_res_8860;\n                    f16 redout_tmp_11127;\n                    \n                    eta_p_8861 = futrts_from_bits16(((__global uint16_t *) mem_10715)[gtid_8851 * (int64_t) 64 + gtid_8852 + i_10460 * ((int64_t) 64 * m_6626)]);\n                    eta_p_8862 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[i_104",
                                    "57 * (int64_t) 64 + i_10460]);\n                    defunc_0_f_res_8863 = eta_p_8861 * eta_p_8862;\n                    defunc_0_op_res_8860 = defunc_0_f_res_8863 + redout_10459;\n                    redout_tmp_11127 = defunc_0_op_res_8860;\n                    redout_10459 = redout_tmp_11127;\n                }\n                defunc_0_f_res_8857 = redout_10459;\n                ((__global uint16_t *) color_10859)[phys_tid_8853 + i_10457 * num_threads_10960] = futrts_to_bits16(defunc_0_f_res_8857);\n            }\n            for (int64_t i_10463 = 0; i_10463 < (int64_t) 64; i_10463++) {\n                f16 defunc_0_f_res_8866;\n                f16 redout_10465 = (f16) 0.0F;\n                \n                for (int64_t i_10466 = 0; i_10466 < dzlz7bUZLztZRz20Umz20U64z7dUzg_6627; i_10466++) {\n                    f16 eta_p_8870;\n                    f16 eta_p_8871;\n                    f16 defunc_0_f_res_8872;\n                    f16 defunc_0_op_res_8869;\n                    f16 redout_tmp_11129;\n                    \n                    eta_p_8870 = futrts_from_bits16(((__global uint16_t *) color_10859)[phys_tid_8853 + i_10466 * num_threads_10960]);\n                    eta_p_8871 = futrts_from_bits16(((__global uint16_t *) mem_10725)[i_10466 + i_10463 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627]);\n                    defunc_0_f_res_8872 = eta_p_8870 * eta_p_8871;\n                    defunc_0_op_res_8869 = defunc_0_f_res_8872 + redout_10465;\n                    redout_tmp_11129 = defunc_0_op_res_8869;\n                    redout_10465 = redout_tmp_11129;\n                }\n                defunc_0_f_res_8866 = redout_10465;\n                mem_10739[i_10463] = defunc_0_f_res_8866;\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 64; i_0++) {\n                ((__global uint16_t *) mem_10756)[gtid_8851 * (int64_t) 64 + gtid_8852 + i_0 * ((int64_t) 64 * m_6626)] = futrts_to_bits16(mem_10739[i_0]);\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_F", "ENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_8830\n}\nFUTHARK_KERNEL_SIZED(run64zisegmap_intrablock_10078_dim1, 1, 1)\nvoid run64zisegmap_intrablock_10078(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t one_intra_par_min_8836, int64_t full_tiles_10106, int64_t kk_10264, __global unsigned char *V_mem_10474, __global unsigned char *ext_mem_10579, __global unsigned char *mem_10690)\n{\n    #define Ty_10060 (run64zisegmap_intrablock_10078ziTy_10060)\n    #define Ry_10061 (run64zisegmap_intrablock_10078ziRy_10061)\n    #define Tk_10062 (run64zisegmap_intrablock_10078ziTk_10062)\n    #define tk_div_tx_10063 (run64zisegmap_intrablock_10078zitk_div_tx_10063)\n    #define TxRx_10065 (run64zisegmap_intrablock_10078ziTxRx_10065)\n    #define a_loc_szz_10068 (run64zisegmap_intrablock_10078zia_loc_szz_10068)\n    #define gridDim_x_10071 (run64zisegmap_intrablock_10078zigridDim_x_10071)\n    #define loop_nonempty_10430 (run64zisegmap_intrablock_10078ziloop_nonempty_10430)\n    #define bytes_10626 (run64zisegmap_intrablock_10078zibytes_10626)\n    \n    volatile __local unsigned char *color_10865_backing_1 = &shared_mem[0];\n    const int64_t color_10865_backing_1_offset = 0 + (bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10864_backing_0 = &shared_mem[color_10865_backing_1_offset];\n    const int64_t color_10864_backing_0_offset = color_10865_backing_1_offset + (bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11354;\n    int32_t tblock_sizze_11357;\n    int32_t wave_sizze_11356;\n    int32_t block_id_11355;\n    int32_t global_tid_11353;\n    int64_t gid_flat_10078;\n    int64_t slice_11360;\n    int64_t slice_11361;\n    int64_t ltid_pre_11358;\n    int64_t remnant_11362;\n    int64_t ltid_pre_11359;\n    int64_t remnant_11363;\n    int64_t", " slice_11364;\n    int64_t slice_11365;\n    int64_t slice_11366;\n    int64_t gtid_8960;\n    int64_t remnant_11367;\n    int64_t gid_y_10076;\n    int64_t remnant_11368;\n    int64_t gid_x_10077;\n    int64_t remnant_11369;\n    __local unsigned char *color_10864;\n    __local unsigned char *color_10865;\n    int64_t iii_10079;\n    int64_t jjj_10080;\n    f16 mem_10625[Ry_10061 * Ry_10061];\n    int64_t ltid_flat_10094;\n    int64_t ltid_y_10093;\n    int64_t ltid_x_10092;\n    f16 mem_10606[Ry_10061 * Ry_10061];\n    f16 ext_mem_10664[Ry_10061 * Ry_10061];\n    f16 mem_param_10630[Ry_10061 * Ry_10061];\n    int64_t ltid_flat_10286;\n    int64_t ltid_flat_10331;\n    f16 mem_10686[Ry_10061 * Ry_10061];\n    int64_t ltid_flat_10392;\n    int64_t ltid_y_10391;\n    int64_t ltid_x_10390;\n    int64_t binop_x_10407;\n    int64_t binop_y_10412;\n    int64_t slice_11393;\n    int64_t slice_11394;\n    int64_t slice_11395;\n    int64_t reg_tile_i_11390;\n    int64_t remnant_11396;\n    int64_t reg_tile_i_11391;\n    int64_t remnant_11397;\n    int64_t reg_tile_i_11392;\n    int64_t remnant_11398;\n    int64_t tile_dim_start_11399;\n    int64_t tile_dim_start_11400;\n    int64_t tile_dim_start_11401;\n    \n    local_tid_11354 = get_local_id(0);\n    tblock_sizze_11357 = get_local_size(0);\n    wave_sizze_11356 = LOCKSTEP_WIDTH;\n    block_id_11355 = get_tblock_id(0);\n    global_tid_11353 = block_id_11355 * tblock_sizze_11357 + local_tid_11354;\n    gid_flat_10078 = sext_i32_i64(block_id_11355);\n    slice_11360 = Ty_10060;\n    slice_11361 = Ty_10060 * slice_11360;\n    ltid_pre_11358 = squot64(sext_i32_i64(local_tid_11354), slice_11360);\n    remnant_11362 = sext_i32_i64(local_tid_11354) - ltid_pre_11358 * slice_11360;\n    ltid_pre_11359 = remnant_11362;\n    remnant_11363 = remnant_11362 - ltid_pre_11359;\n    slice_11364 = gridDim_x_10071;\n    slice_11365 = gridDim_x_10071 * slice_11364;\n    slice_11366 = m_6626 * slice_11365;\n    gtid_8960 = squot64(sext_i32_i64(block_id_11355), slice_11365);\n    remnant_11367 = sex",
                                    "t_i32_i64(block_id_11355) - gtid_8960 * slice_11365;\n    gid_y_10076 = squot64(remnant_11367, slice_11364);\n    remnant_11368 = remnant_11367 - gid_y_10076 * slice_11364;\n    gid_x_10077 = remnant_11368;\n    remnant_11369 = remnant_11368 - gid_x_10077;\n    color_10864 = (__local unsigned char *) color_10864_backing_0;\n    color_10865 = (__local unsigned char *) color_10865_backing_1;\n    iii_10079 = TxRx_10065 * gid_y_10076;\n    jjj_10080 = TxRx_10065 * gid_x_10077;\n    ltid_flat_10094 = sext_i32_i64(local_tid_11354);\n    ltid_y_10093 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10092 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    for (int64_t i_10097 = 0; i_10097 < Ry_10061; i_10097++) {\n        for (int64_t i_10100 = 0; i_10100 < Ry_10061; i_10100++) {\n            mem_10606[i_10097 * Ry_10061 + i_10100] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_10061; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_10061; i_1++) {\n            mem_10625[i_0 * Ry_10061 + i_1] = mem_10606[i_0 * Ry_10061 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < Ry_10061 * Ry_10061; i_2++)\n        mem_param_10630[i_2] = mem_10625[i_2];\n    for (int64_t i_10107 = 0; i_10107 < full_tiles_10106; i_10107++) {\n        int64_t kk_10111;\n        int64_t ltid_flat_10131;\n        int64_t ltid_flat_10172;\n        f16 mem_10657[Ry_10061 * Ry_10061];\n        int64_t ltid_flat_10229;\n        int64_t ltid_y_10228;\n        int64_t ltid_x_10227;\n        int64_t binop_x_10242;\n        int64_t binop_y_10247;\n        f16 mem_param_tmp_11372[Ry_10061 * Ry_10061];\n        \n        kk_10111 = Tk_10062 * i_10107;\n        ltid_flat_10131 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11376 = 0; nest_i_11376 < Ry_10061; nest_i_11376++) {\n            for (int64_t nest_i_11377 = 0; nest_i_11377 < tk_div_tx_10063; nest_i_11377++) {\n                int64_t ltid_seq_10134;\n                int64_t lt", "id_seq_10135;\n                int64_t ltid_y_10132;\n                int64_t ltid_x_10133;\n                int64_t binop_y_10136;\n                int64_t k_10137;\n                int64_t binop_y_10138;\n                int64_t i_10139;\n                int64_t gtid_10140;\n                int64_t defunc_0_map_res_seqdim_idx_10141;\n                bool cond_10142;\n                f16 defunc_0_map_res_elem_10143;\n                bool cond_10147;\n                int64_t defunc_0_map_res_loc_ind_10148;\n                \n                ltid_seq_10134 = nest_i_11376;\n                ltid_seq_10135 = nest_i_11377;\n                ltid_y_10132 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10133 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10136 = Ty_10060 * ltid_seq_10135;\n                k_10137 = ltid_x_10133 + binop_y_10136;\n                binop_y_10138 = Ty_10060 * ltid_seq_10134;\n                i_10139 = ltid_y_10132 + binop_y_10138;\n                gtid_10140 = iii_10079 + i_10139;\n                defunc_0_map_res_seqdim_idx_10141 = kk_10111 + k_10137;\n                cond_10142 = slt64(gtid_10140, (int64_t) 64);\n                if (cond_10142) {\n                    f16 A_elem_10145 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_8960 * one_intra_par_min_8836 + gtid_10140 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + defunc_0_map_res_seqdim_idx_10141]);\n                    \n                    defunc_0_map_res_elem_10143 = A_elem_10145;\n                } else {\n                    defunc_0_map_res_elem_10143 = (f16) 0.0F;\n                }\n                cond_10147 = slt64(k_10137, Tk_10062);\n                if (cond_10147) {\n                    int64_t binop_y_10149;\n                    int64_t x_10150;\n                    \n                    binop_y_10149 = Tk_10062 * i_10139;\n                    x_10150 = k_10137 + binop_y_10149;\n                    defunc_0_map_res_loc_ind_10148 = x_10150;\n                }", " else {\n                    defunc_0_map_res_loc_ind_10148 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10148) && slt64(defunc_0_map_res_loc_ind_10148, a_loc_szz_10068)) {\n                    ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10148] = futrts_to_bits16(defunc_0_map_res_elem_10143);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10172 = sext_i32_i64(local_tid_11354);\n        for (int64_t nest_i_11378 = 0; nest_i_11378 < Ry_10061; nest_i_11378++) {\n            for (int64_t nest_i_11379 = 0; nest_i_11379 < tk_div_tx_10063; nest_i_11379++) {\n                int64_t ltid_seq_10175;\n                int64_t ltid_seq_10176;\n                int64_t ltid_y_10173;\n                int64_t ltid_x_10174;\n                int64_t binop_y_10177;\n                int64_t k_10178;\n                int64_t binop_y_10179;\n                int64_t i_10180;\n                int64_t gtid_10181;\n                int64_t as_transformed_row_seqdim_idx_10182;\n                bool cond_10183;\n                f16 as_transformed_row_elem_10184;\n                bool cond_10188;\n                int64_t as_transformed_row_loc_ind_10189;\n                \n                ltid_seq_10175 = nest_i_11378;\n                ltid_seq_10176 = nest_i_11379;\n                ltid_y_10173 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n                ltid_x_10174 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n                binop_y_10177 = Ty_10060 * ltid_seq_10176;\n                k_10178 = ltid_y_10173 + binop_y_10177;\n                binop_y_10179 = Ty_10060 * ltid_seq_10175;\n                i_10180 = ltid_x_10174 + binop_y_10179;\n                gtid_10181 = jjj_10080 + i_10180;\n                as_transformed_row_seqdim_idx_10182 = kk_10111 + k_10178;\n                cond_10183 = slt64(gtid_10181, (int64_t) 64);\n                if (cond_10183) {\n                    f16 A_elem_10186 = futrt",
                                    "s_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10182 * (int64_t) 64 + gtid_10181]);\n                    \n                    as_transformed_row_elem_10184 = A_elem_10186;\n                } else {\n                    as_transformed_row_elem_10184 = (f16) 0.0F;\n                }\n                cond_10188 = slt64(k_10178, Tk_10062);\n                if (cond_10188) {\n                    int64_t binop_y_10190;\n                    int64_t x_10191;\n                    \n                    binop_y_10190 = TxRx_10065 * k_10178;\n                    x_10191 = i_10180 + binop_y_10190;\n                    as_transformed_row_loc_ind_10189 = x_10191;\n                } else {\n                    as_transformed_row_loc_ind_10189 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_10189) && slt64(as_transformed_row_loc_ind_10189, a_loc_szz_10068)) {\n                    ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10189] = futrts_to_bits16(as_transformed_row_elem_10184);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_10229 = sext_i32_i64(local_tid_11354);\n        ltid_y_10228 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n        ltid_x_10227 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n        binop_x_10242 = Ry_10061 * ltid_y_10228;\n        binop_y_10247 = Ry_10061 * ltid_x_10227;\n        for (int64_t i_10232 = 0; i_10232 < Tk_10062; i_10232++) {\n            int64_t binop_y_10249 = TxRx_10065 * i_10232;\n            \n            for (int64_t i_10236 = 0; i_10236 < Ry_10061; i_10236++) {\n                int64_t binop_x_10243;\n                int64_t binop_y_10244;\n                int64_t defunc_0_map_res_loc_ind_64_10245;\n                f16 defunc_0_map_res_loc_elem_10246;\n                \n                binop_x_10243 = i_10236 + binop_x_10242;\n                binop_y_10244 = Tk_10062 * binop_x_10243;\n                defunc_0_map_res_l", "oc_ind_64_10245 = i_10232 + binop_y_10244;\n                if (loop_nonempty_10430) {\n                    f16 x_10431 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10245]);\n                    \n                    defunc_0_map_res_loc_elem_10246 = x_10431;\n                } else {\n                    defunc_0_map_res_loc_elem_10246 = (f16) 0.0F;\n                }\n                for (int64_t i_10239 = 0; i_10239 < Ry_10061; i_10239++) {\n                    int64_t binop_x_10248;\n                    int64_t as_transformed_row_loc_ind_64_10250;\n                    f16 as_transformed_row_loc_elem_10251;\n                    f16 c_10252;\n                    f16 defunc_0_f_res_10255;\n                    f16 defunc_0_op_res_10258;\n                    \n                    binop_x_10248 = i_10239 + binop_y_10247;\n                    as_transformed_row_loc_ind_64_10250 = binop_x_10248 + binop_y_10249;\n                    as_transformed_row_loc_elem_10251 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10250]);\n                    c_10252 = mem_param_10630[i_10236 * Ry_10061 + i_10239];\n                    defunc_0_f_res_10255 = defunc_0_map_res_loc_elem_10246 * as_transformed_row_loc_elem_10251;\n                    defunc_0_op_res_10258 = c_10252 + defunc_0_f_res_10255;\n                    mem_param_10630[i_10236 * Ry_10061 + i_10239] = defunc_0_op_res_10258;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < Ry_10061; i_0++) {\n            for (int64_t i_1 = 0; i_1 < Ry_10061; i_1++) {\n                mem_10657[i_0 * Ry_10061 + i_1] = mem_param_10630[i_0 * Ry_10061 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < Ry_10061 * Ry_10061; i_3++)\n            mem_param_tmp_11372[i_3] = mem_10657[i_3];\n        for (int32_t i_4 = 0; i_4 < Ry_10061 * Ry_10061; i_4++)\n            mem_param_10630[i_4] = mem_param_tmp_11372[i_4];\n ", "   }\n    for (int32_t i_5 = 0; i_5 < Ry_10061 * Ry_10061; i_5++)\n        ext_mem_10664[i_5] = mem_param_10630[i_5];\n    ltid_flat_10286 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11383 = 0; nest_i_11383 < Ry_10061; nest_i_11383++) {\n        for (int64_t nest_i_11384 = 0; nest_i_11384 < tk_div_tx_10063; nest_i_11384++) {\n            int64_t ltid_seq_10289;\n            int64_t ltid_seq_10290;\n            int64_t ltid_y_10287;\n            int64_t ltid_x_10288;\n            int64_t binop_y_10291;\n            int64_t k_10292;\n            int64_t binop_y_10293;\n            int64_t i_10294;\n            int64_t gtid_10295;\n            int64_t defunc_0_map_res_seqdim_idx_10296;\n            bool binop_x_10297;\n            bool binop_y_10298;\n            bool cond_10299;\n            f16 defunc_0_map_res_elem_10300;\n            bool cond_10304;\n            int64_t defunc_0_map_res_loc_ind_10305;\n            \n            ltid_seq_10289 = nest_i_11383;\n            ltid_seq_10290 = nest_i_11384;\n            ltid_y_10287 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10288 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10291 = Ty_10060 * ltid_seq_10290;\n            k_10292 = ltid_x_10288 + binop_y_10291;\n            binop_y_10293 = Ty_10060 * ltid_seq_10289;\n            i_10294 = ltid_y_10287 + binop_y_10293;\n            gtid_10295 = iii_10079 + i_10294;\n            defunc_0_map_res_seqdim_idx_10296 = kk_10264 + k_10292;\n            binop_x_10297 = slt64(gtid_10295, (int64_t) 64);\n            binop_y_10298 = slt64(defunc_0_map_res_seqdim_idx_10296, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n            cond_10299 = binop_x_10297 && binop_y_10298;\n            if (cond_10299) {\n                f16 A_elem_10302 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_8960 * one_intra_par_min_8836 + gtid_10295 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + defunc_0_map_res_seqdim_idx_10296]);\n                \n                defunc_0_map_res",
                                    "_elem_10300 = A_elem_10302;\n            } else {\n                defunc_0_map_res_elem_10300 = (f16) 0.0F;\n            }\n            cond_10304 = slt64(k_10292, Tk_10062);\n            if (cond_10304) {\n                int64_t binop_y_10306;\n                int64_t x_10307;\n                \n                binop_y_10306 = Tk_10062 * i_10294;\n                x_10307 = k_10292 + binop_y_10306;\n                defunc_0_map_res_loc_ind_10305 = x_10307;\n            } else {\n                defunc_0_map_res_loc_ind_10305 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, defunc_0_map_res_loc_ind_10305) && slt64(defunc_0_map_res_loc_ind_10305, a_loc_szz_10068)) {\n                ((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_10305] = futrts_to_bits16(defunc_0_map_res_elem_10300);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10331 = sext_i32_i64(local_tid_11354);\n    for (int64_t nest_i_11385 = 0; nest_i_11385 < Ry_10061; nest_i_11385++) {\n        for (int64_t nest_i_11386 = 0; nest_i_11386 < tk_div_tx_10063; nest_i_11386++) {\n            int64_t ltid_seq_10334;\n            int64_t ltid_seq_10335;\n            int64_t ltid_y_10332;\n            int64_t ltid_x_10333;\n            int64_t binop_y_10336;\n            int64_t k_10337;\n            int64_t binop_y_10338;\n            int64_t i_10339;\n            int64_t gtid_10340;\n            int64_t as_transformed_row_seqdim_idx_10341;\n            bool binop_x_10342;\n            bool binop_y_10343;\n            bool cond_10344;\n            f16 as_transformed_row_elem_10345;\n            bool cond_10349;\n            int64_t as_transformed_row_loc_ind_10350;\n            \n            ltid_seq_10334 = nest_i_11385;\n            ltid_seq_10335 = nest_i_11386;\n            ltid_y_10332 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n            ltid_x_10333 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n            binop_y_10336 = Ty_10060 * ltid_seq_10335;\n            k_10337 = ltid_y_1", "0332 + binop_y_10336;\n            binop_y_10338 = Ty_10060 * ltid_seq_10334;\n            i_10339 = ltid_x_10333 + binop_y_10338;\n            gtid_10340 = jjj_10080 + i_10339;\n            as_transformed_row_seqdim_idx_10341 = kk_10264 + k_10337;\n            binop_x_10342 = slt64(gtid_10340, (int64_t) 64);\n            binop_y_10343 = slt64(as_transformed_row_seqdim_idx_10341, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n            cond_10344 = binop_x_10342 && binop_y_10343;\n            if (cond_10344) {\n                f16 A_elem_10347 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[as_transformed_row_seqdim_idx_10341 * (int64_t) 64 + gtid_10340]);\n                \n                as_transformed_row_elem_10345 = A_elem_10347;\n            } else {\n                as_transformed_row_elem_10345 = (f16) 0.0F;\n            }\n            cond_10349 = slt64(k_10337, Tk_10062);\n            if (cond_10349) {\n                int64_t binop_y_10351;\n                int64_t x_10352;\n                \n                binop_y_10351 = TxRx_10065 * k_10337;\n                x_10352 = i_10339 + binop_y_10351;\n                as_transformed_row_loc_ind_10350 = x_10352;\n            } else {\n                as_transformed_row_loc_ind_10350 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_10350) && slt64(as_transformed_row_loc_ind_10350, a_loc_szz_10068)) {\n                ((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_10350] = futrts_to_bits16(as_transformed_row_elem_10345);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10392 = sext_i32_i64(local_tid_11354);\n    ltid_y_10391 = sext_i32_i64(sext_i64_i32(ltid_pre_11358));\n    ltid_x_10390 = sext_i32_i64(sext_i64_i32(ltid_pre_11359));\n    binop_x_10407 = Ry_10061 * ltid_y_10391;\n    binop_y_10412 = Ry_10061 * ltid_x_10390;\n    for (int64_t i_10395 = 0; i_10395 < Tk_10062; i_10395++) {\n        int64_t cmpop_x_10397;\n        bool cond_10398;\n        int6", "4_t binop_y_10414;\n        \n        cmpop_x_10397 = kk_10264 + i_10395;\n        cond_10398 = slt64(cmpop_x_10397, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n        binop_y_10414 = TxRx_10065 * i_10395;\n        if (cond_10398) {\n            for (int64_t i_10401 = 0; i_10401 < Ry_10061; i_10401++) {\n                int64_t binop_x_10408;\n                int64_t binop_y_10409;\n                int64_t defunc_0_map_res_loc_ind_64_10410;\n                f16 defunc_0_map_res_loc_elem_10411;\n                \n                binop_x_10408 = i_10401 + binop_x_10407;\n                binop_y_10409 = Tk_10062 * binop_x_10408;\n                defunc_0_map_res_loc_ind_64_10410 = i_10395 + binop_y_10409;\n                if (loop_nonempty_10430) {\n                    f16 x_10428 = futrts_from_bits16(((__local uint16_t *) color_10865)[defunc_0_map_res_loc_ind_64_10410]);\n                    \n                    defunc_0_map_res_loc_elem_10411 = x_10428;\n                } else {\n                    defunc_0_map_res_loc_elem_10411 = (f16) 0.0F;\n                }\n                for (int64_t i_10404 = 0; i_10404 < Ry_10061; i_10404++) {\n                    int64_t binop_x_10413;\n                    int64_t as_transformed_row_loc_ind_64_10415;\n                    f16 as_transformed_row_loc_elem_10416;\n                    f16 c_10417;\n                    f16 defunc_0_f_res_10420;\n                    f16 defunc_0_op_res_10423;\n                    \n                    binop_x_10413 = i_10404 + binop_y_10412;\n                    as_transformed_row_loc_ind_64_10415 = binop_x_10413 + binop_y_10414;\n                    as_transformed_row_loc_elem_10416 = futrts_from_bits16(((__local uint16_t *) color_10864)[as_transformed_row_loc_ind_64_10415]);\n                    c_10417 = ext_mem_10664[i_10401 * Ry_10061 + i_10404];\n                    defunc_0_f_res_10420 = defunc_0_map_res_loc_elem_10411 * as_transformed_row_loc_elem_10416;\n                    defunc_0_op_res_10423 = c_10417 + defunc_0_f_res_1",
                                    "0420;\n                    ext_mem_10664[i_10401 * Ry_10061 + i_10404] = defunc_0_op_res_10423;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_10061; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_10061; i_1++) {\n            mem_10686[i_0 * Ry_10061 + i_1] = ext_mem_10664[i_0 * Ry_10061 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11393 = Ty_10060;\n    slice_11394 = Ty_10060 * slice_11393;\n    slice_11395 = slice_11394;\n    reg_tile_i_11390 = squot64(sext_i32_i64(local_tid_11354), slice_11394);\n    remnant_11396 = sext_i32_i64(local_tid_11354) - reg_tile_i_11390 * slice_11394;\n    reg_tile_i_11391 = squot64(remnant_11396, slice_11393);\n    remnant_11397 = remnant_11396 - reg_tile_i_11391 * slice_11393;\n    reg_tile_i_11392 = remnant_11397;\n    remnant_11398 = remnant_11397 - reg_tile_i_11392;\n    tile_dim_start_11399 = gtid_8960 + reg_tile_i_11390;\n    tile_dim_start_11400 = Ry_10061 * (Ty_10060 * gid_y_10076 + reg_tile_i_11391);\n    tile_dim_start_11401 = Ry_10061 * (Ty_10060 * gid_x_10077 + reg_tile_i_11392);\n    for (int64_t nest_i_11402 = 0; nest_i_11402 < (int64_t) 1; nest_i_11402++) {\n        for (int64_t nest_i_11403 = 0; nest_i_11403 < Ry_10061; nest_i_11403++) {\n            for (int64_t nest_i_11404 = 0; nest_i_11404 < Ry_10061; nest_i_11404++) {\n                if ((slt64(tile_dim_start_11399 + nest_i_11402, m_6626) && slt64(tile_dim_start_11400 + nest_i_11403, (int64_t) 64)) && slt64(tile_dim_start_11401 + nest_i_11404, (int64_t) 64)) {\n                    f16 tmp_11405 = mem_10686[nest_i_11403 * Ry_10061 + nest_i_11404];\n                    \n                    ((__global uint16_t *) mem_10690)[(tile_dim_start_11399 + nest_i_11402) * (int64_t) 4096 + (tile_dim_start_11400 + nest_i_11403) * (int64_t) 64 + (tile_dim_start_11401 + nest_i_11404)] = futrts_to_bits16(tmp_11405);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n    #undef Ty_10060\n    #undef Ry_10061\n    #unde", "f Tk_10062\n    #undef tk_div_tx_10063\n    #undef TxRx_10065\n    #undef a_loc_szz_10068\n    #undef gridDim_x_10071\n    #undef loop_nonempty_10430\n    #undef bytes_10626\n}\nFUTHARK_KERNEL\nvoid run64zisegmap_intrablock_8436(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t one_intra_par_min_8358, int64_t bytes_10763, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10769)\n{\n    volatile __local unsigned char *red_arr_mem_11089_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11089_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11070_backing_2 = &shared_mem[red_arr_mem_11089_backing_3_offset];\n    const int64_t red_arr_mem_11070_backing_2_offset = red_arr_mem_11089_backing_3_offset + ((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10858_backing_1 = &shared_mem[red_arr_mem_11070_backing_2_offset];\n    const int64_t color_10858_backing_1_offset = red_arr_mem_11070_backing_2_offset + (bytes_10763 + srem64((int64_t) 8 - srem64(bytes_10763, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10857_backing_0 = &shared_mem[color_10858_backing_1_offset];\n    const int64_t color_10857_backing_0_offset = color_10858_backing_1_offset + (int64_t) 8192;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11046;\n    int32_t tblock_sizze_11049;\n    int32_t wave_sizze_11048;\n    int32_t block_id_11047;\n    int32_t global_tid_11045;\n    int64_t phys_tblock_id_8436;", "\n    int64_t slice_11053;\n    int64_t slice_11054;\n    int64_t slice_11055;\n    int64_t ltid_pre_11050;\n    int64_t remnant_11056;\n    int64_t ltid_pre_11051;\n    int64_t remnant_11057;\n    int64_t ltid_pre_11052;\n    int64_t remnant_11058;\n    int64_t slice_11062;\n    int64_t slice_11063;\n    int64_t slice_11064;\n    int64_t ltid_pre_11059;\n    int64_t remnant_11065;\n    int64_t ltid_pre_11060;\n    int64_t remnant_11066;\n    int64_t ltid_pre_11061;\n    int64_t remnant_11067;\n    int64_t slice_11068;\n    int64_t gtid_8435;\n    int64_t remnant_11069;\n    __local unsigned char *color_10857;\n    __local unsigned char *color_10858;\n    int64_t phys_tid_8443;\n    __local unsigned char *red_arr_mem_11070;\n    int64_t gtid_8440;\n    int64_t gtid_8441;\n    int64_t gtid_8442;\n    int64_t dims_flat_11072;\n    f16 eta_p_8444;\n    f16 eta_p_8445;\n    f16 eta_p_11074;\n    f16 eta_p_11075;\n    bool ltid_in_bounds_11077;\n    int32_t skip_threads_11078;\n    bool no_carry_in_11084;\n    int64_t phys_tid_8456;\n    __local unsigned char *red_arr_mem_11089;\n    int64_t gtid_8453;\n    int64_t gtid_8454;\n    int64_t gtid_8455;\n    int64_t dims_flat_11091;\n    f16 eta_p_8457;\n    f16 eta_p_8458;\n    f16 eta_p_11093;\n    f16 eta_p_11094;\n    bool ltid_in_bounds_11096;\n    int32_t skip_threads_11097;\n    bool no_carry_in_11103;\n    int32_t num_chunks_11108;\n    \n    local_tid_11046 = get_local_id(0);\n    tblock_sizze_11049 = get_local_size(0);\n    wave_sizze_11048 = LOCKSTEP_WIDTH;\n    block_id_11047 = get_tblock_id(0);\n    global_tid_11045 = block_id_11047 * tblock_sizze_11049 + local_tid_11046;\n    phys_tblock_id_8436 = sext_i32_i64(block_id_11047);\n    slice_11053 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;\n    slice_11054 = (int64_t) 64 * slice_11053;\n    slice_11055 = (int64_t) 64 * slice_11054;\n    ltid_pre_11050 = squot64(sext_i32_i64(local_tid_11046), slice_11054);\n    remnant_11056 = sext_i32_i64(local_tid_11046) - ltid_pre_11050 * slice_11054;\n    ltid_pre_11051 = squot64(remnant_11056,",
                                    " slice_11053);\n    remnant_11057 = remnant_11056 - ltid_pre_11051 * slice_11053;\n    ltid_pre_11052 = remnant_11057;\n    remnant_11058 = remnant_11057 - ltid_pre_11052;\n    slice_11062 = (int64_t) 64;\n    slice_11063 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * slice_11062;\n    slice_11064 = (int64_t) 64 * slice_11063;\n    ltid_pre_11059 = squot64(sext_i32_i64(local_tid_11046), slice_11063);\n    remnant_11065 = sext_i32_i64(local_tid_11046) - ltid_pre_11059 * slice_11063;\n    ltid_pre_11060 = squot64(remnant_11065, slice_11062);\n    remnant_11066 = remnant_11065 - ltid_pre_11060 * slice_11062;\n    ltid_pre_11061 = remnant_11066;\n    remnant_11067 = remnant_11066 - ltid_pre_11061;\n    slice_11068 = m_6626;\n    gtid_8435 = sext_i32_i64(block_id_11047);\n    remnant_11069 = sext_i32_i64(block_id_11047) - gtid_8435;\n    color_10857 = (__local unsigned char *) color_10857_backing_0;\n    color_10858 = (__local unsigned char *) color_10858_backing_1;\n    phys_tid_8443 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11070 = (__local unsigned char *) red_arr_mem_11070_backing_2;\n    gtid_8440 = sext_i32_i64(sext_i64_i32(ltid_pre_11059));\n    gtid_8441 = sext_i32_i64(sext_i64_i32(ltid_pre_11060));\n    gtid_8442 = sext_i32_i64(sext_i64_i32(ltid_pre_11061));\n    if ((slt64(gtid_8440, (int64_t) 64) && slt64(gtid_8441, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) && slt64(gtid_8442, (int64_t) 64)) {\n        f16 eta_p_8449;\n        f16 eta_p_8450;\n        f16 defunc_0_f_res_8451;\n        \n        eta_p_8449 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8435 * (int64_t) 4096 + gtid_8440 * (int64_t) 64 + gtid_8442]);\n        eta_p_8450 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8441 * (int64_t) 64 + gtid_8442]);\n        defunc_0_f_res_8451 = eta_p_8449 * eta_p_8450;\n        ((__local uint16_t *) red_arr_mem_11070)[gtid_8440 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) + gtid_8441 * (int64_t) 64 + gtid_8442] = futrts_to_bits16(defunc_0_f_res_8451);\n  ", "  }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11072 = (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64;\n    ltid_in_bounds_11077 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11077) {\n            eta_p_8445 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_8444 = eta_p_8445;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11078 = 1;\n        while (slt32(skip_threads_11078, 32)) {\n            bool thread_active_11079 = sle32(skip_threads_11078, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11077;\n            \n            if (thread_active_11079) {\n                // read operands\n                {\n                    eta_p_8444 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11078)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11080 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 64), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11078));\n                \n                if (thread_active_11079 && inactive_11080) {\n                    eta_p_8444 = eta_p_8445;\n                }\n                if (thread_active_11079) {\n                    if (!inactive_11080) {\n                        f16 defunc_0_op_res_8446 = eta_p_8444 + eta_p_8445;\n                        \n                        eta_p_8444 = defunc_0_op_res_8446;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        ", "    if (thread_active_11079) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_8444);\n                    eta_p_8445 = eta_p_8444;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11078)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11078 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11077) {\n            ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_8444);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11081;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n                eta_p_11075 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11074 = eta_p_11075;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11081 = 1;\n            while (slt32(skip_threads_11081, 32)) {\n                bool thread_active_11082 = sle32(skip_threads_11081, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077);\n                \n                if (thread_active_11082) {\n                    // read operands\n                    {\n                        eta_p_11074 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_",
                                    "i64(local_tid_11046) - sext_i32_i64(skip_threads_11081)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11083 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), (int64_t) 64), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11081) * 32 + 32 - 1));\n                    \n                    if (thread_active_11082 && inactive_11083) {\n                        eta_p_11074 = eta_p_11075;\n                    }\n                    if (thread_active_11082) {\n                        if (!inactive_11083) {\n                            f16 defunc_0_op_res_11076 = eta_p_11074 + eta_p_11075;\n                            \n                            eta_p_11074 = defunc_0_op_res_11076;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11082) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11074);\n                        eta_p_11075 = eta_p_11074;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11081)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11081 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11084 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11077;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11084) {\n                eta_p_8445 = eta_p_8444;\n                eta_p_8444 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }", "\n        }\n        // perform operation\n        {\n            bool inactive_11085 = slt64(srem64(sext_i32_i64(local_tid_11046), (int64_t) 64), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11084) {\n                if (inactive_11085) {\n                    eta_p_8444 = eta_p_8445;\n                }\n            }\n            if (!no_carry_in_11084) {\n                if (!inactive_11085) {\n                    f16 defunc_0_op_res_8446 = eta_p_8444 + eta_p_8445;\n                    \n                    eta_p_8444 = defunc_0_op_res_8446;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11084) {\n                ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_8444);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11077) {\n            ((__local uint16_t *) red_arr_mem_11070)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_8445);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11086 = sdiv_up32(64 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i64_i32(one_intra_par_min_8358));\n        \n        for (int32_t chunk_i_11087 = 0; chunk_i_11087 < num_chunks_11086; chunk_i_11087++) {\n            int32_t i_11088 = chunk_i_11087 * sext_i64_i32(one_intra_par_min_8358) + local_tid_11046;\n            \n            if (slt32(i_11088, 64 * sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627))) {\n                ((__local uint16_t *) color_10858)[sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627))) * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) *", " sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627))] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11070)[(int64_t) 63 + sext_i32_i64(squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627))) * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) + sext_i32_i64(i_11088 - squot32(i_11088, sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) * sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) * (int64_t) 64]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_8456 = sext_i32_i64(local_tid_11046);\n    red_arr_mem_11089 = (__local unsigned char *) red_arr_mem_11089_backing_3;\n    gtid_8453 = sext_i32_i64(sext_i64_i32(ltid_pre_11050));\n    gtid_8454 = sext_i32_i64(sext_i64_i32(ltid_pre_11051));\n    gtid_8455 = sext_i32_i64(sext_i64_i32(ltid_pre_11052));\n    if ((slt64(gtid_8453, (int64_t) 64) && slt64(gtid_8454, (int64_t) 64)) && slt64(gtid_8455, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) {\n        f16 eta_p_8462;\n        f16 eta_p_8463;\n        f16 defunc_0_f_res_8464;\n        \n        eta_p_8462 = futrts_from_bits16(((__local uint16_t *) color_10858)[gtid_8453 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8455]);\n        eta_p_8463 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_8455 * (int64_t) 64 + gtid_8454]);\n        defunc_0_f_res_8464 = eta_p_8462 * eta_p_8463;\n        ((__local uint16_t *) red_arr_mem_11089)[gtid_8453 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + gtid_8454 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8455] = futrts_to_bits16(defunc_0_f_res_8464);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11091 = (int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;\n    ltid_in_bounds_11096 = slt64(sext_i32_i64(local_tid_11046), (int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11096) {\n            eta_p_8458 = futrts_from_bits16(((volatile __local uint16_t *)",
                                    " red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n            if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                eta_p_8457 = eta_p_8458;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11097 = 1;\n        while (slt32(skip_threads_11097, 32)) {\n            bool thread_active_11098 = sle32(skip_threads_11097, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && ltid_in_bounds_11096;\n            \n            if (thread_active_11098) {\n                // read operands\n                {\n                    eta_p_8457 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11097)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11099 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11046) - sext_i32_i64(local_tid_11046 - skip_threads_11097));\n                \n                if (thread_active_11098 && inactive_11099) {\n                    eta_p_8457 = eta_p_8458;\n                }\n                if (thread_active_11098) {\n                    if (!inactive_11099) {\n                        f16 defunc_0_op_res_8459 = eta_p_8457 + eta_p_8458;\n                        \n                        eta_p_8457 = defunc_0_op_res_8459;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11098) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_8457);\n                    eta_p_8458 = eta_p_8457;\n                }\n            }\n            if (sle32(wave_sizze_11048, skip_threads_11097)) {\n                barrier(CLK_LOCAL_", "MEM_FENCE);\n            }\n            skip_threads_11097 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 31 && ltid_in_bounds_11096) {\n            ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32))] = futrts_to_bits16(eta_p_8457);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11100;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n                eta_p_11094 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)]);\n                if ((local_tid_11046 - squot32(local_tid_11046, 32) * 32) == 0) {\n                    eta_p_11093 = eta_p_11094;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11100 = 1;\n            while (slt32(skip_threads_11100, 32)) {\n                bool thread_active_11101 = sle32(skip_threads_11100, local_tid_11046 - squot32(local_tid_11046, 32) * 32) && (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096);\n                \n                if (thread_active_11101) {\n                    // read operands\n                    {\n                        eta_p_11093 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046) - sext_i32_i64(skip_threads_11100)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11102 = slt64(srem64(sext_i32_i64(local_tid_11046 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11046 * 32 + 32 - 1) - sext_i32_i64((local_tid_11046 - skip_threads_11100", ") * 32 + 32 - 1));\n                    \n                    if (thread_active_11101 && inactive_11102) {\n                        eta_p_11093 = eta_p_11094;\n                    }\n                    if (thread_active_11101) {\n                        if (!inactive_11102) {\n                            f16 defunc_0_op_res_11095 = eta_p_11093 + eta_p_11094;\n                            \n                            eta_p_11093 = defunc_0_op_res_11095;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11101) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_11093);\n                        eta_p_11094 = eta_p_11093;\n                    }\n                }\n                if (sle32(wave_sizze_11048, skip_threads_11100)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11100 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11103 = squot32(local_tid_11046, 32) == 0 || !ltid_in_bounds_11096;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11103) {\n                eta_p_8458 = eta_p_8457;\n                eta_p_8457 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(squot32(local_tid_11046, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11104 = slt64(srem64(sext_i32_i64(local_tid_11046), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11046) - sext_i32_i64(squot32(local_tid_11046, 32) * 32 - 1));\n            \n            if (!no_carry_in_11103) {\n                if (inactive_11104) {\n                    eta_",
                                    "p_8457 = eta_p_8458;\n                }\n            }\n            if (!no_carry_in_11103) {\n                if (!inactive_11104) {\n                    f16 defunc_0_op_res_8459 = eta_p_8457 + eta_p_8458;\n                    \n                    eta_p_8457 = defunc_0_op_res_8459;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11103) {\n                ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_8457);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11046, 32) == 0 && ltid_in_bounds_11096) {\n            ((__local uint16_t *) red_arr_mem_11089)[sext_i32_i64(local_tid_11046)] = futrts_to_bits16(eta_p_8458);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11105 = sdiv_up32(4096, sext_i64_i32(one_intra_par_min_8358));\n        \n        for (int32_t chunk_i_11106 = 0; chunk_i_11106 < num_chunks_11105; chunk_i_11106++) {\n            int32_t i_11107 = chunk_i_11106 * sext_i64_i32(one_intra_par_min_8358) + local_tid_11046;\n            \n            if (slt32(i_11107, 4096)) {\n                ((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11107, 64)) * (int64_t) 64 + sext_i32_i64(i_11107 - squot32(i_11107, 64) * 64)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11089)[dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 - (int64_t) 1 + sext_i32_i64(squot32(i_11107, 64)) * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + sext_i32_i64(i_11107 - squot32(i_11107, 64) * 64) * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11108 = sdiv_up32(4096, sext_i64_i32(one_intra_par_min_8358));\n    for (int32_t chunk_i_11109 = 0; chunk_i_11109 < num_ch", "unks_11108; chunk_i_11109++) {\n        int32_t i_11110 = chunk_i_11109 * sext_i64_i32(one_intra_par_min_8358) + local_tid_11046;\n        \n        if (slt32(i_11110, 4096)) {\n            ((__global uint16_t *) mem_10769)[gtid_8435 * (int64_t) 4096 + sext_i32_i64(squot32(i_11110, 64)) * (int64_t) 64 + sext_i32_i64(i_11110 - squot32(i_11110, 64) * 64)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10857)[sext_i32_i64(squot32(i_11110, 64)) * (int64_t) 64 + sext_i32_i64(i_11110 - squot32(i_11110, 64) * 64)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL\nvoid run64zisegmap_intrablock_8877(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t one_intra_par_min_8836, int64_t bytes_10693, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *V_mem_10474, __global unsigned char *mem_10699)\n{\n    volatile __local unsigned char *red_arr_mem_11173_backing_3 = &shared_mem[0];\n    const int64_t red_arr_mem_11173_backing_3_offset = 0 + ((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_mem_11154_backing_2 = &shared_mem[red_arr_mem_11173_backing_3_offset];\n    const int64_t red_arr_mem_11154_backing_2_offset = red_arr_mem_11173_backing_3_offset + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10861_backing_1 = &shared_mem[red_arr_mem_11154_backing_2_offset];\n    const int64_t color_10861_backing_1_offset = red_arr_mem_11154_backing_2_offset + (bytes_10693 + srem64((int64_t) 8 - srem64(bytes_10693, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned", " char *color_10860_backing_0 = &shared_mem[color_10861_backing_1_offset];\n    const int64_t color_10860_backing_0_offset = color_10861_backing_1_offset + (int64_t) 128;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11134;\n    int32_t tblock_sizze_11137;\n    int32_t wave_sizze_11136;\n    int32_t block_id_11135;\n    int32_t global_tid_11133;\n    int64_t phys_tblock_id_8877;\n    int64_t slice_11140;\n    int64_t slice_11141;\n    int64_t ltid_pre_11138;\n    int64_t remnant_11142;\n    int64_t ltid_pre_11139;\n    int64_t remnant_11143;\n    int64_t slice_11146;\n    int64_t slice_11147;\n    int64_t ltid_pre_11144;\n    int64_t remnant_11148;\n    int64_t ltid_pre_11145;\n    int64_t remnant_11149;\n    int64_t slice_11150;\n    int64_t slice_11151;\n    int64_t gtid_8875;\n    int64_t remnant_11152;\n    int64_t gtid_8876;\n    int64_t remnant_11153;\n    __local unsigned char *color_10860;\n    __local unsigned char *color_10861;\n    int64_t phys_tid_8883;\n    __local unsigned char *red_arr_mem_11154;\n    int64_t gtid_8881;\n    int64_t gtid_8882;\n    int64_t dims_flat_11156;\n    f16 eta_p_8884;\n    f16 eta_p_8885;\n    f16 eta_p_11158;\n    f16 eta_p_11159;\n    bool ltid_in_bounds_11161;\n    int32_t skip_threads_11162;\n    bool no_carry_in_11168;\n    int64_t phys_tid_8894;\n    __local unsigned char *red_arr_mem_11173;\n    int64_t gtid_8892;\n    int64_t gtid_8893;\n    int64_t dims_flat_11175;\n    f16 eta_p_8895;\n    f16 eta_p_8896;\n    f16 eta_p_11177;\n    f16 eta_p_11178;\n    bool ltid_in_bounds_11180;\n    int32_t skip_threads_11181;\n    bool no_carry_in_11187;\n    int32_t num_chunks_11192;\n    \n    local_tid_11134 = get_local_id(0);\n    tblock_sizze_11137 = get_local_size(0);\n    wave_sizze_11136 = LOCKSTEP_WIDTH;\n    block_id_11135 = get_tblock_id(0);\n    global_tid_11133 = block_id_11135 * tblock_sizze_11137 + local_tid_11134;\n    phys_tblock_id_8877 = sext_i32_i64(block_id_11135);\n    slice_11140 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;\n    slice_11141 ",
                                    "= (int64_t) 64 * slice_11140;\n    ltid_pre_11138 = squot64(sext_i32_i64(local_tid_11134), slice_11140);\n    remnant_11142 = sext_i32_i64(local_tid_11134) - ltid_pre_11138 * slice_11140;\n    ltid_pre_11139 = remnant_11142;\n    remnant_11143 = remnant_11142 - ltid_pre_11139;\n    slice_11146 = (int64_t) 64;\n    slice_11147 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * slice_11146;\n    ltid_pre_11144 = squot64(sext_i32_i64(local_tid_11134), slice_11146);\n    remnant_11148 = sext_i32_i64(local_tid_11134) - ltid_pre_11144 * slice_11146;\n    ltid_pre_11145 = remnant_11148;\n    remnant_11149 = remnant_11148 - ltid_pre_11145;\n    slice_11150 = (int64_t) 64;\n    slice_11151 = m_6626 * slice_11150;\n    gtid_8875 = squot64(sext_i32_i64(block_id_11135), slice_11150);\n    remnant_11152 = sext_i32_i64(block_id_11135) - gtid_8875 * slice_11150;\n    gtid_8876 = remnant_11152;\n    remnant_11153 = remnant_11152 - gtid_8876;\n    color_10860 = (__local unsigned char *) color_10860_backing_0;\n    color_10861 = (__local unsigned char *) color_10861_backing_1;\n    phys_tid_8883 = sext_i32_i64(local_tid_11134);\n    red_arr_mem_11154 = (__local unsigned char *) red_arr_mem_11154_backing_2;\n    gtid_8881 = sext_i32_i64(sext_i64_i32(ltid_pre_11144));\n    gtid_8882 = sext_i32_i64(sext_i64_i32(ltid_pre_11145));\n    if (slt64(gtid_8881, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) && slt64(gtid_8882, (int64_t) 64)) {\n        f16 eta_p_8888;\n        f16 eta_p_8889;\n        f16 defunc_0_f_res_8890;\n        \n        eta_p_8888 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8875 * (int64_t) 4096 + gtid_8876 * (int64_t) 64 + gtid_8882]);\n        eta_p_8889 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8881 * (int64_t) 64 + gtid_8882]);\n        defunc_0_f_res_8890 = eta_p_8888 * eta_p_8889;\n        ((__local uint16_t *) red_arr_mem_11154)[gtid_8881 * (int64_t) 64 + gtid_8882] = futrts_to_bits16(defunc_0_f_res_8890);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11156 = dzlz7bUZ", "LztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64;\n    ltid_in_bounds_11161 = slt64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11161) {\n            eta_p_8885 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_8884 = eta_p_8885;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11162 = 1;\n        while (slt32(skip_threads_11162, 32)) {\n            bool thread_active_11163 = sle32(skip_threads_11162, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11161;\n            \n            if (thread_active_11163) {\n                // read operands\n                {\n                    eta_p_8884 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11162)]);\n                }\n            }\n            // perform operation\n            {\n                bool inactive_11164 = slt64(srem64(sext_i32_i64(local_tid_11134), (int64_t) 64), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11162));\n                \n                if (thread_active_11163 && inactive_11164) {\n                    eta_p_8884 = eta_p_8885;\n                }\n                if (thread_active_11163) {\n                    if (!inactive_11164) {\n                        f16 defunc_0_op_res_8886 = eta_p_8884 + eta_p_8885;\n                        \n                        eta_p_8884 = defunc_0_op_res_8886;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11163) {\n                // write result\n                {\n                 ", "   ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8884);\n                    eta_p_8885 = eta_p_8884;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11162)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11162 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11161) {\n            ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_8884);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11165;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n                eta_p_11159 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11158 = eta_p_11159;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11165 = 1;\n            while (slt32(skip_threads_11165, 32)) {\n                bool thread_active_11166 = sle32(skip_threads_11165, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161);\n                \n                if (thread_active_11166) {\n                    // read operands\n                    {\n                        eta_p_11158 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11165)]);\n                    }\n                }",
                                    "\n                // perform operation\n                {\n                    bool inactive_11167 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), (int64_t) 64), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11165) * 32 + 32 - 1));\n                    \n                    if (thread_active_11166 && inactive_11167) {\n                        eta_p_11158 = eta_p_11159;\n                    }\n                    if (thread_active_11166) {\n                        if (!inactive_11167) {\n                            f16 defunc_0_op_res_11160 = eta_p_11158 + eta_p_11159;\n                            \n                            eta_p_11158 = defunc_0_op_res_11160;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11166) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11158);\n                        eta_p_11159 = eta_p_11158;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11165)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11165 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11168 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11161;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11168) {\n                eta_p_8885 = eta_p_8884;\n                eta_p_8884 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11169 = slt64(srem64(s", "ext_i32_i64(local_tid_11134), (int64_t) 64), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11168) {\n                if (inactive_11169) {\n                    eta_p_8884 = eta_p_8885;\n                }\n            }\n            if (!no_carry_in_11168) {\n                if (!inactive_11169) {\n                    f16 defunc_0_op_res_8886 = eta_p_8884 + eta_p_8885;\n                    \n                    eta_p_8884 = defunc_0_op_res_8886;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11168) {\n                ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8884);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11161) {\n            ((__local uint16_t *) red_arr_mem_11154)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8885);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11170 = sdiv_up32(sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i64_i32(one_intra_par_min_8836));\n        \n        for (int32_t chunk_i_11171 = 0; chunk_i_11171 < num_chunks_11170; chunk_i_11171++) {\n            int32_t i_11172 = chunk_i_11171 * sext_i64_i32(one_intra_par_min_8836) + local_tid_11134;\n            \n            if (slt32(i_11172, sext_i64_i32(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627))) {\n                ((__local uint16_t *) color_10861)[sext_i32_i64(i_11172)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11154)[(int64_t) 63 + sext_i32_i64(i_11172) * (int64_t) 64]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    phys_tid_8894 = sext_i32_i64(local_tid_11134);\n    red_arr", "_mem_11173 = (__local unsigned char *) red_arr_mem_11173_backing_3;\n    gtid_8892 = sext_i32_i64(sext_i64_i32(ltid_pre_11138));\n    gtid_8893 = sext_i32_i64(sext_i64_i32(ltid_pre_11139));\n    if (slt64(gtid_8892, (int64_t) 64) && slt64(gtid_8893, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) {\n        f16 eta_p_8899;\n        f16 eta_p_8900;\n        f16 defunc_0_f_res_8901;\n        \n        eta_p_8899 = futrts_from_bits16(((__local uint16_t *) color_10861)[gtid_8893]);\n        eta_p_8900 = futrts_from_bits16(((__global uint16_t *) V_mem_10474)[gtid_8893 * (int64_t) 64 + gtid_8892]);\n        defunc_0_f_res_8901 = eta_p_8899 * eta_p_8900;\n        ((__local uint16_t *) red_arr_mem_11173)[gtid_8892 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8893] = futrts_to_bits16(defunc_0_f_res_8901);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dims_flat_11175 = (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;\n    ltid_in_bounds_11180 = slt64(sext_i32_i64(local_tid_11134), (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n    // read input for in-block scan\n    {\n        if (ltid_in_bounds_11180) {\n            eta_p_8896 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)]);\n            if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                eta_p_8895 = eta_p_8896;\n            }\n        }\n    }\n    // in-block scan (hopefully no barriers needed)\n    {\n        skip_threads_11181 = 1;\n        while (slt32(skip_threads_11181, 32)) {\n            bool thread_active_11182 = sle32(skip_threads_11181, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && ltid_in_bounds_11180;\n            \n            if (thread_active_11182) {\n                // read operands\n                {\n                    eta_p_8895 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11181)]);\n                }\n            }\n            // perform operation\n         ",
                                    "   {\n                bool inactive_11183 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11134) - sext_i32_i64(local_tid_11134 - skip_threads_11181));\n                \n                if (thread_active_11182 && inactive_11183) {\n                    eta_p_8895 = eta_p_8896;\n                }\n                if (thread_active_11182) {\n                    if (!inactive_11183) {\n                        f16 defunc_0_op_res_8897 = eta_p_8895 + eta_p_8896;\n                        \n                        eta_p_8895 = defunc_0_op_res_8897;\n                    }\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            if (thread_active_11182) {\n                // write result\n                {\n                    ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8895);\n                    eta_p_8896 = eta_p_8895;\n                }\n            }\n            if (sle32(wave_sizze_11136, skip_threads_11181)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n            skip_threads_11181 *= 2;\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // last thread of block 'i' writes its result to offset 'i'\n    {\n        if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 31 && ltid_in_bounds_11180) {\n            ((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32))] = futrts_to_bits16(eta_p_8895);\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n    {\n        int32_t skip_threads_11184;\n        \n        // read input for in-block scan\n        {\n            if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n                eta_p_11178 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_1117", "3)[sext_i32_i64(local_tid_11134)]);\n                if ((local_tid_11134 - squot32(local_tid_11134, 32) * 32) == 0) {\n                    eta_p_11177 = eta_p_11178;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_11184 = 1;\n            while (slt32(skip_threads_11184, 32)) {\n                bool thread_active_11185 = sle32(skip_threads_11184, local_tid_11134 - squot32(local_tid_11134, 32) * 32) && (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180);\n                \n                if (thread_active_11185) {\n                    // read operands\n                    {\n                        eta_p_11177 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134) - sext_i32_i64(skip_threads_11184)]);\n                    }\n                }\n                // perform operation\n                {\n                    bool inactive_11186 = slt64(srem64(sext_i32_i64(local_tid_11134 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11134 * 32 + 32 - 1) - sext_i32_i64((local_tid_11134 - skip_threads_11184) * 32 + 32 - 1));\n                    \n                    if (thread_active_11185 && inactive_11186) {\n                        eta_p_11177 = eta_p_11178;\n                    }\n                    if (thread_active_11185) {\n                        if (!inactive_11186) {\n                            f16 defunc_0_op_res_11179 = eta_p_11177 + eta_p_11178;\n                            \n                            eta_p_11177 = defunc_0_op_res_11179;\n                        }\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_11185) {\n                    // write result\n                    {\n                        ((volatile __local uint16_t *) red_arr_mem_11173)[sext_", "i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_11177);\n                        eta_p_11178 = eta_p_11177;\n                    }\n                }\n                if (sle32(wave_sizze_11136, skip_threads_11184)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_11184 *= 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    no_carry_in_11187 = squot32(local_tid_11134, 32) == 0 || !ltid_in_bounds_11180;\n    // carry-in for every block except the first\n    {\n        // read operands\n        {\n            if (!no_carry_in_11187) {\n                eta_p_8896 = eta_p_8895;\n                eta_p_8895 = futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(squot32(local_tid_11134, 32)) - (int64_t) 1]);\n            }\n        }\n        // perform operation\n        {\n            bool inactive_11188 = slt64(srem64(sext_i32_i64(local_tid_11134), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11134) - sext_i32_i64(squot32(local_tid_11134, 32) * 32 - 1));\n            \n            if (!no_carry_in_11187) {\n                if (inactive_11188) {\n                    eta_p_8895 = eta_p_8896;\n                }\n            }\n            if (!no_carry_in_11187) {\n                if (!inactive_11188) {\n                    f16 defunc_0_op_res_8897 = eta_p_8895 + eta_p_8896;\n                    \n                    eta_p_8895 = defunc_0_op_res_8897;\n                }\n            }\n        }\n        // write final result\n        {\n            if (!no_carry_in_11187) {\n                ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8895);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // restore correct values for first block\n    {\n        if (squot32(local_tid_11134, 32) == 0 && ltid_in_bounds_11180) {\n            ((__local uint16_t *) red_arr_mem_11173)[sext_i32_i64(local_tid_11134)] = futrts_to_bits16(eta_p_8896);\n       ",
                                    " }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Save result of reduction.\n    {\n        int32_t num_chunks_11189 = sdiv_up32(64, sext_i64_i32(one_intra_par_min_8836));\n        \n        for (int32_t chunk_i_11190 = 0; chunk_i_11190 < num_chunks_11189; chunk_i_11190++) {\n            int32_t i_11191 = chunk_i_11190 * sext_i64_i32(one_intra_par_min_8836) + local_tid_11134;\n            \n            if (slt32(i_11191, 64)) {\n                ((__local uint16_t *) color_10860)[sext_i32_i64(i_11191)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) red_arr_mem_11173)[dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 - (int64_t) 1 + sext_i32_i64(i_11191) * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627]));\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    num_chunks_11192 = sdiv_up32(64, sext_i64_i32(one_intra_par_min_8836));\n    for (int32_t chunk_i_11193 = 0; chunk_i_11193 < num_chunks_11192; chunk_i_11193++) {\n        int32_t i_11194 = chunk_i_11193 * sext_i64_i32(one_intra_par_min_8836) + local_tid_11134;\n        \n        if (slt32(i_11194, 64)) {\n            ((__global uint16_t *) mem_10699)[gtid_8875 * (int64_t) 4096 + gtid_8876 * (int64_t) 64 + sext_i32_i64(i_11194)] = futrts_to_bits16(futrts_from_bits16(((__local uint16_t *) color_10860)[sext_i32_i64(i_11194)]));\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n  error_6:\n    return;\n}\nFUTHARK_KERNEL_SIZED(run64zisegmap_intrablock_9700_dim1, 1, 1)\nvoid run64zisegmap_intrablock_9700(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t gridDim_x_9693, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10575)\n{\n    #define Ty_9680 (run64zisegmap_intrablock_9700ziTy_9680)\n    #define Ry_9681 (run64zisegmap_intrablock_9700ziRy_9681)\n    #define Tk_9682 (run64zisegmap_intrablock_9700ziTk_9682)\n    #define tk_div_tx_9683 (run64zisegmap_intrablock_", "9700zitk_div_tx_9683)\n    #define TxRx_9685 (run64zisegmap_intrablock_9700ziTxRx_9685)\n    #define a_loc_szz_9688 (run64zisegmap_intrablock_9700zia_loc_szz_9688)\n    #define b_loc_szz_9692 (run64zisegmap_intrablock_9700zib_loc_szz_9692)\n    #define gridDim_y_9694 (run64zisegmap_intrablock_9700zigridDim_y_9694)\n    #define full_tiles_9728 (run64zisegmap_intrablock_9700zifull_tiles_9728)\n    #define binop_y_9874 (run64zisegmap_intrablock_9700zibinop_y_9874)\n    #define kk_9890 (run64zisegmap_intrablock_9700zikk_9890)\n    #define loop_nonempty_10436 (run64zisegmap_intrablock_9700ziloop_nonempty_10436)\n    #define bytes_10511 (run64zisegmap_intrablock_9700zibytes_10511)\n    #define bytes_10513 (run64zisegmap_intrablock_9700zibytes_10513)\n    \n    volatile __local unsigned char *color_10863_backing_1 = &shared_mem[0];\n    const int64_t color_10863_backing_1_offset = 0 + (bytes_10511 + srem64((int64_t) 8 - srem64(bytes_10511, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *color_10862_backing_0 = &shared_mem[color_10863_backing_1_offset];\n    const int64_t color_10862_backing_0_offset = color_10863_backing_1_offset + (bytes_10513 + srem64((int64_t) 8 - srem64(bytes_10513, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11198;\n    int32_t tblock_sizze_11201;\n    int32_t wave_sizze_11200;\n    int32_t block_id_11199;\n    int32_t global_tid_11197;\n    int64_t gid_flat_9700;\n    int64_t slice_11204;\n    int64_t slice_11205;\n    int64_t ltid_pre_11202;\n    int64_t remnant_11206;\n    int64_t ltid_pre_11203;\n    int64_t remnant_11207;\n    int64_t slice_11208;\n    int64_t slice_11209;\n    int64_t slice_11210;\n    int64_t gtid_8913;\n    int64_t remnant_11211;\n    int64_t gid_y_9698;\n    int64_t remnant_11212;\n    int64_t gid_x_9699;\n    int64_t remnant_11213;\n    __local unsigned char *color_10862;\n    __local unsigned char *color_10863;\n    int64_t iii_9701;\n    int64_t jjj_9702;\n    f16 mem_10510[Ry_9681 ", "* Ry_9681];\n    int64_t ltid_flat_9716;\n    int64_t ltid_y_9715;\n    int64_t ltid_x_9714;\n    f16 mem_10491[Ry_9681 * Ry_9681];\n    f16 ext_mem_10549[Ry_9681 * Ry_9681];\n    f16 mem_param_10515[Ry_9681 * Ry_9681];\n    int64_t ltid_flat_9912;\n    int64_t ltid_flat_9958;\n    f16 mem_10571[Ry_9681 * Ry_9681];\n    int64_t ltid_flat_10021;\n    int64_t ltid_y_10020;\n    int64_t ltid_x_10019;\n    int64_t binop_x_10036;\n    int64_t binop_x_10041;\n    int64_t slice_11237;\n    int64_t slice_11238;\n    int64_t slice_11239;\n    int64_t reg_tile_i_11234;\n    int64_t remnant_11240;\n    int64_t reg_tile_i_11235;\n    int64_t remnant_11241;\n    int64_t reg_tile_i_11236;\n    int64_t remnant_11242;\n    int64_t tile_dim_start_11243;\n    int64_t tile_dim_start_11244;\n    int64_t tile_dim_start_11245;\n    \n    local_tid_11198 = get_local_id(0);\n    tblock_sizze_11201 = get_local_size(0);\n    wave_sizze_11200 = LOCKSTEP_WIDTH;\n    block_id_11199 = get_tblock_id(0);\n    global_tid_11197 = block_id_11199 * tblock_sizze_11201 + local_tid_11198;\n    gid_flat_9700 = sext_i32_i64(block_id_11199);\n    slice_11204 = Ty_9680;\n    slice_11205 = Ty_9680 * slice_11204;\n    ltid_pre_11202 = squot64(sext_i32_i64(local_tid_11198), slice_11204);\n    remnant_11206 = sext_i32_i64(local_tid_11198) - ltid_pre_11202 * slice_11204;\n    ltid_pre_11203 = remnant_11206;\n    remnant_11207 = remnant_11206 - ltid_pre_11203;\n    slice_11208 = gridDim_x_9693;\n    slice_11209 = gridDim_y_9694 * slice_11208;\n    slice_11210 = m_6626 * slice_11209;\n    gtid_8913 = squot64(sext_i32_i64(block_id_11199), slice_11209);\n    remnant_11211 = sext_i32_i64(block_id_11199) - gtid_8913 * slice_11209;\n    gid_y_9698 = squot64(remnant_11211, slice_11208);\n    remnant_11212 = remnant_11211 - gid_y_9698 * slice_11208;\n    gid_x_9699 = remnant_11212;\n    remnant_11213 = remnant_11212 - gid_x_9699;\n    color_10862 = (__local unsigned char *) color_10862_backing_0;\n    color_10863 = (__local unsigned char *) color_10863_backing_1;\n    iii",
                                    "_9701 = TxRx_9685 * gid_y_9698;\n    jjj_9702 = TxRx_9685 * gid_x_9699;\n    ltid_flat_9716 = sext_i32_i64(local_tid_11198);\n    ltid_y_9715 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_9714 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    for (int64_t i_9719 = 0; i_9719 < Ry_9681; i_9719++) {\n        for (int64_t i_9722 = 0; i_9722 < Ry_9681; i_9722++) {\n            mem_10491[i_9719 * Ry_9681 + i_9722] = (f16) 0.0F;\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_9681; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_9681; i_1++) {\n            mem_10510[i_0 * Ry_9681 + i_1] = mem_10491[i_0 * Ry_9681 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for (int32_t i_2 = 0; i_2 < Ry_9681 * Ry_9681; i_2++)\n        mem_param_10515[i_2] = mem_10510[i_2];\n    for (int64_t i_9729 = 0; i_9729 < full_tiles_9728; i_9729++) {\n        int64_t kk_9733;\n        int64_t ltid_flat_9753;\n        int64_t ltid_flat_9795;\n        f16 mem_10542[Ry_9681 * Ry_9681];\n        int64_t ltid_flat_9854;\n        int64_t ltid_y_9853;\n        int64_t ltid_x_9852;\n        int64_t binop_x_9867;\n        int64_t binop_x_9872;\n        f16 mem_param_tmp_11216[Ry_9681 * Ry_9681];\n        \n        kk_9733 = Tk_9682 * i_9729;\n        ltid_flat_9753 = sext_i32_i64(local_tid_11198);\n        for (int64_t nest_i_11220 = 0; nest_i_11220 < Ry_9681; nest_i_11220++) {\n            for (int64_t nest_i_11221 = 0; nest_i_11221 < tk_div_tx_9683; nest_i_11221++) {\n                int64_t ltid_seq_9756;\n                int64_t ltid_seq_9757;\n                int64_t ltid_y_9754;\n                int64_t ltid_x_9755;\n                int64_t binop_y_9758;\n                int64_t k_9759;\n                int64_t binop_y_9760;\n                int64_t i_9761;\n                int64_t gtid_9762;\n                int64_t as_transformed_row_seqdim_idx_9763;\n                bool cond_9764;\n                f16 as_transformed_row_elem_9765;\n                bool cond_9769;\n       ", "         int64_t as_transformed_row_loc_ind_9770;\n                \n                ltid_seq_9756 = nest_i_11220;\n                ltid_seq_9757 = nest_i_11221;\n                ltid_y_9754 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9755 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9758 = Ty_9680 * ltid_seq_9757;\n                k_9759 = ltid_x_9755 + binop_y_9758;\n                binop_y_9760 = Ty_9680 * ltid_seq_9756;\n                i_9761 = ltid_y_9754 + binop_y_9760;\n                gtid_9762 = iii_9701 + i_9761;\n                as_transformed_row_seqdim_idx_9763 = kk_9733 + k_9759;\n                cond_9764 = slt64(gtid_9762, (int64_t) 64);\n                if (cond_9764) {\n                    f16 A_elem_9767 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8913 * (int64_t) 4096 + gtid_9762 * (int64_t) 64 + as_transformed_row_seqdim_idx_9763]);\n                    \n                    as_transformed_row_elem_9765 = A_elem_9767;\n                } else {\n                    as_transformed_row_elem_9765 = (f16) 0.0F;\n                }\n                cond_9769 = slt64(k_9759, Tk_9682);\n                if (cond_9769) {\n                    int64_t binop_y_9771;\n                    int64_t x_9772;\n                    \n                    binop_y_9771 = Tk_9682 * i_9761;\n                    x_9772 = k_9759 + binop_y_9771;\n                    as_transformed_row_loc_ind_9770 = x_9772;\n                } else {\n                    as_transformed_row_loc_ind_9770 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9770) && slt64(as_transformed_row_loc_ind_9770, a_loc_szz_9688)) {\n                    ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9770] = futrts_to_bits16(as_transformed_row_elem_9765);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9795 = sext_i32_i64(local_tid_11198);\n        for (int6", "4_t nest_i_11222 = 0; nest_i_11222 < Ry_9681; nest_i_11222++) {\n            for (int64_t nest_i_11223 = 0; nest_i_11223 < tk_div_tx_9683; nest_i_11223++) {\n                int64_t ltid_seq_9798;\n                int64_t ltid_seq_9799;\n                int64_t ltid_y_9796;\n                int64_t ltid_x_9797;\n                int64_t binop_y_9800;\n                int64_t k_9801;\n                int64_t binop_y_9802;\n                int64_t i_9803;\n                int64_t gtid_9804;\n                int64_t as_transformed_row_seqdim_idx_9805;\n                bool cond_9806;\n                f16 as_transformed_row_elem_9807;\n                bool cond_9811;\n                int64_t as_transformed_row_loc_ind_9812;\n                \n                ltid_seq_9798 = nest_i_11222;\n                ltid_seq_9799 = nest_i_11223;\n                ltid_y_9796 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n                ltid_x_9797 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n                binop_y_9800 = Ty_9680 * ltid_seq_9799;\n                k_9801 = ltid_x_9797 + binop_y_9800;\n                binop_y_9802 = Ty_9680 * ltid_seq_9798;\n                i_9803 = ltid_y_9796 + binop_y_9802;\n                gtid_9804 = jjj_9702 + i_9803;\n                as_transformed_row_seqdim_idx_9805 = kk_9733 + k_9801;\n                cond_9806 = slt64(gtid_9804, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n                if (cond_9806) {\n                    f16 A_elem_9809 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9804 * (int64_t) 64 + as_transformed_row_seqdim_idx_9805]);\n                    \n                    as_transformed_row_elem_9807 = A_elem_9809;\n                } else {\n                    as_transformed_row_elem_9807 = (f16) 0.0F;\n                }\n                cond_9811 = slt64(k_9801, Tk_9682);\n                if (cond_9811) {\n                    int64_t binop_y_9813;\n                    int64_t binop_y_9814;\n                    int64_t x_9815;\n                    \n  ",
                                    "                  binop_y_9813 = (int64_t) 1 + Tk_9682;\n                    binop_y_9814 = i_9803 * binop_y_9813;\n                    x_9815 = k_9801 + binop_y_9814;\n                    as_transformed_row_loc_ind_9812 = x_9815;\n                } else {\n                    as_transformed_row_loc_ind_9812 = (int64_t) -1;\n                }\n                if (sle64((int64_t) 0, as_transformed_row_loc_ind_9812) && slt64(as_transformed_row_loc_ind_9812, b_loc_szz_9692)) {\n                    ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9812] = futrts_to_bits16(as_transformed_row_elem_9807);\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        ltid_flat_9854 = sext_i32_i64(local_tid_11198);\n        ltid_y_9853 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n        ltid_x_9852 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n        binop_x_9867 = Ry_9681 * ltid_y_9853;\n        binop_x_9872 = Ry_9681 * ltid_x_9852;\n        for (int64_t i_9857 = 0; i_9857 < Tk_9682; i_9857++) {\n            for (int64_t i_9861 = 0; i_9861 < Ry_9681; i_9861++) {\n                int64_t binop_x_9868;\n                int64_t binop_y_9869;\n                int64_t as_transformed_row_loc_ind_64_9870;\n                f16 as_transformed_row_loc_elem_9871;\n                \n                binop_x_9868 = i_9861 + binop_x_9867;\n                binop_y_9869 = Tk_9682 * binop_x_9868;\n                as_transformed_row_loc_ind_64_9870 = i_9857 + binop_y_9869;\n                if (loop_nonempty_10436) {\n                    f16 x_10437 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_9870]);\n                    \n                    as_transformed_row_loc_elem_9871 = x_10437;\n                } else {\n                    as_transformed_row_loc_elem_9871 = (f16) 0.0F;\n                }\n                for (int64_t i_9864 = 0; i_9864 < Ry_9681; i_9864++) {\n                    int64_t binop_x_9873;\n                    int64_t bin", "op_y_9875;\n                    int64_t as_transformed_row_loc_ind_64_9876;\n                    f16 as_transformed_row_loc_elem_9877;\n                    f16 c_9878;\n                    f16 defunc_0_f_res_9881;\n                    f16 defunc_0_op_res_9884;\n                    \n                    binop_x_9873 = i_9864 + binop_x_9872;\n                    binop_y_9875 = binop_x_9873 * binop_y_9874;\n                    as_transformed_row_loc_ind_64_9876 = i_9857 + binop_y_9875;\n                    as_transformed_row_loc_elem_9877 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_9876]);\n                    c_9878 = mem_param_10515[i_9861 * Ry_9681 + i_9864];\n                    defunc_0_f_res_9881 = as_transformed_row_loc_elem_9871 * as_transformed_row_loc_elem_9877;\n                    defunc_0_op_res_9884 = c_9878 + defunc_0_f_res_9881;\n                    mem_param_10515[i_9861 * Ry_9681 + i_9864] = defunc_0_op_res_9884;\n                }\n            }\n        }\n        for (int64_t i_0 = 0; i_0 < Ry_9681; i_0++) {\n            for (int64_t i_1 = 0; i_1 < Ry_9681; i_1++) {\n                mem_10542[i_0 * Ry_9681 + i_1] = mem_param_10515[i_0 * Ry_9681 + i_1];\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_3 = 0; i_3 < Ry_9681 * Ry_9681; i_3++)\n            mem_param_tmp_11216[i_3] = mem_10542[i_3];\n        for (int32_t i_4 = 0; i_4 < Ry_9681 * Ry_9681; i_4++)\n            mem_param_10515[i_4] = mem_param_tmp_11216[i_4];\n    }\n    for (int32_t i_5 = 0; i_5 < Ry_9681 * Ry_9681; i_5++)\n        ext_mem_10549[i_5] = mem_param_10515[i_5];\n    ltid_flat_9912 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11227 = 0; nest_i_11227 < Ry_9681; nest_i_11227++) {\n        for (int64_t nest_i_11228 = 0; nest_i_11228 < tk_div_tx_9683; nest_i_11228++) {\n            int64_t ltid_seq_9915;\n            int64_t ltid_seq_9916;\n            int64_t ltid_y_9913;\n            int64_t ltid_x_9914;\n            int64_t", " binop_y_9917;\n            int64_t k_9918;\n            int64_t binop_y_9919;\n            int64_t i_9920;\n            int64_t gtid_9921;\n            int64_t as_transformed_row_seqdim_idx_9922;\n            bool binop_x_9923;\n            bool binop_y_9924;\n            bool cond_9925;\n            f16 as_transformed_row_elem_9926;\n            bool cond_9930;\n            int64_t as_transformed_row_loc_ind_9931;\n            \n            ltid_seq_9915 = nest_i_11227;\n            ltid_seq_9916 = nest_i_11228;\n            ltid_y_9913 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9914 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9917 = Ty_9680 * ltid_seq_9916;\n            k_9918 = ltid_x_9914 + binop_y_9917;\n            binop_y_9919 = Ty_9680 * ltid_seq_9915;\n            i_9920 = ltid_y_9913 + binop_y_9919;\n            gtid_9921 = iii_9701 + i_9920;\n            as_transformed_row_seqdim_idx_9922 = kk_9890 + k_9918;\n            binop_x_9923 = slt64(gtid_9921, (int64_t) 64);\n            binop_y_9924 = slt64(as_transformed_row_seqdim_idx_9922, (int64_t) 64);\n            cond_9925 = binop_x_9923 && binop_y_9924;\n            if (cond_9925) {\n                f16 A_elem_9928 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8913 * (int64_t) 4096 + gtid_9921 * (int64_t) 64 + as_transformed_row_seqdim_idx_9922]);\n                \n                as_transformed_row_elem_9926 = A_elem_9928;\n            } else {\n                as_transformed_row_elem_9926 = (f16) 0.0F;\n            }\n            cond_9930 = slt64(k_9918, Tk_9682);\n            if (cond_9930) {\n                int64_t binop_y_9932;\n                int64_t x_9933;\n                \n                binop_y_9932 = Tk_9682 * i_9920;\n                x_9933 = k_9918 + binop_y_9932;\n                as_transformed_row_loc_ind_9931 = x_9933;\n            } else {\n                as_transformed_row_loc_ind_9931 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transf",
                                    "ormed_row_loc_ind_9931) && slt64(as_transformed_row_loc_ind_9931, a_loc_szz_9688)) {\n                ((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_9931] = futrts_to_bits16(as_transformed_row_elem_9926);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_9958 = sext_i32_i64(local_tid_11198);\n    for (int64_t nest_i_11229 = 0; nest_i_11229 < Ry_9681; nest_i_11229++) {\n        for (int64_t nest_i_11230 = 0; nest_i_11230 < tk_div_tx_9683; nest_i_11230++) {\n            int64_t ltid_seq_9961;\n            int64_t ltid_seq_9962;\n            int64_t ltid_y_9959;\n            int64_t ltid_x_9960;\n            int64_t binop_y_9963;\n            int64_t k_9964;\n            int64_t binop_y_9965;\n            int64_t i_9966;\n            int64_t gtid_9967;\n            int64_t as_transformed_row_seqdim_idx_9968;\n            bool binop_x_9969;\n            bool binop_y_9970;\n            bool cond_9971;\n            f16 as_transformed_row_elem_9972;\n            bool cond_9976;\n            int64_t as_transformed_row_loc_ind_9977;\n            \n            ltid_seq_9961 = nest_i_11229;\n            ltid_seq_9962 = nest_i_11230;\n            ltid_y_9959 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n            ltid_x_9960 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n            binop_y_9963 = Ty_9680 * ltid_seq_9962;\n            k_9964 = ltid_x_9960 + binop_y_9963;\n            binop_y_9965 = Ty_9680 * ltid_seq_9961;\n            i_9966 = ltid_y_9959 + binop_y_9965;\n            gtid_9967 = jjj_9702 + i_9966;\n            as_transformed_row_seqdim_idx_9968 = kk_9890 + k_9964;\n            binop_x_9969 = slt64(gtid_9967, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n            binop_y_9970 = slt64(as_transformed_row_seqdim_idx_9968, (int64_t) 64);\n            cond_9971 = binop_x_9969 && binop_y_9970;\n            if (cond_9971) {\n                f16 A_elem_9974 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_9967 * (int64_t) 64 + as_transformed_row_seq", "dim_idx_9968]);\n                \n                as_transformed_row_elem_9972 = A_elem_9974;\n            } else {\n                as_transformed_row_elem_9972 = (f16) 0.0F;\n            }\n            cond_9976 = slt64(k_9964, Tk_9682);\n            if (cond_9976) {\n                int64_t binop_y_9978;\n                int64_t binop_y_9979;\n                int64_t x_9980;\n                \n                binop_y_9978 = (int64_t) 1 + Tk_9682;\n                binop_y_9979 = i_9966 * binop_y_9978;\n                x_9980 = k_9964 + binop_y_9979;\n                as_transformed_row_loc_ind_9977 = x_9980;\n            } else {\n                as_transformed_row_loc_ind_9977 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, as_transformed_row_loc_ind_9977) && slt64(as_transformed_row_loc_ind_9977, b_loc_szz_9692)) {\n                ((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_9977] = futrts_to_bits16(as_transformed_row_elem_9972);\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ltid_flat_10021 = sext_i32_i64(local_tid_11198);\n    ltid_y_10020 = sext_i32_i64(sext_i64_i32(ltid_pre_11202));\n    ltid_x_10019 = sext_i32_i64(sext_i64_i32(ltid_pre_11203));\n    binop_x_10036 = Ry_9681 * ltid_y_10020;\n    binop_x_10041 = Ry_9681 * ltid_x_10019;\n    for (int64_t i_10024 = 0; i_10024 < Tk_9682; i_10024++) {\n        int64_t cmpop_x_10026;\n        bool cond_10027;\n        \n        cmpop_x_10026 = kk_9890 + i_10024;\n        cond_10027 = slt64(cmpop_x_10026, (int64_t) 64);\n        if (cond_10027) {\n            for (int64_t i_10030 = 0; i_10030 < Ry_9681; i_10030++) {\n                int64_t binop_x_10037;\n                int64_t binop_y_10038;\n                int64_t as_transformed_row_loc_ind_64_10039;\n                f16 as_transformed_row_loc_elem_10040;\n                \n                binop_x_10037 = i_10030 + binop_x_10036;\n                binop_y_10038 = Tk_9682 * binop_x_10037;\n                as_transformed_row_loc_ind_64_10039 = i_", "10024 + binop_y_10038;\n                if (loop_nonempty_10436) {\n                    f16 x_10434 = futrts_from_bits16(((__local uint16_t *) color_10863)[as_transformed_row_loc_ind_64_10039]);\n                    \n                    as_transformed_row_loc_elem_10040 = x_10434;\n                } else {\n                    as_transformed_row_loc_elem_10040 = (f16) 0.0F;\n                }\n                for (int64_t i_10033 = 0; i_10033 < Ry_9681; i_10033++) {\n                    int64_t binop_x_10042;\n                    int64_t binop_y_10044;\n                    int64_t as_transformed_row_loc_ind_64_10045;\n                    f16 as_transformed_row_loc_elem_10046;\n                    f16 c_10047;\n                    f16 defunc_0_f_res_10050;\n                    f16 defunc_0_op_res_10053;\n                    \n                    binop_x_10042 = i_10033 + binop_x_10041;\n                    binop_y_10044 = binop_y_9874 * binop_x_10042;\n                    as_transformed_row_loc_ind_64_10045 = i_10024 + binop_y_10044;\n                    as_transformed_row_loc_elem_10046 = futrts_from_bits16(((__local uint16_t *) color_10862)[as_transformed_row_loc_ind_64_10045]);\n                    c_10047 = ext_mem_10549[i_10030 * Ry_9681 + i_10033];\n                    defunc_0_f_res_10050 = as_transformed_row_loc_elem_10040 * as_transformed_row_loc_elem_10046;\n                    defunc_0_op_res_10053 = c_10047 + defunc_0_f_res_10050;\n                    ext_mem_10549[i_10030 * Ry_9681 + i_10033] = defunc_0_op_res_10053;\n                }\n            }\n        }\n    }\n    for (int64_t i_0 = 0; i_0 < Ry_9681; i_0++) {\n        for (int64_t i_1 = 0; i_1 < Ry_9681; i_1++) {\n            mem_10571[i_0 * Ry_9681 + i_1] = ext_mem_10549[i_0 * Ry_9681 + i_1];\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    slice_11237 = Ty_9680;\n    slice_11238 = Ty_9680 * slice_11237;\n    slice_11239 = slice_11238;\n    reg_tile_i_11234 = squot64(sext_i32_i64(local_tid_11198), slice_11238);\n    remnan",
                                    "t_11240 = sext_i32_i64(local_tid_11198) - reg_tile_i_11234 * slice_11238;\n    reg_tile_i_11235 = squot64(remnant_11240, slice_11237);\n    remnant_11241 = remnant_11240 - reg_tile_i_11235 * slice_11237;\n    reg_tile_i_11236 = remnant_11241;\n    remnant_11242 = remnant_11241 - reg_tile_i_11236;\n    tile_dim_start_11243 = gtid_8913 + reg_tile_i_11234;\n    tile_dim_start_11244 = Ry_9681 * (Ty_9680 * gid_y_9698 + reg_tile_i_11235);\n    tile_dim_start_11245 = Ry_9681 * (Ty_9680 * gid_x_9699 + reg_tile_i_11236);\n    for (int64_t nest_i_11246 = 0; nest_i_11246 < (int64_t) 1; nest_i_11246++) {\n        for (int64_t nest_i_11247 = 0; nest_i_11247 < Ry_9681; nest_i_11247++) {\n            for (int64_t nest_i_11248 = 0; nest_i_11248 < Ry_9681; nest_i_11248++) {\n                if ((slt64(tile_dim_start_11243 + nest_i_11246, m_6626) && slt64(tile_dim_start_11244 + nest_i_11247, (int64_t) 64)) && slt64(tile_dim_start_11245 + nest_i_11248, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) {\n                    f16 tmp_11249 = mem_10571[nest_i_11247 * Ry_9681 + nest_i_11248];\n                    \n                    ((__global uint16_t *) mem_10575)[(tile_dim_start_11243 + nest_i_11246) * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + (tile_dim_start_11244 + nest_i_11247) * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + (tile_dim_start_11245 + nest_i_11248)] = futrts_to_bits16(tmp_11249);\n                }\n            }\n        }\n    }\n    \n  error_8:\n    return;\n    #undef Ty_9680\n    #undef Ry_9681\n    #undef Tk_9682\n    #undef tk_div_tx_9683\n    #undef TxRx_9685\n    #undef a_loc_szz_9688\n    #undef b_loc_szz_9692\n    #undef gridDim_y_9694\n    #undef full_tiles_9728\n    #undef binop_y_9874\n    #undef kk_9890\n    #undef loop_nonempty_10436\n    #undef bytes_10511\n    #undef bytes_10513\n}\nFUTHARK_KERNEL_SIZED(run64zisegred_large_8938_dim1, 1, 1)\nvoid run64zisegred_large_8938(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t num_tblocks_8931, int64_t", " blocks_per_segment_11283, int64_t q_11284, int64_t num_virtblocks_11285, int64_t threads_per_segment_11286, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479, __global unsigned char *segred_tmp_mem_11287, __global unsigned char *counters_mem_11289)\n{\n    #define segred_tblock_sizze_8930 (run64zisegred_large_8938zisegred_tblock_sizze_8930)\n    #define chunk_sizze_11250 (run64zisegred_large_8938zichunk_sizze_11250)\n    \n    volatile __local unsigned char *sync_arr_mem_11318_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11318_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11316_backing_0 = &shared_mem[sync_arr_mem_11318_backing_1_offset];\n    const int64_t red_arr_f16_mem_11316_backing_0_offset = sync_arr_mem_11318_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_8930 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8930, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11312;\n    int32_t tblock_sizze_11315;\n    int32_t wave_sizze_11314;\n    int32_t block_id_11313;\n    int32_t global_tid_11311;\n    int64_t phys_tid_8938;\n    __local unsigned char *red_arr_f16_mem_11316;\n    __local unsigned char *sync_arr_mem_11318;\n    int32_t phys_tblock_id_11320;\n    int32_t iterations_11321;\n    \n    local_tid_11312 = get_local_id(0);\n    tblock_sizze_11315 = get_local_size(0);\n    wave_sizze_11314 = LOCKSTEP_WIDTH;\n    block_id_11313 = get_tblock_id(0);\n    global_tid_11311 = block_id_11313 * tblock_sizze_11315 + local_tid_11312;\n    phys_tid_8938 = sext_i32_i64(global_tid_11311);\n    red_arr_f16_mem_11316 = (__local unsigned char *) red_arr_f16_mem_11316_backing_0;\n    sync_arr_mem_11318 = (__local unsigned char *) sync_arr_mem_11318_backing_1;\n    phys_tblock_id_11320 = get_tblock_id(0);\n    iterations_11321 = sdiv_up32(sext_i64_i32(num_virtblocks_11285) - phys_tblock_id_11320, sext_i64_i32(num_tblock", "s_8931));\n    for (int32_t i_11322 = 0; i_11322 < iterations_11321; i_11322++) {\n        int32_t virt_tblock_id_11323;\n        int64_t flat_segment_id_11324;\n        int64_t global_tid_11325;\n        int64_t slice_11326;\n        int64_t slice_11327;\n        int64_t slice_11328;\n        int64_t gtid_8934;\n        int64_t remnant_11329;\n        int64_t gtid_8935;\n        int64_t remnant_11330;\n        int64_t gtid_8936;\n        int64_t remnant_11331;\n        int64_t gtid_8937;\n        f16 eta_p_block_res_acc_11332;\n        f16 eta_p_8939;\n        f16 eta_p_8940;\n        int64_t tblock_id_in_segment_11336;\n        int64_t block_base_offset_11337;\n        int32_t offset_11340;\n        int32_t skip_waves_11341;\n        f16 eta_p_11333;\n        f16 eta_p_11334;\n        \n        virt_tblock_id_11323 = phys_tblock_id_11320 + i_11322 * sext_i64_i32(num_tblocks_8931);\n        flat_segment_id_11324 = squot64(sext_i32_i64(virt_tblock_id_11323), blocks_per_segment_11283);\n        global_tid_11325 = srem64(sext_i32_i64(virt_tblock_id_11323) * segred_tblock_sizze_8930 + sext_i32_i64(local_tid_11312), threads_per_segment_11286);\n        slice_11326 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;\n        slice_11327 = (int64_t) 64 * slice_11326;\n        slice_11328 = m_6626 * slice_11327;\n        gtid_8934 = squot64(flat_segment_id_11324, slice_11327);\n        remnant_11329 = flat_segment_id_11324 - gtid_8934 * slice_11327;\n        gtid_8935 = squot64(remnant_11329, slice_11326);\n        remnant_11330 = remnant_11329 - gtid_8935 * slice_11326;\n        gtid_8936 = remnant_11330;\n        remnant_11331 = remnant_11330 - gtid_8936;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11332 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11336 = squot64(global_tid_11325, segred_tblock_sizze_8930);\n        block_base_offset_11337 = tblock_id_in_segment_11336 * q_11284 * segred_tblock_sizze_8930;\n        for (int64_t i_11338 = 0; i_11338 < q_1",
                                    "1284; i_11338++) {\n            int64_t block_offset_11339 = block_base_offset_11337 + i_11338 * segred_tblock_sizze_8930;\n            \n            gtid_8937 = global_tid_11325 + threads_per_segment_11286 * i_11338;\n            if (slt64(gtid_8937, (int64_t) 64)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_8945 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8934 * (int64_t) 4096 + gtid_8935 * (int64_t) 64 + gtid_8937]);\n                        f16 eta_p_8946 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8936 * (int64_t) 64 + gtid_8937]);\n                        f16 defunc_0_f_res_8947 = eta_p_8945 * eta_p_8946;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_8939 = eta_p_block_res_acc_11332;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_8940 = defunc_0_f_res_8947;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_8941 = eta_p_8939 + eta_p_8940;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11332 = defunc_0_op_res_8941;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11341 = 1;\n        offset_11340 = 0;\n        // participating threads read initi", "al accumulator\n        {\n            if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_8930))) {\n                eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n            }\n        }\n        offset_11340 = 1;\n        while (slt32(offset_11340, wave_sizze_11314)) {\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_8930)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11340 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            offset_11340 *= 2;\n        }\n        while (slt32(skip_waves_11341, squot32(sext_i64_i32(segred_tblock_sizze_8930) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11340 = skip_waves_11341 * wave_sizze_11314;\n            if (slt32(local_tid_11312 + offset_11340, sext_i64_i32(segred_tblock_sizze_8930)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11341 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + ", "offset_11340)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                    \n                    eta_p_11333 = defunc_0_op_res_11335;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                }\n            }\n            skip_waves_11341 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11312) == (int64_t) 0) {\n                eta_p_block_res_acc_11332 = eta_p_11333;\n            } else {\n                eta_p_block_res_acc_11332 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11283 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) mem_10479)[gtid_8934 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + gtid_8935 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8936] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                }\n            }\n        } else {\n            int32_t old_counter_11342;\n            bool is_last_block_11343;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11312 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11287)[sext_i32_i64(virt_tblock_id_11323)] = futrts_to_bits16(eta_p_block_res_acc_11332);\n                    mem_fence_global();\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11318",
                                    ")[(int64_t) 0] = old_counter_11342 == sext_i64_i32(blocks_per_segment_11283 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11343 = ((__local bool *) sync_arr_mem_11318)[(int64_t) 0];\n            if (is_last_block_11343) {\n                if (local_tid_11312 == 0) {\n                    old_counter_11342 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11289)[srem64(flat_segment_id_11324, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11283));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11344 = sdiv_up64(blocks_per_segment_11283, segred_tblock_sizze_8930);\n                    \n                    eta_p_8939 = (f16) 0.0F;\n                    for (int64_t i_11345 = 0; i_11345 < read_per_thread_11344; i_11345++) {\n                        int64_t block_res_id_11346 = sext_i32_i64(local_tid_11312) * read_per_thread_11344 + i_11345;\n                        int64_t index_of_block_res_11347 = flat_segment_id_11324 * blocks_per_segment_11283 + block_res_id_11346;\n                        \n                        if (slt64(block_res_id_11346, blocks_per_segment_11283)) {\n                            eta_p_8940 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11287)[index_of_block_res_11347]);\n                            \n                            f16 defunc_0_op_res_8941 = eta_p_8939 + eta_p_8940;\n                            \n                            eta_p_8939 = defunc_0_op_res_8941;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_8939);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11348;\n                    int32_t sk", "ip_waves_11349 = 1;\n                    f16 eta_p_11333;\n                    f16 eta_p_11334;\n                    \n                    offset_11348 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11312, sext_i64_i32(segred_tblock_sizze_8930))) {\n                            eta_p_11333 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                        }\n                    }\n                    offset_11348 = 1;\n                    while (slt32(offset_11348, wave_sizze_11314)) {\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_8930)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) & (2 * offset_11348 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        offset_11348 *= 2;\n                    }\n                    while (slt32(skip_waves_11349, squot32(sext_i64_i32(segred_tblock_sizze_8930) + wave_sizze_11314 - 1, wave_sizze_11314))) {\n                        barrier(CLK_LOCAL_", "MEM_FENCE);\n                        offset_11348 = skip_waves_11349 * wave_sizze_11314;\n                        if (slt32(local_tid_11312 + offset_11348, sext_i64_i32(segred_tblock_sizze_8930)) && ((local_tid_11312 - squot32(local_tid_11312, wave_sizze_11314) * wave_sizze_11314) == 0 && (squot32(local_tid_11312, wave_sizze_11314) & (2 * skip_waves_11349 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11334 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312 + offset_11348)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11335 = eta_p_11333 + eta_p_11334;\n                                \n                                eta_p_11333 = defunc_0_op_res_11335;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11316)[sext_i32_i64(local_tid_11312)] = futrts_to_bits16(eta_p_11333);\n                            }\n                        }\n                        skip_waves_11349 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11312 == 0) {\n                            ((__global uint16_t *) mem_10479)[gtid_8934 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + gtid_8935 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8936] = futrts_to_bits16(eta_p_11333);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_8930\n    #undef chunk_sizze_11250\n}\nFUTHARK_KERNEL_SIZED(run64zisegred_larg",
                                    "e_8985_dim1, 1, 1)\nvoid run64zisegred_large_8985(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t one_intra_par_min_8836, int64_t num_tblocks_8978, int64_t blocks_per_segment_11439, int64_t q_11440, int64_t num_virtblocks_11441, int64_t threads_per_segment_11442, __global unsigned char *ext_mem_10579, __global unsigned char *mem_10589, __global unsigned char *mem_10594, __global unsigned char *segred_tmp_mem_11443, __global unsigned char *counters_mem_11445)\n{\n    #define segred_tblock_sizze_8977 (run64zisegred_large_8985zisegred_tblock_sizze_8977)\n    #define chunk_sizze_11406 (run64zisegred_large_8985zichunk_sizze_11406)\n    \n    volatile __local unsigned char *sync_arr_mem_11454_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_11454_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_f16_mem_11452_backing_0 = &shared_mem[sync_arr_mem_11454_backing_1_offset];\n    const int64_t red_arr_f16_mem_11452_backing_0_offset = sync_arr_mem_11454_backing_1_offset + ((int64_t) 2 * segred_tblock_sizze_8977 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8977, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11448;\n    int32_t tblock_sizze_11451;\n    int32_t wave_sizze_11450;\n    int32_t block_id_11449;\n    int32_t global_tid_11447;\n    int64_t phys_tid_8985;\n    __local unsigned char *red_arr_f16_mem_11452;\n    __local unsigned char *sync_arr_mem_11454;\n    int32_t phys_tblock_id_11456;\n    int32_t iterations_11457;\n    \n    local_tid_11448 = get_local_id(0);\n    tblock_sizze_11451 = get_local_size(0);\n    wave_sizze_11450 = LOCKSTEP_WIDTH;\n    block_id_11449 = get_tblock_id(0);\n    global_tid_11447 = block_id_11449 * tblock_sizze_11451 + local_tid_11448;\n    phys_tid_8985 = sext_i32_i64(global_tid_11447);\n    red_arr_f16_mem_11452 = (__local unsigned char *) red_arr_f16_mem_11452_backing_0;\n    sync_arr_mem_11454 = (__local un", "signed char *) sync_arr_mem_11454_backing_1;\n    phys_tblock_id_11456 = get_tblock_id(0);\n    iterations_11457 = sdiv_up32(sext_i64_i32(num_virtblocks_11441) - phys_tblock_id_11456, sext_i64_i32(num_tblocks_8978));\n    for (int32_t i_11458 = 0; i_11458 < iterations_11457; i_11458++) {\n        int32_t virt_tblock_id_11459;\n        int64_t flat_segment_id_11460;\n        int64_t global_tid_11461;\n        int64_t slice_11462;\n        int64_t slice_11463;\n        int64_t slice_11464;\n        int64_t gtid_8981;\n        int64_t remnant_11465;\n        int64_t gtid_8982;\n        int64_t remnant_11466;\n        int64_t gtid_8983;\n        int64_t remnant_11467;\n        int64_t gtid_8984;\n        f16 eta_p_block_res_acc_11468;\n        f16 eta_p_8986;\n        f16 eta_p_8987;\n        int64_t tblock_id_in_segment_11472;\n        int64_t block_base_offset_11473;\n        int32_t offset_11476;\n        int32_t skip_waves_11477;\n        f16 eta_p_11469;\n        f16 eta_p_11470;\n        \n        virt_tblock_id_11459 = phys_tblock_id_11456 + i_11458 * sext_i64_i32(num_tblocks_8978);\n        flat_segment_id_11460 = squot64(sext_i32_i64(virt_tblock_id_11459), blocks_per_segment_11439);\n        global_tid_11461 = srem64(sext_i32_i64(virt_tblock_id_11459) * segred_tblock_sizze_8977 + sext_i32_i64(local_tid_11448), threads_per_segment_11442);\n        slice_11462 = (int64_t) 64;\n        slice_11463 = (int64_t) 64 * slice_11462;\n        slice_11464 = m_6626 * slice_11463;\n        gtid_8981 = squot64(flat_segment_id_11460, slice_11463);\n        remnant_11465 = flat_segment_id_11460 - gtid_8981 * slice_11463;\n        gtid_8982 = squot64(remnant_11465, slice_11462);\n        remnant_11466 = remnant_11465 - gtid_8982 * slice_11462;\n        gtid_8983 = remnant_11466;\n        remnant_11467 = remnant_11466 - gtid_8983;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_11468 = (f16) 0.0F;\n        }\n        tblock_id_in_segment_11472 = squot64(global_ti", "d_11461, segred_tblock_sizze_8977);\n        block_base_offset_11473 = tblock_id_in_segment_11472 * q_11440 * segred_tblock_sizze_8977;\n        for (int64_t i_11474 = 0; i_11474 < q_11440; i_11474++) {\n            int64_t block_offset_11475 = block_base_offset_11473 + i_11474 * segred_tblock_sizze_8977;\n            \n            gtid_8984 = global_tid_11461 + threads_per_segment_11442 * i_11474;\n            if (slt64(gtid_8984, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) {\n                // apply map function(s)\n                {\n                    // apply map function\n                    {\n                        f16 eta_p_8992 = futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_8981 * one_intra_par_min_8836 + gtid_8982 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8984]);\n                        f16 eta_p_8993 = futrts_from_bits16(((__global uint16_t *) mem_10589)[gtid_8984 + gtid_8983 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627]);\n                        f16 defunc_0_f_res_8994 = eta_p_8992 * eta_p_8993;\n                        \n                        // load accumulator(s)\n                        {\n                            eta_p_8986 = eta_p_block_res_acc_11468;\n                        }\n                        // load next value(s)\n                        {\n                            eta_p_8987 = defunc_0_f_res_8994;\n                        }\n                        // apply reduction operator(s)\n                        {\n                            f16 defunc_0_op_res_8988 = eta_p_8986 + eta_p_8987;\n                            \n                            // store in accumulator(s)\n                            {\n                                eta_p_block_res_acc_11468 = defunc_0_op_res_8988;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local u",
                                    "int16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_11477 = 1;\n        offset_11476 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_8977))) {\n                eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n            }\n        }\n        offset_11476 = 1;\n        while (slt32(offset_11476, wave_sizze_11450)) {\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_8977)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11476 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            offset_11476 *= 2;\n        }\n        while (slt32(skip_waves_11477, squot32(sext_i64_i32(segred_tblock_sizze_8977) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_11476 = skip_waves_11477 * wave_sizze_11450;\n            if (slt32(local_tid_11448 + offset_11476, sext_i64_i32(segred_tblock_sizze_8977)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(", "local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11477 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11476)]);\n                }\n                // apply reduction operation\n                {\n                    f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                    \n                    eta_p_11469 = defunc_0_op_res_11471;\n                }\n                // write result of operation\n                {\n                    ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                }\n            }\n            skip_waves_11477 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_11448) == (int64_t) 0) {\n                eta_p_block_res_acc_11468 = eta_p_11469;\n            } else {\n                eta_p_block_res_acc_11468 = (f16) 0.0F;\n            }\n        }\n        if (blocks_per_segment_11439 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) mem_10594)[gtid_8981 * (int64_t) 4096 + gtid_8982 * (int64_t) 64 + gtid_8983] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                }\n            }\n        } else {\n            int32_t old_counter_11478;\n            bool is_last_block_11479;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_11448 == 0) {\n                    ((__global uint16_t *) segred_tmp_mem_11443)[sext_i32_i64(virt_tblock_id_11459)] = futrts_to_bits16(eta_p_block_res_acc_11468);\n                    mem_fence_global();\n                    old_cou", "nter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_11454)[(int64_t) 0] = old_counter_11478 == sext_i64_i32(blocks_per_segment_11439 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_11479 = ((__local bool *) sync_arr_mem_11454)[(int64_t) 0];\n            if (is_last_block_11479) {\n                if (local_tid_11448 == 0) {\n                    old_counter_11478 = atomic_add_i32_global(&((volatile __global int *) counters_mem_11445)[srem64(flat_segment_id_11460, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_11439));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_11480 = sdiv_up64(blocks_per_segment_11439, segred_tblock_sizze_8977);\n                    \n                    eta_p_8986 = (f16) 0.0F;\n                    for (int64_t i_11481 = 0; i_11481 < read_per_thread_11480; i_11481++) {\n                        int64_t block_res_id_11482 = sext_i32_i64(local_tid_11448) * read_per_thread_11480 + i_11481;\n                        int64_t index_of_block_res_11483 = flat_segment_id_11460 * blocks_per_segment_11439 + block_res_id_11482;\n                        \n                        if (slt64(block_res_id_11482, blocks_per_segment_11439)) {\n                            eta_p_8987 = futrts_from_bits16(((__global uint16_t *) segred_tmp_mem_11443)[index_of_block_res_11483]);\n                            \n                            f16 defunc_0_op_res_8988 = eta_p_8986 + eta_p_8987;\n                            \n                            eta_p_8986 = defunc_0_op_res_8988;\n                        }\n                    }\n                }\n                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16",
                                    "(eta_p_8986);\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_11484;\n                    int32_t skip_waves_11485 = 1;\n                    f16 eta_p_11469;\n                    f16 eta_p_11470;\n                    \n                    offset_11484 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_11448, sext_i64_i32(segred_tblock_sizze_8977))) {\n                            eta_p_11469 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                        }\n                    }\n                    offset_11484 = 1;\n                    while (slt32(offset_11484, wave_sizze_11450)) {\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_8977)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) & (2 * offset_11484 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        offset_11484 *= 2;\n          ", "          }\n                    while (slt32(skip_waves_11485, squot32(sext_i64_i32(segred_tblock_sizze_8977) + wave_sizze_11450 - 1, wave_sizze_11450))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_11484 = skip_waves_11485 * wave_sizze_11450;\n                        if (slt32(local_tid_11448 + offset_11484, sext_i64_i32(segred_tblock_sizze_8977)) && ((local_tid_11448 - squot32(local_tid_11448, wave_sizze_11450) * wave_sizze_11450) == 0 && (squot32(local_tid_11448, wave_sizze_11450) & (2 * skip_waves_11485 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_11470 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448 + offset_11484)]);\n                            }\n                            // apply reduction operation\n                            {\n                                f16 defunc_0_op_res_11471 = eta_p_11469 + eta_p_11470;\n                                \n                                eta_p_11469 = defunc_0_op_res_11471;\n                            }\n                            // write result of operation\n                            {\n                                ((__local uint16_t *) red_arr_f16_mem_11452)[sext_i32_i64(local_tid_11448)] = futrts_to_bits16(eta_p_11469);\n                            }\n                        }\n                        skip_waves_11485 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_11448 == 0) {\n                            ((__global uint16_t *) mem_10594)[gtid_8981 * (int64_t) 4096 + gtid_8982 * (int64_t) 64 + gtid_8983] = futrts_to_bits16(eta_p_11469);\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n   ", " }\n    \n  error_6:\n    return;\n    #undef segred_tblock_sizze_8977\n    #undef chunk_sizze_11406\n}\nFUTHARK_KERNEL_SIZED(run64zisegred_small_8938_dim1, 1, 1)\nvoid run64zisegred_small_8938(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t num_tblocks_8931, int64_t segment_sizze_nonzzero_11251, __global unsigned char *Q_mem_10472, __global unsigned char *K_mem_10473, __global unsigned char *mem_10479)\n{\n    #define segred_tblock_sizze_8930 (run64zisegred_small_8938zisegred_tblock_sizze_8930)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11258_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11258_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_8930 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8930, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11254;\n    int32_t tblock_sizze_11257;\n    int32_t wave_sizze_11256;\n    int32_t block_id_11255;\n    int32_t global_tid_11253;\n    int64_t phys_tid_8938;\n    __local unsigned char *red_arr_f16_mem_11258;\n    int32_t phys_tblock_id_11260;\n    int32_t iterations_11261;\n    \n    local_tid_11254 = get_local_id(0);\n    tblock_sizze_11257 = get_local_size(0);\n    wave_sizze_11256 = LOCKSTEP_WIDTH;\n    block_id_11255 = get_tblock_id(0);\n    global_tid_11253 = block_id_11255 * tblock_sizze_11257 + local_tid_11254;\n    phys_tid_8938 = sext_i32_i64(global_tid_11253);\n    red_arr_f16_mem_11258 = (__local unsigned char *) red_arr_f16_mem_11258_backing_0;\n    phys_tblock_id_11260 = get_tblock_id(0);\n    iterations_11261 = sdiv_up32(sext_i64_i32(sdiv_up64(m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251))) - phys_tblock_id_11260, sext_i64_i32(num_tblocks_8931));\n    for (int32_t i_11262 = 0; i_11262 < iterations_11261; i_11262++) {\n        int32_t virt_tblock_id_11263;\n        int64_t slice_11264;\n        int64",
                                    "_t slice_11265;\n        int64_t slice_11266;\n        int64_t gtid_8934;\n        int64_t remnant_11267;\n        int64_t gtid_8935;\n        int64_t remnant_11268;\n        int64_t gtid_8936;\n        int64_t remnant_11269;\n        int64_t gtid_8937;\n        \n        virt_tblock_id_11263 = phys_tblock_id_11260 + i_11262 * sext_i64_i32(num_tblocks_8931);\n        slice_11264 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;\n        slice_11265 = (int64_t) 64 * slice_11264;\n        slice_11266 = m_6626 * slice_11265;\n        gtid_8934 = squot64(squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251), slice_11265);\n        remnant_11267 = squot64(sext_i32_i64(local_tid_11254), segment_sizze_nonzzero_11251) + sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) - gtid_8934 * slice_11265;\n        gtid_8935 = squot64(remnant_11267, slice_11264);\n        remnant_11268 = remnant_11267 - gtid_8935 * slice_11264;\n        gtid_8936 = remnant_11268;\n        remnant_11269 = remnant_11268 - gtid_8936;\n        gtid_8937 = srem64(sext_i32_i64(local_tid_11254), (int64_t) 64);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, (int64_t) 64) && (((slt64(gtid_8934, m_6626) && slt64(gtid_8935, (int64_t) 64)) && slt64(gtid_8936, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) && slt64(sext_i32_i64(local_tid_11254), (int64_t) 64 * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251)))) {\n                // apply map function\n                {\n                    f16 eta_p_8945 = futrts_from_bits16(((__global uint16_t *) Q_mem_10472)[gtid_8934 * (int64_t) 4096 + gtid_8935 * (int64_t) 64 + gtid_8937]);\n                    f16 eta_p_8946 = futrts_from_bits16(((__global uint16_t *) K_mem_10473)[gtid_8936 * (int64_t) 64 + gtid_8937]);\n                    f16 defunc_0_f_res_8947 = eta_p_8945 * eta_p_8946;\n       ", "             \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(defunc_0_f_res_8947);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, (int64_t) 64)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_8939;\n                f16 eta_p_8940;\n                f16 eta_p_11270;\n                f16 eta_p_11271;\n                bool ltid_in_bounds_11273 = slt64(sext_i32_i64(local_tid_11254), (int64_t) 64 * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251));\n                int32_t skip_threads_11274;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11273) {\n                        eta_p_8940 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                        if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                            eta_p_8939 = eta_p_8940;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11274 = 1;\n                    while (slt32(skip_threads_11274, 32)) {\n                        bool thread_active_11275 = sle32(skip_threads_11274, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && ltid_in_bounds_11273;\n                        \n                        if (thread_active_11275) {\n                            // read operands\n                            {\n                                eta_p_8939 = futrts_from_bits16(((volatile __local uint16_t *)", " red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11274)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11276 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 64), sext_i32_i64(local_tid_11254) - sext_i32_i64(local_tid_11254 - skip_threads_11274));\n                            \n                            if (thread_active_11275 && inactive_11276) {\n                                eta_p_8939 = eta_p_8940;\n                            }\n                            if (thread_active_11275) {\n                                if (!inactive_11276) {\n                                    f16 defunc_0_op_res_8941 = eta_p_8939 + eta_p_8940;\n                                    \n                                    eta_p_8939 = defunc_0_op_res_8941;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11275) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_8939);\n                                eta_p_8940 = eta_p_8939;\n                            }\n                        }\n                        if (sle32(wave_sizze_11256, skip_threads_11274)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11274 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_11254 - squot32(local_tid_11254, ",
                                    "32) * 32) == 31 && ltid_in_bounds_11273) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32))] = futrts_to_bits16(eta_p_8939);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11277;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                            eta_p_11271 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)]);\n                            if ((local_tid_11254 - squot32(local_tid_11254, 32) * 32) == 0) {\n                                eta_p_11270 = eta_p_11271;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11277 = 1;\n                        while (slt32(skip_threads_11277, 32)) {\n                            bool thread_active_11278 = sle32(skip_threads_11277, local_tid_11254 - squot32(local_tid_11254, 32) * 32) && (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273);\n                            \n                            if (thread_active_11278) {\n                                // read operands\n                                {\n                                    eta_p_11270 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254) - sext_i32_i64(skip_threads_11277)]);\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_11279 = slt64(srem64(sext_i32_i64(local_tid", "_11254 * 32 + 32 - 1), (int64_t) 64), sext_i32_i64(local_tid_11254 * 32 + 32 - 1) - sext_i32_i64((local_tid_11254 - skip_threads_11277) * 32 + 32 - 1));\n                                \n                                if (thread_active_11278 && inactive_11279) {\n                                    eta_p_11270 = eta_p_11271;\n                                }\n                                if (thread_active_11278) {\n                                    if (!inactive_11279) {\n                                        f16 defunc_0_op_res_11272 = eta_p_11270 + eta_p_11271;\n                                        \n                                        eta_p_11270 = defunc_0_op_res_11272;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11278) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_11270);\n                                    eta_p_11271 = eta_p_11270;\n                                }\n                            }\n                            if (sle32(wave_sizze_11256, skip_threads_11277)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_11277 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11280 = squot32(local_tid_11254, 32) == 0 || !ltid_in_bounds_11273;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n         ", "               if (!no_carry_in_11280) {\n                            eta_p_8940 = eta_p_8939;\n                            eta_p_8939 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(squot32(local_tid_11254, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_11281 = slt64(srem64(sext_i32_i64(local_tid_11254), (int64_t) 64), sext_i32_i64(local_tid_11254) - sext_i32_i64(squot32(local_tid_11254, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11280) {\n                            if (inactive_11281) {\n                                eta_p_8939 = eta_p_8940;\n                            }\n                        }\n                        if (!no_carry_in_11280) {\n                            if (!inactive_11281) {\n                                f16 defunc_0_op_res_8941 = eta_p_8939 + eta_p_8940;\n                                \n                                eta_p_8939 = defunc_0_op_res_8941;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11280) {\n                            ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_8939);\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11254, 32) == 0 && ltid_in_bounds_11273) {\n                        ((__local uint16_t *) red_arr_f16_mem_11258)[sext_i32_i64(local_tid_11254)] = futrts_to_bits16(eta_p_8940);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of seg",
                                    "ments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) && slt64(sext_i32_i64(local_tid_11254), squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251))) {\n                f16 tmp_11282 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11258)[(sext_i32_i64(local_tid_11254) + (int64_t) 1) * segment_sizze_nonzzero_11251 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10479)[squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + (sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254) - squot64(sext_i32_i64(virt_tblock_id_11263) * squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251) + sext_i32_i64(local_tid_11254), (int64_t)", " 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)] = futrts_to_bits16(tmp_11282);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_8930\n}\nFUTHARK_KERNEL_SIZED(run64zisegred_small_8985_dim1, 1, 1)\nvoid run64zisegred_small_8985(__global int *global_failure, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, int64_t one_intra_par_min_8836, int64_t num_tblocks_8978, int64_t segment_sizze_nonzzero_11407, __global unsigned char *ext_mem_10579, __global unsigned char *mem_10589, __global unsigned char *mem_10594)\n{\n    #define segred_tblock_sizze_8977 (run64zisegred_small_8985zisegred_tblock_sizze_8977)\n    \n    volatile __local unsigned char *red_arr_f16_mem_11414_backing_0 = &shared_mem[0];\n    const int64_t red_arr_f16_mem_11414_backing_0_offset = 0 + ((int64_t) 2 * segred_tblock_sizze_8977 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8977, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_11410;\n    int32_t tblock_sizze_11413;\n    int32_t wave_sizze_11412;\n    int32_t block_id_11411;\n    int32_t global_tid_11409;\n    int64_t phys_tid_8985;\n    __local unsigned char *red_arr_f16_mem_11414;\n    int32_t phys_tblock_id_11416;\n    int32_t iterations_11417;\n    \n    local_tid_11410 = get_local_id(0);\n    tblock_sizze_11413 = get_local_size(0);\n    wave_sizze_11412 = LOCKSTEP_WIDTH;\n    block_id_11411 = get_tblock_id(0);\n    global_tid_11409 = block_id_11411 * tblock_sizze_11413 + local_tid_11410;\n    phys_tid_8985 = sext_i32_i64(global_tid_11409);\n    red_arr_f16_mem_11414 = (__local unsigned char *) red_arr_f16_mem_11414_backing_0;\n    phys_tblock_id_11416 = get_tblock_id(0);\n    iterations_11417 = sdiv_up32(sext_i64_i32(sdiv_up64", "(m_6626 * (int64_t) 64 * (int64_t) 64, squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407))) - phys_tblock_id_11416, sext_i64_i32(num_tblocks_8978));\n    for (int32_t i_11418 = 0; i_11418 < iterations_11417; i_11418++) {\n        int32_t virt_tblock_id_11419;\n        int64_t slice_11420;\n        int64_t slice_11421;\n        int64_t slice_11422;\n        int64_t gtid_8981;\n        int64_t remnant_11423;\n        int64_t gtid_8982;\n        int64_t remnant_11424;\n        int64_t gtid_8983;\n        int64_t remnant_11425;\n        int64_t gtid_8984;\n        \n        virt_tblock_id_11419 = phys_tblock_id_11416 + i_11418 * sext_i64_i32(num_tblocks_8978);\n        slice_11420 = (int64_t) 64;\n        slice_11421 = (int64_t) 64 * slice_11420;\n        slice_11422 = m_6626 * slice_11421;\n        gtid_8981 = squot64(squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407), slice_11421);\n        remnant_11423 = squot64(sext_i32_i64(local_tid_11410), segment_sizze_nonzzero_11407) + sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) - gtid_8981 * slice_11421;\n        gtid_8982 = squot64(remnant_11423, slice_11420);\n        remnant_11424 = remnant_11423 - gtid_8982 * slice_11420;\n        gtid_8983 = remnant_11424;\n        remnant_11425 = remnant_11424 - gtid_8983;\n        gtid_8984 = srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) && (((slt64(gtid_8981, m_6626) && slt64(gtid_8982, (int64_t) 64)) && slt64(gtid_8983, (int64_t) 64)) && slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407)))) {\n                // apply map function\n                {\n                    f16 eta_p_8992 ",
                                    "= futrts_from_bits16(((__global uint16_t *) ext_mem_10579)[gtid_8981 * one_intra_par_min_8836 + gtid_8982 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 + gtid_8984]);\n                    f16 eta_p_8993 = futrts_from_bits16(((__global uint16_t *) mem_10589)[gtid_8984 + gtid_8983 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627]);\n                    f16 defunc_0_f_res_8994 = eta_p_8992 * eta_p_8993;\n                    \n                    // save results to be reduced\n                    {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(defunc_0_f_res_8994);\n                    }\n                }\n            } else {\n                ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16((f16) 0.0F);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)) {\n            // perform segmented scan to imitate reduction\n            {\n                f16 eta_p_8986;\n                f16 eta_p_8987;\n                f16 eta_p_11426;\n                f16 eta_p_11427;\n                bool ltid_in_bounds_11429 = slt64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407));\n                int32_t skip_threads_11430;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_11429) {\n                        eta_p_8987 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                        if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                            eta_p_8986 = eta_p_8987;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_11430 = 1;\n                    whil", "e (slt32(skip_threads_11430, 32)) {\n                        bool thread_active_11431 = sle32(skip_threads_11430, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && ltid_in_bounds_11429;\n                        \n                        if (thread_active_11431) {\n                            // read operands\n                            {\n                                eta_p_8986 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11430)]);\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_11432 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11410) - sext_i32_i64(local_tid_11410 - skip_threads_11430));\n                            \n                            if (thread_active_11431 && inactive_11432) {\n                                eta_p_8986 = eta_p_8987;\n                            }\n                            if (thread_active_11431) {\n                                if (!inactive_11432) {\n                                    f16 defunc_0_op_res_8988 = eta_p_8986 + eta_p_8987;\n                                    \n                                    eta_p_8986 = defunc_0_op_res_8988;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_11431) {\n                            // write result\n                            {\n                                ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_8986);\n                                eta_p_8987 = eta_p_8986;\n                            }\n                       ", " }\n                        if (sle32(wave_sizze_11412, skip_threads_11430)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_11430 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 31 && ltid_in_bounds_11429) {\n                        ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32))] = futrts_to_bits16(eta_p_8986);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_11433;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                            eta_p_11427 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)]);\n                            if ((local_tid_11410 - squot32(local_tid_11410, 32) * 32) == 0) {\n                                eta_p_11426 = eta_p_11427;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_11433 = 1;\n                        while (slt32(skip_threads_11433, 32)) {\n                            bool thread_active_11434 = sle32(skip_threads_11433, local_tid_11410 - squot32(local_tid_11410, 32) * 32) && (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429);\n                            \n                            if (thread_active_11434) {\n                                // read operand",
                                    "s\n                                {\n                                    eta_p_11426 = futrts_from_bits16(((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410) - sext_i32_i64(skip_threads_11433)]);\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_11435 = slt64(srem64(sext_i32_i64(local_tid_11410 * 32 + 32 - 1), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11410 * 32 + 32 - 1) - sext_i32_i64((local_tid_11410 - skip_threads_11433) * 32 + 32 - 1));\n                                \n                                if (thread_active_11434 && inactive_11435) {\n                                    eta_p_11426 = eta_p_11427;\n                                }\n                                if (thread_active_11434) {\n                                    if (!inactive_11435) {\n                                        f16 defunc_0_op_res_11428 = eta_p_11426 + eta_p_11427;\n                                        \n                                        eta_p_11426 = defunc_0_op_res_11428;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_11434) {\n                                // write result\n                                {\n                                    ((volatile __local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_11426);\n                                    eta_p_11427 = eta_p_11426;\n                                }\n                            }\n                            if (sle32(wave_sizze_11412, skip_threads_11433)) {\n                                barrier(CLK_LOCAL_MEM_FEN", "CE);\n                            }\n                            skip_threads_11433 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_11436 = squot32(local_tid_11410, 32) == 0 || !ltid_in_bounds_11429;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_11436) {\n                            eta_p_8987 = eta_p_8986;\n                            eta_p_8986 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(squot32(local_tid_11410, 32)) - (int64_t) 1]);\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_11437 = slt64(srem64(sext_i32_i64(local_tid_11410), dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), sext_i32_i64(local_tid_11410) - sext_i32_i64(squot32(local_tid_11410, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_11436) {\n                            if (inactive_11437) {\n                                eta_p_8986 = eta_p_8987;\n                            }\n                        }\n                        if (!no_carry_in_11436) {\n                            if (!inactive_11437) {\n                                f16 defunc_0_op_res_8988 = eta_p_8986 + eta_p_8987;\n                                \n                                eta_p_8986 = defunc_0_op_res_8988;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_11436) {\n                            ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_8986);\n                        }\n                    }\n                }\n                b", "arrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_11410, 32) == 0 && ltid_in_bounds_11429) {\n                        ((__local uint16_t *) red_arr_f16_mem_11414)[sext_i32_i64(local_tid_11410)] = futrts_to_bits16(eta_p_8987);\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), m_6626 * (int64_t) 64 * (int64_t) 64) && slt64(sext_i32_i64(local_tid_11410), squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407))) {\n                f16 tmp_11438 = futrts_from_bits16(((__local uint16_t *) red_arr_f16_mem_11414)[(sext_i32_i64(local_tid_11410) + (int64_t) 1) * segment_sizze_nonzzero_11407 - (int64_t) 1]);\n                \n                ((__global uint16_t *) mem_10594)[squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 4096) * (int64_t) 4096 + squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 4096) * (int64_t) 4096, (int64_t) 64) * (int64_t) 64 + (sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 4096) * (int64_t) 4096 - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, s", "egment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410) - squot64(sext_i32_i64(virt_tblock_id_11419) * squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407) + sext_i32_i64(local_tid_11410), (int64_t) 4096) * (int64_t) 4096, (int64_t) 64) * (int64_t) 64)] = futrts_to_bits16(tmp_11438);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef segred_tblock_sizze_8977\n}\n", NULL};
// Start of gpu_prototypes.h

// Dummy definitions for Tensor Core functions in C code
#define memblock_shared memblock_device
#define memblock_set_shared memblock_set_device
#define memblock_unref_shared memblock_unref_device

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 110;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "run64zisegred_large_8985_dim1";
        values[0] = *ctx->tuning_params.run64zisegred_tblock_sizze_8609;
    }
    {
        names[1] = "run64zisegred_large_8985zisegred_tblock_sizze_8977";
        values[1] = *ctx->tuning_params.run64zisegred_tblock_sizze_8609;
    }
    {
        names[2] = "run64zisegred_large_8985zichunk_sizze_11406";
        values[2] = (int64_t) 1;
    }
    {
        names[3] = "run64zisegred_small_8985_dim1";
        values[3] = *ctx->tuning_params.run64zisegred_tblock_sizze_8609;
    }
    {
        names[4] = "run64zisegred_small_8985zisegred_tblock_sizze_8977";
        values[4] = *ctx->tuning_params.run64zisegred_tblock_sizze_8609;
    }
    {
        names[5] = "run64zisegmap_intrablock_10078_dim1";
        values[5] = *ctx->tuning_params.run64ziTy_10058 * *ctx->tuning_params.run64ziTy_10058;
    }
    {
        names[6] = "run64zisegmap_intrablock_10078ziTy_10060";
        values[6] = *ctx->tuning_params.run64ziTy_10058;
    }
    {
        names[7] = "run64zisegmap_intrablock_10078ziRy_10061";
        values[7] = *ctx->tuning_params.run64ziRy_10059;
    }
    {
        names[8] = "run64zisegmap_intrablock_10078ziTk_10062";
        values[8] = *ctx->tuning_params.run64ziTk_10057;
    }
    {
        names[9] = "run64zisegmap_intrablock_10078zitk_div_tx_10063";
        values[9] = sdiv_up64(*ctx->tuning_params.run64ziTk_10057, *ctx->tuning_params.run64ziTy_10058);
    }
    {
        names[10] = "run64zisegmap_intrablock_10078ziTxRx_10065";
        values[10] = *ctx->tuning_params.run64ziTy_10058 * *ctx->tuning_params.run64ziRy_10059;
    }
    {
        names[11] = "run64zisegmap_intrablock_10078zia_loc_szz_10068";
        values[11] = *ctx->tuning_params.run64ziTk_10057 * (*ctx->tuning_params.run64ziTy_10058 * *ctx->tuning_params.run64ziRy_10059);
    }
    {
        names[12] = "run64zisegmap_intrablock_10078zigridDim_x_10071";
        values[12] = sdiv_up64((int64_t) 64, *ctx->tuning_params.run64ziTy_10058 * *ctx->tuning_params.run64ziRy_10059);
    }
    {
        names[13] = "run64zisegmap_intrablock_10078ziloop_nonempty_10430";
        values[13] = slt64((int64_t) 0, *ctx->tuning_params.run64ziRy_10059);
    }
    {
        names[14] = "run64zisegmap_intrablock_10078zibytes_10626";
        values[14] = (int64_t) 2 * (*ctx->tuning_params.run64ziTk_10057 * (*ctx->tuning_params.run64ziTy_10058 * *ctx->tuning_params.run64ziRy_10059));
    }
    {
        names[15] = "run64zisegred_large_8938_dim1";
        values[15] = *ctx->tuning_params.run64zisegred_tblock_sizze_8688;
    }
    {
        names[16] = "run64zisegred_large_8938zisegred_tblock_sizze_8930";
        values[16] = *ctx->tuning_params.run64zisegred_tblock_sizze_8688;
    }
    {
        names[17] = "run64zisegred_large_8938zichunk_sizze_11250";
        values[17] = (int64_t) 1;
    }
    {
        names[18] = "run64zisegred_small_8938_dim1";
        values[18] = *ctx->tuning_params.run64zisegred_tblock_sizze_8688;
    }
    {
        names[19] = "run64zisegred_small_8938zisegred_tblock_sizze_8930";
        values[19] = *ctx->tuning_params.run64zisegred_tblock_sizze_8688;
    }
    {
        names[20] = "run64zisegmap_intrablock_9700_dim1";
        values[20] = *ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziTy_9678;
    }
    {
        names[21] = "run64zisegmap_intrablock_9700ziTy_9680";
        values[21] = *ctx->tuning_params.run64ziTy_9678;
    }
    {
        names[22] = "run64zisegmap_intrablock_9700ziRy_9681";
        values[22] = *ctx->tuning_params.run64ziRy_9679;
    }
    {
        names[23] = "run64zisegmap_intrablock_9700ziTk_9682";
        values[23] = *ctx->tuning_params.run64ziTk_9677;
    }
    {
        names[24] = "run64zisegmap_intrablock_9700zitk_div_tx_9683";
        values[24] = sdiv_up_safe64(*ctx->tuning_params.run64ziTk_9677, *ctx->tuning_params.run64ziTy_9678);
    }
    {
        names[25] = "run64zisegmap_intrablock_9700ziTxRx_9685";
        values[25] = *ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679;
    }
    {
        names[26] = "run64zisegmap_intrablock_9700zia_loc_szz_9688";
        values[26] = *ctx->tuning_params.run64ziTk_9677 * (*ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679);
    }
    {
        names[27] = "run64zisegmap_intrablock_9700zib_loc_szz_9692";
        values[27] = *ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679 + *ctx->tuning_params.run64ziTk_9677 * (*ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679);
    }
    {
        names[28] = "run64zisegmap_intrablock_9700zigridDim_y_9694";
        values[28] = sdiv_up_safe64((int64_t) 64, *ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679);
    }
    {
        names[29] = "run64zisegmap_intrablock_9700zifull_tiles_9728";
        values[29] = squot_safe64((int64_t) 64, *ctx->tuning_params.run64ziTk_9677);
    }
    {
        names[30] = "run64zisegmap_intrablock_9700zibinop_y_9874";
        values[30] = (int64_t) 1 + *ctx->tuning_params.run64ziTk_9677;
    }
    {
        names[31] = "run64zisegmap_intrablock_9700zikk_9890";
        values[31] = *ctx->tuning_params.run64ziTk_9677 * squot_safe64((int64_t) 64, *ctx->tuning_params.run64ziTk_9677);
    }
    {
        names[32] = "run64zisegmap_intrablock_9700ziloop_nonempty_10436";
        values[32] = slt64((int64_t) 0, *ctx->tuning_params.run64ziRy_9679);
    }
    {
        names[33] = "run64zisegmap_intrablock_9700zibytes_10511";
        values[33] = (int64_t) 2 * (*ctx->tuning_params.run64ziTk_9677 * (*ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679));
    }
    {
        names[34] = "run64zisegmap_intrablock_9700zibytes_10513";
        values[34] = (int64_t) 2 * (*ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679 + *ctx->tuning_params.run64ziTk_9677 * (*ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziRy_9679));
    }
    {
        names[35] = "run64zisegmap_8853_dim1";
        values[35] = *ctx->tuning_params.run64zisegmap_tblock_sizze_8470;
    }
    {
        names[36] = "run64zisegmap_8853zisegmap_tblock_sizze_8830";
        values[36] = *ctx->tuning_params.run64zisegmap_tblock_sizze_8470;
    }
    {
        names[37] = "run64zisegmap_8407_dim1";
        values[37] = *ctx->tuning_params.run64zisegmap_tblock_sizze_8373;
    }
    {
        names[38] = "run64zisegmap_8407zisegmap_tblock_sizze_8402";
        values[38] = *ctx->tuning_params.run64zisegmap_tblock_sizze_8373;
    }
    {
        names[39] = "run32zisegred_large_8307_dim1";
        values[39] = *ctx->tuning_params.run32zisegred_tblock_sizze_7931;
    }
    {
        names[40] = "run32zisegred_large_8307zisegred_tblock_sizze_8299";
        values[40] = *ctx->tuning_params.run32zisegred_tblock_sizze_7931;
    }
    {
        names[41] = "run32zisegred_large_8307zichunk_sizze_11406";
        values[41] = (int64_t) 1;
    }
    {
        names[42] = "run32zisegred_small_8307_dim1";
        values[42] = *ctx->tuning_params.run32zisegred_tblock_sizze_7931;
    }
    {
        names[43] = "run32zisegred_small_8307zisegred_tblock_sizze_8299";
        values[43] = *ctx->tuning_params.run32zisegred_tblock_sizze_7931;
    }
    {
        names[44] = "run32zisegmap_intrablock_10048_dim1";
        values[44] = (int64_t) 64;
    }
    {
        names[45] = "run32zisegred_large_8260_dim1";
        values[45] = *ctx->tuning_params.run32zisegred_tblock_sizze_8010;
    }
    {
        names[46] = "run32zisegred_large_8260zisegred_tblock_sizze_8252";
        values[46] = *ctx->tuning_params.run32zisegred_tblock_sizze_8010;
    }
    {
        names[47] = "run32zisegred_large_8260zichunk_sizze_11250";
        values[47] = (int64_t) 1;
    }
    {
        names[48] = "run32zisegred_small_8260_dim1";
        values[48] = *ctx->tuning_params.run32zisegred_tblock_sizze_8010;
    }
    {
        names[49] = "run32zisegred_small_8260zisegred_tblock_sizze_8252";
        values[49] = *ctx->tuning_params.run32zisegred_tblock_sizze_8010;
    }
    {
        names[50] = "run32zisegmap_intrablock_9688_dim1";
        values[50] = (int64_t) 64;
    }
    {
        names[51] = "run32zisegmap_8175_dim1";
        values[51] = *ctx->tuning_params.run32zisegmap_tblock_sizze_7792;
    }
    {
        names[52] = "run32zisegmap_8175zisegmap_tblock_sizze_8152";
        values[52] = *ctx->tuning_params.run32zisegmap_tblock_sizze_7792;
    }
    {
        names[53] = "run32zisegmap_7729_dim1";
        values[53] = *ctx->tuning_params.run32zisegmap_tblock_sizze_7695;
    }
    {
        names[54] = "run32zisegmap_7729zisegmap_tblock_sizze_7724";
        values[54] = *ctx->tuning_params.run32zisegmap_tblock_sizze_7695;
    }
    {
        names[55] = "run16zisegred_large_7629_dim1";
        values[55] = *ctx->tuning_params.run16zisegred_tblock_sizze_7253;
    }
    {
        names[56] = "run16zisegred_large_7629zisegred_tblock_sizze_7621";
        values[56] = *ctx->tuning_params.run16zisegred_tblock_sizze_7253;
    }
    {
        names[57] = "run16zisegred_large_7629zichunk_sizze_11406";
        values[57] = (int64_t) 1;
    }
    {
        names[58] = "run16zisegred_small_7629_dim1";
        values[58] = *ctx->tuning_params.run16zisegred_tblock_sizze_7253;
    }
    {
        names[59] = "run16zisegred_small_7629zisegred_tblock_sizze_7621";
        values[59] = *ctx->tuning_params.run16zisegred_tblock_sizze_7253;
    }
    {
        names[60] = "run16zisegmap_intrablock_10048_dim1";
        values[60] = (int64_t) 64;
    }
    {
        names[61] = "run16zisegred_large_7582_dim1";
        values[61] = *ctx->tuning_params.run16zisegred_tblock_sizze_7332;
    }
    {
        names[62] = "run16zisegred_large_7582zisegred_tblock_sizze_7574";
        values[62] = *ctx->tuning_params.run16zisegred_tblock_sizze_7332;
    }
    {
        names[63] = "run16zisegred_large_7582zichunk_sizze_11250";
        values[63] = (int64_t) 1;
    }
    {
        names[64] = "run16zisegred_small_7582_dim1";
        values[64] = *ctx->tuning_params.run16zisegred_tblock_sizze_7332;
    }
    {
        names[65] = "run16zisegred_small_7582zisegred_tblock_sizze_7574";
        values[65] = *ctx->tuning_params.run16zisegred_tblock_sizze_7332;
    }
    {
        names[66] = "run16zisegmap_intrablock_9688_dim1";
        values[66] = (int64_t) 64;
    }
    {
        names[67] = "run16zisegmap_7497_dim1";
        values[67] = *ctx->tuning_params.run16zisegmap_tblock_sizze_7114;
    }
    {
        names[68] = "run16zisegmap_7497zisegmap_tblock_sizze_7474";
        values[68] = *ctx->tuning_params.run16zisegmap_tblock_sizze_7114;
    }
    {
        names[69] = "run16zisegmap_7051_dim1";
        values[69] = *ctx->tuning_params.run16zisegmap_tblock_sizze_7017;
    }
    {
        names[70] = "run16zisegmap_7051zisegmap_tblock_sizze_7046";
        values[70] = *ctx->tuning_params.run16zisegmap_tblock_sizze_7017;
    }
    {
        names[71] = "run128zisegred_large_9663_dim1";
        values[71] = *ctx->tuning_params.run128zisegred_tblock_sizze_9287;
    }
    {
        names[72] = "run128zisegred_large_9663zisegred_tblock_sizze_9655";
        values[72] = *ctx->tuning_params.run128zisegred_tblock_sizze_9287;
    }
    {
        names[73] = "run128zisegred_large_9663zichunk_sizze_11406";
        values[73] = (int64_t) 1;
    }
    {
        names[74] = "run128zisegred_small_9663_dim1";
        values[74] = *ctx->tuning_params.run128zisegred_tblock_sizze_9287;
    }
    {
        names[75] = "run128zisegred_small_9663zisegred_tblock_sizze_9655";
        values[75] = *ctx->tuning_params.run128zisegred_tblock_sizze_9287;
    }
    {
        names[76] = "run128zisegmap_intrablock_10078_dim1";
        values[76] = *ctx->tuning_params.run128ziTy_10058 * *ctx->tuning_params.run128ziTy_10058;
    }
    {
        names[77] = "run128zisegmap_intrablock_10078ziTy_10060";
        values[77] = *ctx->tuning_params.run128ziTy_10058;
    }
    {
        names[78] = "run128zisegmap_intrablock_10078ziRy_10061";
        values[78] = *ctx->tuning_params.run128ziRy_10059;
    }
    {
        names[79] = "run128zisegmap_intrablock_10078ziTk_10062";
        values[79] = *ctx->tuning_params.run128ziTk_10057;
    }
    {
        names[80] = "run128zisegmap_intrablock_10078zitk_div_tx_10063";
        values[80] = sdiv_up64(*ctx->tuning_params.run128ziTk_10057, *ctx->tuning_params.run128ziTy_10058);
    }
    {
        names[81] = "run128zisegmap_intrablock_10078ziTxRx_10065";
        values[81] = *ctx->tuning_params.run128ziTy_10058 * *ctx->tuning_params.run128ziRy_10059;
    }
    {
        names[82] = "run128zisegmap_intrablock_10078zia_loc_szz_10068";
        values[82] = *ctx->tuning_params.run128ziTk_10057 * (*ctx->tuning_params.run128ziTy_10058 * *ctx->tuning_params.run128ziRy_10059);
    }
    {
        names[83] = "run128zisegmap_intrablock_10078zigridDim_x_10071";
        values[83] = sdiv_up64((int64_t) 128, *ctx->tuning_params.run128ziTy_10058 * *ctx->tuning_params.run128ziRy_10059);
    }
    {
        names[84] = "run128zisegmap_intrablock_10078ziloop_nonempty_10430";
        values[84] = slt64((int64_t) 0, *ctx->tuning_params.run128ziRy_10059);
    }
    {
        names[85] = "run128zisegmap_intrablock_10078zibytes_10626";
        values[85] = (int64_t) 2 * (*ctx->tuning_params.run128ziTk_10057 * (*ctx->tuning_params.run128ziTy_10058 * *ctx->tuning_params.run128ziRy_10059));
    }
    {
        names[86] = "run128zisegred_large_9616_dim1";
        values[86] = *ctx->tuning_params.run128zisegred_tblock_sizze_9366;
    }
    {
        names[87] = "run128zisegred_large_9616zisegred_tblock_sizze_9608";
        values[87] = *ctx->tuning_params.run128zisegred_tblock_sizze_9366;
    }
    {
        names[88] = "run128zisegred_large_9616zichunk_sizze_11250";
        values[88] = (int64_t) 1;
    }
    {
        names[89] = "run128zisegred_small_9616_dim1";
        values[89] = *ctx->tuning_params.run128zisegred_tblock_sizze_9366;
    }
    {
        names[90] = "run128zisegred_small_9616zisegred_tblock_sizze_9608";
        values[90] = *ctx->tuning_params.run128zisegred_tblock_sizze_9366;
    }
    {
        names[91] = "run128zisegmap_intrablock_9700_dim1";
        values[91] = *ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziTy_9678;
    }
    {
        names[92] = "run128zisegmap_intrablock_9700ziTy_9680";
        values[92] = *ctx->tuning_params.run128ziTy_9678;
    }
    {
        names[93] = "run128zisegmap_intrablock_9700ziRy_9681";
        values[93] = *ctx->tuning_params.run128ziRy_9679;
    }
    {
        names[94] = "run128zisegmap_intrablock_9700ziTk_9682";
        values[94] = *ctx->tuning_params.run128ziTk_9677;
    }
    {
        names[95] = "run128zisegmap_intrablock_9700zitk_div_tx_9683";
        values[95] = sdiv_up_safe64(*ctx->tuning_params.run128ziTk_9677, *ctx->tuning_params.run128ziTy_9678);
    }
    {
        names[96] = "run128zisegmap_intrablock_9700ziTxRx_9685";
        values[96] = *ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679;
    }
    {
        names[97] = "run128zisegmap_intrablock_9700zia_loc_szz_9688";
        values[97] = *ctx->tuning_params.run128ziTk_9677 * (*ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679);
    }
    {
        names[98] = "run128zisegmap_intrablock_9700zib_loc_szz_9692";
        values[98] = *ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679 + *ctx->tuning_params.run128ziTk_9677 * (*ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679);
    }
    {
        names[99] = "run128zisegmap_intrablock_9700zigridDim_y_9694";
        values[99] = sdiv_up_safe64((int64_t) 128, *ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679);
    }
    {
        names[100] = "run128zisegmap_intrablock_9700zifull_tiles_9728";
        values[100] = squot_safe64((int64_t) 128, *ctx->tuning_params.run128ziTk_9677);
    }
    {
        names[101] = "run128zisegmap_intrablock_9700zibinop_y_9874";
        values[101] = (int64_t) 1 + *ctx->tuning_params.run128ziTk_9677;
    }
    {
        names[102] = "run128zisegmap_intrablock_9700zikk_9890";
        values[102] = *ctx->tuning_params.run128ziTk_9677 * squot_safe64((int64_t) 128, *ctx->tuning_params.run128ziTk_9677);
    }
    {
        names[103] = "run128zisegmap_intrablock_9700ziloop_nonempty_10436";
        values[103] = slt64((int64_t) 0, *ctx->tuning_params.run128ziRy_9679);
    }
    {
        names[104] = "run128zisegmap_intrablock_9700zibytes_10511";
        values[104] = (int64_t) 2 * (*ctx->tuning_params.run128ziTk_9677 * (*ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679));
    }
    {
        names[105] = "run128zisegmap_intrablock_9700zibytes_10513";
        values[105] = (int64_t) 2 * (*ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679 + *ctx->tuning_params.run128ziTk_9677 * (*ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziRy_9679));
    }
    {
        names[106] = "run128zisegmap_9531_dim1";
        values[106] = *ctx->tuning_params.run128zisegmap_tblock_sizze_9148;
    }
    {
        names[107] = "run128zisegmap_9531zisegmap_tblock_sizze_9508";
        values[107] = *ctx->tuning_params.run128zisegmap_tblock_sizze_9148;
    }
    {
        names[108] = "run128zisegmap_9085_dim1";
        values[108] = *ctx->tuning_params.run128zisegmap_tblock_sizze_9051;
    }
    {
        names[109] = "run128zisegmap_9085zisegmap_tblock_sizze_9080";
        values[109] = *ctx->tuning_params.run128zisegmap_tblock_sizze_9051;
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) { }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhreplicate_f16zireplicate_11019;
    gpu_kernel builtinzhreplicate_i32zireplicate_11296;
    gpu_kernel run128zisegmap_9085;
    gpu_kernel run128zisegmap_9531;
    gpu_kernel run128zisegmap_intrablock_10078;
    gpu_kernel run128zisegmap_intrablock_9114;
    gpu_kernel run128zisegmap_intrablock_9555;
    gpu_kernel run128zisegmap_intrablock_9700;
    gpu_kernel run128zisegred_large_9616;
    gpu_kernel run128zisegred_large_9663;
    gpu_kernel run128zisegred_small_9616;
    gpu_kernel run128zisegred_small_9663;
    gpu_kernel run16zisegmap_7051;
    gpu_kernel run16zisegmap_7497;
    gpu_kernel run16zisegmap_intrablock_10048;
    gpu_kernel run16zisegmap_intrablock_7080;
    gpu_kernel run16zisegmap_intrablock_7521;
    gpu_kernel run16zisegmap_intrablock_9688;
    gpu_kernel run16zisegred_large_7582;
    gpu_kernel run16zisegred_large_7629;
    gpu_kernel run16zisegred_small_7582;
    gpu_kernel run16zisegred_small_7629;
    gpu_kernel run32zisegmap_7729;
    gpu_kernel run32zisegmap_8175;
    gpu_kernel run32zisegmap_intrablock_10048;
    gpu_kernel run32zisegmap_intrablock_7758;
    gpu_kernel run32zisegmap_intrablock_8199;
    gpu_kernel run32zisegmap_intrablock_9688;
    gpu_kernel run32zisegred_large_8260;
    gpu_kernel run32zisegred_large_8307;
    gpu_kernel run32zisegred_small_8260;
    gpu_kernel run32zisegred_small_8307;
    gpu_kernel run64zisegmap_8407;
    gpu_kernel run64zisegmap_8853;
    gpu_kernel run64zisegmap_intrablock_10078;
    gpu_kernel run64zisegmap_intrablock_8436;
    gpu_kernel run64zisegmap_intrablock_8877;
    gpu_kernel run64zisegmap_intrablock_9700;
    gpu_kernel run64zisegred_large_8938;
    gpu_kernel run64zisegred_large_8985;
    gpu_kernel run64zisegred_small_8938;
    gpu_kernel run64zisegred_small_8985;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_f16zireplicate_11019, "builtinzhreplicate_f16zireplicate_11019");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_11296, "builtinzhreplicate_i32zireplicate_11296");
    gpu_create_kernel(ctx, &ctx->program->run128zisegmap_9085, "run128zisegmap_9085");
    gpu_create_kernel(ctx, &ctx->program->run128zisegmap_9531, "run128zisegmap_9531");
    gpu_create_kernel(ctx, &ctx->program->run128zisegmap_intrablock_10078, "run128zisegmap_intrablock_10078");
    gpu_create_kernel(ctx, &ctx->program->run128zisegmap_intrablock_9114, "run128zisegmap_intrablock_9114");
    gpu_create_kernel(ctx, &ctx->program->run128zisegmap_intrablock_9555, "run128zisegmap_intrablock_9555");
    gpu_create_kernel(ctx, &ctx->program->run128zisegmap_intrablock_9700, "run128zisegmap_intrablock_9700");
    gpu_create_kernel(ctx, &ctx->program->run128zisegred_large_9616, "run128zisegred_large_9616");
    gpu_create_kernel(ctx, &ctx->program->run128zisegred_large_9663, "run128zisegred_large_9663");
    gpu_create_kernel(ctx, &ctx->program->run128zisegred_small_9616, "run128zisegred_small_9616");
    gpu_create_kernel(ctx, &ctx->program->run128zisegred_small_9663, "run128zisegred_small_9663");
    gpu_create_kernel(ctx, &ctx->program->run16zisegmap_7051, "run16zisegmap_7051");
    gpu_create_kernel(ctx, &ctx->program->run16zisegmap_7497, "run16zisegmap_7497");
    gpu_create_kernel(ctx, &ctx->program->run16zisegmap_intrablock_10048, "run16zisegmap_intrablock_10048");
    gpu_create_kernel(ctx, &ctx->program->run16zisegmap_intrablock_7080, "run16zisegmap_intrablock_7080");
    gpu_create_kernel(ctx, &ctx->program->run16zisegmap_intrablock_7521, "run16zisegmap_intrablock_7521");
    gpu_create_kernel(ctx, &ctx->program->run16zisegmap_intrablock_9688, "run16zisegmap_intrablock_9688");
    gpu_create_kernel(ctx, &ctx->program->run16zisegred_large_7582, "run16zisegred_large_7582");
    gpu_create_kernel(ctx, &ctx->program->run16zisegred_large_7629, "run16zisegred_large_7629");
    gpu_create_kernel(ctx, &ctx->program->run16zisegred_small_7582, "run16zisegred_small_7582");
    gpu_create_kernel(ctx, &ctx->program->run16zisegred_small_7629, "run16zisegred_small_7629");
    gpu_create_kernel(ctx, &ctx->program->run32zisegmap_7729, "run32zisegmap_7729");
    gpu_create_kernel(ctx, &ctx->program->run32zisegmap_8175, "run32zisegmap_8175");
    gpu_create_kernel(ctx, &ctx->program->run32zisegmap_intrablock_10048, "run32zisegmap_intrablock_10048");
    gpu_create_kernel(ctx, &ctx->program->run32zisegmap_intrablock_7758, "run32zisegmap_intrablock_7758");
    gpu_create_kernel(ctx, &ctx->program->run32zisegmap_intrablock_8199, "run32zisegmap_intrablock_8199");
    gpu_create_kernel(ctx, &ctx->program->run32zisegmap_intrablock_9688, "run32zisegmap_intrablock_9688");
    gpu_create_kernel(ctx, &ctx->program->run32zisegred_large_8260, "run32zisegred_large_8260");
    gpu_create_kernel(ctx, &ctx->program->run32zisegred_large_8307, "run32zisegred_large_8307");
    gpu_create_kernel(ctx, &ctx->program->run32zisegred_small_8260, "run32zisegred_small_8260");
    gpu_create_kernel(ctx, &ctx->program->run32zisegred_small_8307, "run32zisegred_small_8307");
    gpu_create_kernel(ctx, &ctx->program->run64zisegmap_8407, "run64zisegmap_8407");
    gpu_create_kernel(ctx, &ctx->program->run64zisegmap_8853, "run64zisegmap_8853");
    gpu_create_kernel(ctx, &ctx->program->run64zisegmap_intrablock_10078, "run64zisegmap_intrablock_10078");
    gpu_create_kernel(ctx, &ctx->program->run64zisegmap_intrablock_8436, "run64zisegmap_intrablock_8436");
    gpu_create_kernel(ctx, &ctx->program->run64zisegmap_intrablock_8877, "run64zisegmap_intrablock_8877");
    gpu_create_kernel(ctx, &ctx->program->run64zisegmap_intrablock_9700, "run64zisegmap_intrablock_9700");
    gpu_create_kernel(ctx, &ctx->program->run64zisegred_large_8938, "run64zisegred_large_8938");
    gpu_create_kernel(ctx, &ctx->program->run64zisegred_large_8985, "run64zisegred_large_8985");
    gpu_create_kernel(ctx, &ctx->program->run64zisegred_small_8938, "run64zisegred_small_8938");
    gpu_create_kernel(ctx, &ctx->program->run64zisegred_small_8985, "run64zisegred_small_8985");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_f16zireplicate_11019);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_11296);
    gpu_free_kernel(ctx, ctx->program->run128zisegmap_9085);
    gpu_free_kernel(ctx, ctx->program->run128zisegmap_9531);
    gpu_free_kernel(ctx, ctx->program->run128zisegmap_intrablock_10078);
    gpu_free_kernel(ctx, ctx->program->run128zisegmap_intrablock_9114);
    gpu_free_kernel(ctx, ctx->program->run128zisegmap_intrablock_9555);
    gpu_free_kernel(ctx, ctx->program->run128zisegmap_intrablock_9700);
    gpu_free_kernel(ctx, ctx->program->run128zisegred_large_9616);
    gpu_free_kernel(ctx, ctx->program->run128zisegred_large_9663);
    gpu_free_kernel(ctx, ctx->program->run128zisegred_small_9616);
    gpu_free_kernel(ctx, ctx->program->run128zisegred_small_9663);
    gpu_free_kernel(ctx, ctx->program->run16zisegmap_7051);
    gpu_free_kernel(ctx, ctx->program->run16zisegmap_7497);
    gpu_free_kernel(ctx, ctx->program->run16zisegmap_intrablock_10048);
    gpu_free_kernel(ctx, ctx->program->run16zisegmap_intrablock_7080);
    gpu_free_kernel(ctx, ctx->program->run16zisegmap_intrablock_7521);
    gpu_free_kernel(ctx, ctx->program->run16zisegmap_intrablock_9688);
    gpu_free_kernel(ctx, ctx->program->run16zisegred_large_7582);
    gpu_free_kernel(ctx, ctx->program->run16zisegred_large_7629);
    gpu_free_kernel(ctx, ctx->program->run16zisegred_small_7582);
    gpu_free_kernel(ctx, ctx->program->run16zisegred_small_7629);
    gpu_free_kernel(ctx, ctx->program->run32zisegmap_7729);
    gpu_free_kernel(ctx, ctx->program->run32zisegmap_8175);
    gpu_free_kernel(ctx, ctx->program->run32zisegmap_intrablock_10048);
    gpu_free_kernel(ctx, ctx->program->run32zisegmap_intrablock_7758);
    gpu_free_kernel(ctx, ctx->program->run32zisegmap_intrablock_8199);
    gpu_free_kernel(ctx, ctx->program->run32zisegmap_intrablock_9688);
    gpu_free_kernel(ctx, ctx->program->run32zisegred_large_8260);
    gpu_free_kernel(ctx, ctx->program->run32zisegred_large_8307);
    gpu_free_kernel(ctx, ctx->program->run32zisegred_small_8260);
    gpu_free_kernel(ctx, ctx->program->run32zisegred_small_8307);
    gpu_free_kernel(ctx, ctx->program->run64zisegmap_8407);
    gpu_free_kernel(ctx, ctx->program->run64zisegmap_8853);
    gpu_free_kernel(ctx, ctx->program->run64zisegmap_intrablock_10078);
    gpu_free_kernel(ctx, ctx->program->run64zisegmap_intrablock_8436);
    gpu_free_kernel(ctx, ctx->program->run64zisegmap_intrablock_8877);
    gpu_free_kernel(ctx, ctx->program->run64zisegmap_intrablock_9700);
    gpu_free_kernel(ctx, ctx->program->run64zisegred_large_8938);
    gpu_free_kernel(ctx, ctx->program->run64zisegred_large_8985);
    gpu_free_kernel(ctx, ctx->program->run64zisegred_small_8938);
    gpu_free_kernel(ctx, ctx->program->run64zisegred_small_8985);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhreplicate_f16zitblock_sizze_11023 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_11300 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.run128ziRy_10059 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.run128ziRy_9679 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.run128ziTk_10057 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.run128ziTk_9677 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.run128ziTy_10058 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.run128ziTy_9678 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.run128zisegmap_num_tblocks_9053 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.run128zisegmap_num_tblocks_9150 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.run128zisegmap_tblock_sizze_9051 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.run128zisegmap_tblock_sizze_9148 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.run128zisegred_num_tblocks_9289 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.run128zisegred_num_tblocks_9368 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.run128zisegred_tblock_sizze_9287 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.run128zisegred_tblock_sizze_9366 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.run128zisuff_intra_par_1 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.run128zisuff_intra_par_3 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.run128zisuff_outer_par_0 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.run128zisuff_outer_par_2 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.run128zisuff_outer_par_4 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.run128zisuff_outer_par_5 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.run16zisegmap_num_tblocks_7019 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.run16zisegmap_num_tblocks_7116 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.run16zisegmap_tblock_sizze_7017 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.run16zisegmap_tblock_sizze_7114 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.run16zisegred_num_tblocks_7255 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.run16zisegred_num_tblocks_7334 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.run16zisegred_tblock_sizze_7253 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.run16zisegred_tblock_sizze_7332 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.run16zisuff_intra_par_1 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.run16zisuff_intra_par_3 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.run16zisuff_outer_par_0 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.run16zisuff_outer_par_2 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.run16zisuff_outer_par_4 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.run16zisuff_outer_par_5 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.run32zisegmap_num_tblocks_7697 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.run32zisegmap_num_tblocks_7794 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.run32zisegmap_tblock_sizze_7695 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.run32zisegmap_tblock_sizze_7792 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.run32zisegred_num_tblocks_7933 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.run32zisegred_num_tblocks_8012 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.run32zisegred_tblock_sizze_7931 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.run32zisegred_tblock_sizze_8010 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.run32zisuff_intra_par_1 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.run32zisuff_intra_par_3 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.run32zisuff_outer_par_0 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.run32zisuff_outer_par_2 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.run32zisuff_outer_par_4 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.run32zisuff_outer_par_5 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.run64ziRy_10059 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.run64ziRy_9679 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.run64ziTk_10057 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.run64ziTk_9677 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.run64ziTy_10058 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.run64ziTy_9678 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.run64zisegmap_num_tblocks_8375 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.run64zisegmap_num_tblocks_8472 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.run64zisegmap_tblock_sizze_8373 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.run64zisegmap_tblock_sizze_8470 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.run64zisegred_num_tblocks_8611 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.run64zisegred_num_tblocks_8690 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.run64zisegred_tblock_sizze_8609 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.run64zisegred_tblock_sizze_8688 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.run64zisuff_intra_par_1 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.run64zisuff_intra_par_3 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.run64zisuff_outer_par_0 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.run64zisuff_outer_par_2 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.run64zisuff_outer_par_4 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.run64zisuff_outer_par_5 = &ctx->cfg->tuning_params[69];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f16(struct futhark_context *ctx, struct memblock_device mem_11014, int64_t num_elems_11015, f16 val_11016);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_11291, int64_t num_elems_11292, int32_t val_11293);
FUTHARK_FUN_ATTR int futrts_entry_mk_input(struct futhark_context *ctx, struct memblock_device *mem_out_p_11491, struct memblock_device *mem_out_p_11492, struct memblock_device *mem_out_p_11493, int64_t *out_prim_out_11494, int64_t m_6250, int64_t d_6251);
FUTHARK_FUN_ATTR int futrts_entry_run128(struct futhark_context *ctx, struct memblock_device *mem_out_p_11495, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);
FUTHARK_FUN_ATTR int futrts_entry_run16(struct futhark_context *ctx, struct memblock_device *mem_out_p_11496, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);
FUTHARK_FUN_ATTR int futrts_entry_run32(struct futhark_context *ctx, struct memblock_device *mem_out_p_11497, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);
FUTHARK_FUN_ATTR int futrts_entry_run64(struct futhark_context *ctx, struct memblock_device *mem_out_p_11498, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_11289 (ctx->constants->counters_mem_11289)
    #define counters_mem_11445 (ctx->constants->counters_mem_11445)
    counters_mem_11289.references = NULL;
    counters_mem_11445.references = NULL;
    if (memblock_alloc_device(ctx, &counters_mem_11289, (int64_t) 81920, "counters_mem_11289")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11289, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11445, (int64_t) 81920, "counters_mem_11445")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11445, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11289, (int64_t) 81920, "counters_mem_11289")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11289, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11445, (int64_t) 81920, "counters_mem_11445")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11445, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11289, (int64_t) 81920, "counters_mem_11289")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11289, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11445, (int64_t) 81920, "counters_mem_11445")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11445, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11289, (int64_t) 81920, "counters_mem_11289")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11289, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_11445, (int64_t) 81920, "counters_mem_11445")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_11445, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_11289
    #undef counters_mem_11445
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_11289, "ctx->constants->counters_mem_11289") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_11445, "ctx->constants->counters_mem_11445") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhreplicate_f16zireplicate_11019(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, uint16_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_f16zireplicate_11019, "builtin#replicate_f16.replicate_11019", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_11296(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_11296, "builtin#replicate_i32.replicate_11296", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegmap_9085(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegmap_9085, "run128.segmap_9085", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegmap_intrablock_9114(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegmap_intrablock_9114, "run128.segmap_intrablock_9114", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegmap_9531(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegmap_9531, "run128.segmap_9531", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegmap_intrablock_9555(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegmap_intrablock_9555, "run128.segmap_intrablock_9555", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegmap_intrablock_9700(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegmap_intrablock_9700, "run128.segmap_intrablock_9700", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegred_small_9616(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegred_small_9616, "run128.segred_small_9616", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegred_large_9616(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegred_large_9616, "run128.segred_large_9616", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegmap_intrablock_10078(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegmap_intrablock_10078, "run128.segmap_intrablock_10078", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegred_small_9663(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegred_small_9663, "run128.segred_small_9663", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run128zisegred_large_9663(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->run128zisegred_large_9663, "run128.segred_large_9663", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegmap_7051(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegmap_7051, "run16.segmap_7051", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegmap_intrablock_7080(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegmap_intrablock_7080, "run16.segmap_intrablock_7080", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegmap_7497(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegmap_7497, "run16.segmap_7497", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegmap_intrablock_7521(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegmap_intrablock_7521, "run16.segmap_intrablock_7521", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegmap_intrablock_9688(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegmap_intrablock_9688, "run16.segmap_intrablock_9688", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegred_small_7582(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegred_small_7582, "run16.segred_small_7582", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegred_large_7582(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegred_large_7582, "run16.segred_large_7582", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegmap_intrablock_10048(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegmap_intrablock_10048, "run16.segmap_intrablock_10048", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegred_small_7629(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegred_small_7629, "run16.segred_small_7629", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run16zisegred_large_7629(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->run16zisegred_large_7629, "run16.segred_large_7629", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegmap_7729(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegmap_7729, "run32.segmap_7729", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegmap_intrablock_7758(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegmap_intrablock_7758, "run32.segmap_intrablock_7758", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegmap_8175(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegmap_8175, "run32.segmap_8175", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegmap_intrablock_8199(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegmap_intrablock_8199, "run32.segmap_intrablock_8199", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegmap_intrablock_9688(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegmap_intrablock_9688, "run32.segmap_intrablock_9688", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegred_small_8260(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegred_small_8260, "run32.segred_small_8260", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegred_large_8260(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegred_large_8260, "run32.segred_large_8260", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegmap_intrablock_10048(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegmap_intrablock_10048, "run32.segmap_intrablock_10048", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegred_small_8307(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegred_small_8307, "run32.segred_small_8307", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run32zisegred_large_8307(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->run32zisegred_large_8307, "run32.segred_large_8307", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegmap_8407(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegmap_8407, "run64.segmap_8407", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegmap_intrablock_8436(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegmap_intrablock_8436, "run64.segmap_intrablock_8436", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegmap_8853(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegmap_8853, "run64.segmap_8853", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegmap_intrablock_8877(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegmap_intrablock_8877, "run64.segmap_intrablock_8877", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegmap_intrablock_9700(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegmap_intrablock_9700, "run64.segmap_intrablock_9700", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegred_small_8938(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegred_small_8938, "run64.segred_small_8938", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegred_large_8938(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegred_large_8938, "run64.segred_large_8938", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegmap_intrablock_10078(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegmap_intrablock_10078, "run64.segmap_intrablock_10078", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegred_small_8985(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegred_small_8985, "run64.segred_small_8985", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_run64zisegred_large_8985(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, int64_t arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->run64zisegred_large_8985, "run64.segred_large_8985", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_f16_2d {
    struct memblock_device mem;
    int64_t shape[2];
};
struct futhark_f16_2d *futhark_new_f16_2d(struct futhark_context *ctx, const uint16_t *data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_f16_2d *bad = NULL;
    struct futhark_f16_2d *arr = (struct futhark_f16_2d *) malloc(sizeof(struct futhark_f16_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * 2, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) (dim0 * dim1) * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f16_2d *futhark_new_raw_f16_2d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1)
{
    int err = 0;
    struct futhark_f16_2d *bad = NULL;
    struct futhark_f16_2d *arr = (struct futhark_f16_2d *) malloc(sizeof(struct futhark_f16_2d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr, uint16_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) (arr->shape[0] * arr->shape[1]) * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f16_2d(struct futhark_context *ctx, uint16_t *out, struct futhark_f16_2d *arr, int64_t i0, int64_t i1)
{
    int err = 0;
    
    if ((i0 >= 0 && i0 < arr->shape[0]) && (i1 >= 0 && i1 < arr->shape[1])) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 2 * (i0 * arr->shape[1] + i1 * 1), 2);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f16_2d(struct futhark_context *ctx, struct futhark_f16_2d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f16_3d {
    struct memblock_device mem;
    int64_t shape[3];
};
struct futhark_f16_3d *futhark_new_f16_3d(struct futhark_context *ctx, const uint16_t *data, int64_t dim0, int64_t dim1, int64_t dim2)
{
    int err = 0;
    struct futhark_f16_3d *bad = NULL;
    struct futhark_f16_3d *arr = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * dim1 * dim2 * 2, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    arr->shape[2] = dim2;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) (dim0 * dim1 * dim2) * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f16_3d *futhark_new_raw_f16_3d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0, int64_t dim1, int64_t dim2)
{
    int err = 0;
    struct futhark_f16_3d *bad = NULL;
    struct futhark_f16_3d *arr = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    arr->shape[1] = dim1;
    arr->shape[2] = dim2;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr, uint16_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) (arr->shape[0] * arr->shape[1] * arr->shape[2]) * 2);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f16_3d(struct futhark_context *ctx, uint16_t *out, struct futhark_f16_3d *arr, int64_t i0, int64_t i1, int64_t i2)
{
    int err = 0;
    
    if ((i0 >= 0 && i0 < arr->shape[0]) && ((i1 >= 0 && i1 < arr->shape[1]) && (i2 >= 0 && i2 < arr->shape[2]))) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 2 * (i0 * (arr->shape[1] * arr->shape[2]) + i1 * arr->shape[2] + i2 * 1), 2);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f16_3d(struct futhark_context *ctx, struct futhark_f16_3d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f16(struct futhark_context *ctx, struct memblock_device mem_11014, int64_t num_elems_11015, f16 val_11016)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t replicate_n_11018 = num_elems_11015;
    int64_t tblock_sizze_11023;
    
    tblock_sizze_11023 = *ctx->tuning_params.builtinzhreplicate_f16zitblock_sizze_11023;
    
    int64_t virt_num_tblocks_11024 = sdiv_up64(replicate_n_11018, tblock_sizze_11023);
    int64_t num_tblocks_11025 = smin64(virt_num_tblocks_11024, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_f16zireplicate_11019(ctx, num_tblocks_11025, 1, 1, tblock_sizze_11023, 1, 1, (int64_t) 0, num_elems_11015, futrts_to_bits16(val_11016), replicate_n_11018, virt_num_tblocks_11024, num_tblocks_11025, mem_11014.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_11291, int64_t num_elems_11292, int32_t val_11293)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t replicate_n_11295 = num_elems_11292;
    int64_t tblock_sizze_11300;
    
    tblock_sizze_11300 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_11300;
    
    int64_t virt_num_tblocks_11301 = sdiv_up64(replicate_n_11295, tblock_sizze_11300);
    int64_t num_tblocks_11302 = smin64(virt_num_tblocks_11301, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_11296(ctx, num_tblocks_11302, 1, 1, tblock_sizze_11300, 1, 1, (int64_t) 0, num_elems_11292, val_11293, replicate_n_11295, virt_num_tblocks_11301, num_tblocks_11302, mem_11291.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_mk_input(struct futhark_context *ctx, struct memblock_device *mem_out_p_11491, struct memblock_device *mem_out_p_11492, struct memblock_device *mem_out_p_11493, int64_t *out_prim_out_11494, int64_t m_6250, int64_t d_6251)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_10481;
    
    mem_10481.references = NULL;
    
    struct memblock_device mem_10478;
    
    mem_10478.references = NULL;
    
    struct memblock_device mem_10475;
    
    mem_10475.references = NULL;
    
    struct memblock_device mem_out_11012;
    
    mem_out_11012.references = NULL;
    
    struct memblock_device mem_out_11011;
    
    mem_out_11011.references = NULL;
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t prim_out_11013;
    int64_t dzlz7bUZLztZRz20Umz20Udz7dUzg_6814 = mul64(m_6250, d_6251);
    int64_t binop_x_10472 = (int64_t) 2 * m_6250;
    int64_t binop_x_10473 = d_6251 * binop_x_10472;
    int64_t bytes_10474 = d_6251 * binop_x_10473;
    int64_t binop_x_10476 = (int64_t) 2 * dzlz7bUZLztZRz20Umz20Udz7dUzg_6814;
    int64_t bytes_10477 = d_6251 * binop_x_10476;
    
    if (memblock_alloc_device(ctx, &mem_10475, bytes_10474, "mem_10475")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f16(ctx, mem_10475, m_6250 * d_6251 * d_6251, (f16) 3.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_10478, bytes_10477, "mem_10478")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f16(ctx, mem_10478, dzlz7bUZLztZRz20Umz20Udz7dUzg_6814 * d_6251, (f16) 2.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_10481, bytes_10477, "mem_10481")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f16(ctx, mem_10481, dzlz7bUZLztZRz20Umz20Udz7dUzg_6814 * d_6251, (f16) 1.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_set_device(ctx, &mem_out_11010, &mem_10475, "mem_10475") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_11011, &mem_10478, "mem_10478") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_11012, &mem_10481, "mem_10481") != 0)
        return 1;
    prim_out_11013 = dzlz7bUZLztZRz20Umz20Udz7dUzg_6814;
    if (memblock_set_device(ctx, &*mem_out_p_11491, &mem_out_11010, "mem_out_11010") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_11492, &mem_out_11011, "mem_out_11011") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_11493, &mem_out_11012, "mem_out_11012") != 0)
        return 1;
    *out_prim_out_11494 = prim_out_11013;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_10481, "mem_10481") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10478, "mem_10478") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10475, "mem_10475") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11012, "mem_out_11012") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11011, "mem_out_11011") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11010, "mem_out_11010") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_run128(struct futhark_context *ctx, struct memblock_device *mem_out_p_11495, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6642, int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_10849;
    
    mem_10849.references = NULL;
    
    struct memblock_device segred_tmp_mem_11443;
    
    segred_tmp_mem_11443.references = NULL;
    
    struct memblock_device mem_10594;
    
    mem_10594.references = NULL;
    
    struct memblock_device mem_10589;
    
    mem_10589.references = NULL;
    
    struct memblock_device mem_10690;
    
    mem_10690.references = NULL;
    
    struct memblock_device ext_mem_10691;
    
    ext_mem_10691.references = NULL;
    
    struct memblock_device segred_tmp_mem_11287;
    
    segred_tmp_mem_11287.references = NULL;
    
    struct memblock_device mem_10479;
    
    mem_10479.references = NULL;
    
    struct memblock_device mem_10575;
    
    mem_10575.references = NULL;
    
    struct memblock_device ext_mem_10579;
    
    ext_mem_10579.references = NULL;
    
    struct memblock_device mem_10699;
    
    mem_10699.references = NULL;
    
    struct memblock_device ext_mem_10700;
    
    ext_mem_10700.references = NULL;
    
    struct memblock_device color_10859;
    
    color_10859.references = NULL;
    
    struct memblock_device mem_10756;
    
    mem_10756.references = NULL;
    
    struct memblock_device mem_10725;
    
    mem_10725.references = NULL;
    
    struct memblock_device mem_10715;
    
    mem_10715.references = NULL;
    
    struct memblock_device ext_mem_10761;
    
    ext_mem_10761.references = NULL;
    
    struct memblock_device mem_10769;
    
    mem_10769.references = NULL;
    
    struct memblock_device ext_mem_10773;
    
    ext_mem_10773.references = NULL;
    
    struct memblock_device color_10856;
    
    color_10856.references = NULL;
    
    struct memblock_device mem_10840;
    
    mem_10840.references = NULL;
    
    struct memblock_device mem_10798;
    
    mem_10798.references = NULL;
    
    struct memblock_device mem_10788;
    
    mem_10788.references = NULL;
    
    struct memblock_device ext_mem_10845;
    
    ext_mem_10845.references = NULL;
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t arg_6655 = mul64((int64_t) 128, m_6642);
    bool assert_cond_6656 = arg_6655 == dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;
    bool assert_c_6657;
    
    if (!assert_cond_6656) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "Assertion is false: entry point arguments have invalid sizes.", "-> #0  ./custom_attention_like_expanded.fut:57:3-23\n   #1  ./custom_attention_like_expanded.fut:56:1-57:23\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_10593 = (int64_t) 32768 * m_6642;
    bool suff_outer_par_9047;
    
    suff_outer_par_9047 = *ctx->tuning_params.run128zisuff_outer_par_0 <= m_6642;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run128.suff_outer_par_0", (long) m_6642, suff_outer_par_9047 ? "true" : "false");
    
    int64_t one_intra_par_min_9036 = (int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;
    int64_t intra_avail_par_9043 = smin64(one_intra_par_min_9036, one_intra_par_min_9036);
    int64_t max_tblock_sizze_9109;
    
    max_tblock_sizze_9109 = ctx->max_thread_block_size;
    
    bool fits_9110 = sle64(one_intra_par_min_9036, max_tblock_sizze_9109);
    bool suff_intra_par_9108;
    
    suff_intra_par_9108 = *ctx->tuning_params.run128zisuff_intra_par_1 <= intra_avail_par_9043;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run128.suff_intra_par_1", (long) intra_avail_par_9043, suff_intra_par_9108 ? "true" : "false");
    
    bool intra_suff_and_fits_9111 = suff_intra_par_9108 && fits_9110;
    int64_t segmap_tblock_sizze_9508;
    
    segmap_tblock_sizze_9508 = *ctx->tuning_params.run128zisegmap_tblock_sizze_9148;
    
    int64_t num_tblocks_9509;
    int64_t max_num_tblocks_11011;
    
    max_num_tblocks_11011 = *ctx->tuning_params.run128zisegmap_num_tblocks_9150;
    num_tblocks_9509 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_6655, segmap_tblock_sizze_9508), max_num_tblocks_11011)));
    
    bool suff_outer_par_9513;
    
    suff_outer_par_9513 = *ctx->tuning_params.run128zisuff_outer_par_2 <= arg_6655;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run128.suff_outer_par_2", (long) arg_6655, suff_outer_par_9513 ? "true" : "false");
    
    int64_t one_intra_par_min_9514 = (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;
    int64_t intra_avail_par_9518 = smin64(one_intra_par_min_9514, one_intra_par_min_9514);
    bool fits_9523 = sle64(one_intra_par_min_9514, max_tblock_sizze_9109);
    bool suff_intra_par_9525;
    
    suff_intra_par_9525 = *ctx->tuning_params.run128zisuff_intra_par_3 <= intra_avail_par_9518;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run128.suff_intra_par_3", (long) intra_avail_par_9518, suff_intra_par_9525 ? "true" : "false");
    
    bool intra_suff_and_fits_9526 = fits_9523 && suff_intra_par_9525;
    int64_t comparatee_9587 = m_6642 * one_intra_par_min_9514;
    bool suff_outer_par_9588;
    
    suff_outer_par_9588 = *ctx->tuning_params.run128zisuff_outer_par_5 <= comparatee_9587;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run128.suff_outer_par_5", (long) comparatee_9587, suff_outer_par_9588 ? "true" : "false");
    
    int64_t nest_sizze_9607 = (int64_t) 128 * comparatee_9587;
    int64_t segred_tblock_sizze_9608;
    
    segred_tblock_sizze_9608 = *ctx->tuning_params.run128zisegred_tblock_sizze_9366;
    
    int64_t num_tblocks_9609;
    int64_t max_num_tblocks_11012;
    
    max_num_tblocks_11012 = *ctx->tuning_params.run128zisegred_num_tblocks_9368;
    num_tblocks_9609 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_9607, segred_tblock_sizze_9608), max_num_tblocks_11012)));
    
    int64_t comparatee_9634 = (int64_t) 16384 * m_6642;
    bool suff_outer_par_9635;
    
    suff_outer_par_9635 = *ctx->tuning_params.run128zisuff_outer_par_4 <= comparatee_9634;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run128.suff_outer_par_4", (long) comparatee_9634, suff_outer_par_9635 ? "true" : "false");
    
    int64_t nest_sizze_9654 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * comparatee_9634;
    int64_t segred_tblock_sizze_9655;
    
    segred_tblock_sizze_9655 = *ctx->tuning_params.run128zisegred_tblock_sizze_9287;
    
    int64_t num_tblocks_9656;
    int64_t max_num_tblocks_11013;
    
    max_num_tblocks_11013 = *ctx->tuning_params.run128zisegred_num_tblocks_9289;
    num_tblocks_9656 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_9654, segred_tblock_sizze_9655), max_num_tblocks_11013)));
    
    int64_t segmap_tblock_sizze_9080;
    
    segmap_tblock_sizze_9080 = *ctx->tuning_params.run128zisegmap_tblock_sizze_9051;
    
    int64_t num_tblocks_9081;
    int64_t max_num_tblocks_11014;
    
    max_num_tblocks_11014 = *ctx->tuning_params.run128zisegmap_num_tblocks_9053;
    num_tblocks_9081 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_6642, segmap_tblock_sizze_9080), max_num_tblocks_11014)));
    
    int64_t Ty_9680;
    
    Ty_9680 = *ctx->tuning_params.run128ziTy_9678;
    
    int64_t Ry_9681;
    
    Ry_9681 = *ctx->tuning_params.run128ziRy_9679;
    
    int64_t Tk_9682;
    
    Tk_9682 = *ctx->tuning_params.run128ziTk_9677;
    
    int64_t TxRx_9685 = Ty_9680 * Ry_9681;
    int64_t a_loc_szz_9688 = Tk_9682 * TxRx_9685;
    int64_t b_loc_szz_9692 = TxRx_9685 + a_loc_szz_9688;
    int64_t tblock_sizze_9697 = Ty_9680 * Ty_9680;
    bool loop_nonempty_10436 = slt64((int64_t) 0, Ry_9681);
    int64_t binop_y_9874 = (int64_t) 1 + Tk_9682;
    int64_t Ty_10060;
    
    Ty_10060 = *ctx->tuning_params.run128ziTy_10058;
    
    int64_t Ry_10061;
    
    Ry_10061 = *ctx->tuning_params.run128ziRy_10059;
    
    int64_t Tk_10062;
    
    Tk_10062 = *ctx->tuning_params.run128ziTk_10057;
    
    int64_t TxRx_10065 = Ty_10060 * Ry_10061;
    int64_t a_loc_szz_10068 = Tk_10062 * TxRx_10065;
    int64_t tblock_sizze_10075 = Ty_10060 * Ty_10060;
    bool loop_nonempty_10430 = slt64((int64_t) 0, Ry_10061);
    int64_t ext_10760;
    int64_t shared_memory_capacity_11015;
    
    shared_memory_capacity_11015 = ctx->max_shared_memory;
    if (suff_outer_par_9513) {
        ext_10760 = (int64_t) 128;
    } else {
        ext_10760 = (int64_t) 16384;
    }
    
    int64_t ext_10759;
    int64_t shared_memory_capacity_11016;
    
    shared_memory_capacity_11016 = ctx->max_shared_memory;
    if (suff_outer_par_9513) {
        ext_10759 = (int64_t) 1;
    } else {
        ext_10759 = (int64_t) 128;
    }
    
    int64_t binop_x_10477 = (int64_t) 256 * m_6642;
    int64_t bytes_10478 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * binop_x_10477;
    int64_t tk_div_tx_9683 = sdiv_up_safe64(Tk_9682, Ty_9680);
    int64_t gridDim_x_9693 = sdiv_up_safe64(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, TxRx_9685);
    int64_t gridDim_y_9694 = sdiv_up_safe64((int64_t) 128, TxRx_9685);
    int64_t binop_y_9695 = gridDim_x_9693 * gridDim_y_9694;
    int64_t grid_sizze_9696 = m_6642 * binop_y_9695;
    int64_t full_tiles_9728 = squot_safe64((int64_t) 128, Tk_9682);
    int64_t kk_9890 = Tk_9682 * full_tiles_9728;
    int64_t binop_y_10499 = Ry_9681 - (int64_t) 1;
    int64_t binop_x_10500 = smax64((int64_t) 0, binop_y_10499);
    int64_t binop_y_10501 = Ry_9681 * binop_x_10500;
    int64_t binop_y_10502 = smax64((int64_t) 0, binop_y_10501);
    int64_t binop_y_10507 = binop_x_10500 + binop_y_10502;
    int64_t binop_y_10508 = (int64_t) 1 + binop_y_10507;
    int64_t bytes_10509 = (int64_t) 2 * binop_y_10508;
    int64_t bytes_10511 = (int64_t) 2 * a_loc_szz_9688;
    int64_t bytes_10513 = (int64_t) 2 * b_loc_szz_9692;
    int64_t binop_y_10580 = dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 - (int64_t) 1;
    int64_t binop_x_10582 = smax64((int64_t) 0, binop_y_10580);
    int64_t binop_y_10584 = (int64_t) 127 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;
    int64_t binop_y_10585 = smax64((int64_t) 0, binop_y_10584);
    int64_t binop_y_10586 = binop_x_10582 + binop_y_10585;
    int64_t binop_y_10587 = (int64_t) 1 + binop_y_10586;
    int64_t bytes_10588 = (int64_t) 2 * binop_y_10587;
    int64_t binop_y_10614 = Ry_10061 - (int64_t) 1;
    int64_t binop_x_10615 = smax64((int64_t) 0, binop_y_10614);
    int64_t binop_y_10616 = Ry_10061 * binop_x_10615;
    int64_t binop_y_10617 = smax64((int64_t) 0, binop_y_10616);
    int64_t binop_y_10622 = binop_x_10615 + binop_y_10617;
    int64_t binop_y_10623 = (int64_t) 1 + binop_y_10622;
    int64_t bytes_10624 = (int64_t) 2 * binop_y_10623;
    int64_t bytes_10626 = (int64_t) 2 * a_loc_szz_10068;
    int64_t bytes_10693 = (int64_t) 2 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;
    int64_t binop_y_10701 = m_6642 - (int64_t) 1;
    int64_t binop_x_10702 = smax64((int64_t) 0, binop_y_10701);
    int64_t binop_y_10703 = (int64_t) 128 * binop_x_10702;
    int64_t binop_x_10704 = smax64((int64_t) 0, binop_y_10703);
    int64_t binop_x_10707 = (int64_t) 127 + binop_x_10704;
    int64_t binop_y_10710 = (int64_t) 16256 * m_6642;
    int64_t binop_y_10711 = smax64((int64_t) 0, binop_y_10710);
    int64_t binop_y_10712 = binop_x_10707 + binop_y_10711;
    int64_t binop_y_10713 = (int64_t) 1 + binop_y_10712;
    int64_t bytes_10714 = (int64_t) 2 * binop_y_10713;
    int64_t binop_x_10748 = (int64_t) 127 + binop_x_10704;
    int64_t binop_y_10753 = binop_y_10711 + binop_x_10748;
    int64_t binop_y_10754 = (int64_t) 1 + binop_y_10753;
    int64_t bytes_10755 = (int64_t) 2 * binop_y_10754;
    int64_t bytes_10763 = (int64_t) 256 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643;
    int64_t binop_x_10781 = binop_x_10702 + binop_y_10711;
    int64_t binop_y_10783 = (int64_t) 127 * m_6642;
    int64_t binop_y_10784 = smax64((int64_t) 0, binop_y_10783);
    int64_t binop_y_10785 = binop_x_10781 + binop_y_10784;
    int64_t binop_y_10786 = (int64_t) 1 + binop_y_10785;
    int64_t bytes_10787 = (int64_t) 2 * binop_y_10786;
    int64_t binop_y_10838 = (int64_t) 1 + binop_y_10785;
    int64_t bytes_10839 = (int64_t) 2 * binop_y_10838;
    int64_t ext_10772;
    int64_t shared_memory_capacity_11017;
    
    shared_memory_capacity_11017 = ctx->max_shared_memory;
    if (intra_suff_and_fits_9111) {
        ext_10772 = (int64_t) 16384;
    } else {
        ext_10772 = ext_10760;
    }
    
    int64_t ext_10771;
    int64_t shared_memory_capacity_11018;
    
    shared_memory_capacity_11018 = ctx->max_shared_memory;
    if (intra_suff_and_fits_9111) {
        ext_10771 = (int64_t) 128;
    } else {
        ext_10771 = ext_10759;
    }
    
    int64_t ext_10758;
    int64_t shared_memory_capacity_11019;
    
    shared_memory_capacity_11019 = ctx->max_shared_memory;
    if (suff_outer_par_9513) {
        ext_10758 = arg_6655;
    } else {
        ext_10758 = (int64_t) 1;
    }
    
    int64_t ext_10844;
    int64_t shared_memory_capacity_11020;
    
    shared_memory_capacity_11020 = ctx->max_shared_memory;
    if (suff_outer_par_9047) {
        ext_10844 = (int64_t) 1;
    } else {
        ext_10844 = ext_10772;
    }
    
    int64_t ext_10843;
    int64_t shared_memory_capacity_11021;
    
    shared_memory_capacity_11021 = ctx->max_shared_memory;
    if (suff_outer_par_9047) {
        ext_10843 = arg_6655;
    } else {
        ext_10843 = ext_10771;
    }
    
    int64_t ext_10770;
    int64_t shared_memory_capacity_11022;
    
    shared_memory_capacity_11022 = ctx->max_shared_memory;
    if (intra_suff_and_fits_9111) {
        ext_10770 = (int64_t) 1;
    } else {
        ext_10770 = ext_10758;
    }
    
    int64_t ext_10842;
    int64_t shared_memory_capacity_11023;
    
    shared_memory_capacity_11023 = ctx->max_shared_memory;
    if (suff_outer_par_9047) {
        ext_10842 = m_6642;
    } else {
        ext_10842 = ext_10770;
    }
    
    int64_t num_threads_10996 = segmap_tblock_sizze_9508 * num_tblocks_9509;
    int64_t total_sizze_10997 = bytes_10693 * num_threads_10996;
    int64_t num_threads_10974 = segmap_tblock_sizze_9080 * num_tblocks_9081;
    int64_t total_sizze_10975 = bytes_10693 * num_threads_10974;
    int64_t shared_memory_capacity_11490;
    
    shared_memory_capacity_11490 = ctx->max_shared_memory;
    if (suff_outer_par_9047 && sle64((int64_t) 0, shared_memory_capacity_11490)) {
        if (memblock_alloc_device(ctx, &mem_10788, bytes_10787, "mem_10788")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10788.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_6642 * (int64_t) 128, m_6642}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 16384, (int64_t) 128, (int64_t) 1}, (int64_t []) {m_6642, (int64_t) 128, (int64_t) 128})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10798, bytes_10588, "mem_10798")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10798.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 128, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, (int64_t) 128})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10840, bytes_10839, "mem_10840")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &color_10856, total_sizze_10975, "color_10856")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_11024 = sext_i64_i32(sdiv_up64(m_6642, segmap_tblock_sizze_9080));
        
        {
            err = gpu_kernel_run128zisegmap_9085(ctx, num_tblocks_9081, 1, 1, *ctx->tuning_params.run128zisegmap_tblock_sizze_9051, 1, 1, (int64_t) 0, m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, num_tblocks_9081, num_threads_10974, virt_num_tblocks_11024, K_mem_10473.mem, mem_10788.mem, mem_10798.mem, mem_10840.mem, color_10856.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_10788, "mem_10788") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10798, "mem_10798") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_10845, &mem_10840, "mem_10840") != 0)
            return 1;
    } else {
        int64_t shared_memory_capacity_11489;
        
        shared_memory_capacity_11489 = ctx->max_shared_memory;
        if (intra_suff_and_fits_9111 && sle64((int64_t) 32768 + sdiv_up64(bytes_10763, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11489)) {
            if (memblock_alloc_device(ctx, &mem_10769, bytes_10593, "mem_10769")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t num_chunks_11042 = sext_i64_i32(sdiv_up64((int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9036));
            int32_t num_chunks_11043 = sext_i64_i32(sdiv_up64((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128, one_intra_par_min_9036));
            int32_t virt_num_tblocks_11044 = sext_i64_i32(m_6642);
            
            {
                err = gpu_kernel_run128zisegmap_intrablock_9114(ctx, m_6642, 1, 1, one_intra_par_min_9036, 1, 1, (int64_t) 2 * ((int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 16384 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128), (int64_t) 8), (int64_t) 8)) + (bytes_10763 + srem64((int64_t) 8 - srem64(bytes_10763, (int64_t) 8), (int64_t) 8)) + (int64_t) 32768, m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9036, bytes_10763, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10769.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_set_device(ctx, &ext_mem_10773, &mem_10769, "mem_10769") != 0)
                return 1;
        } else {
            int64_t shared_memory_capacity_11488;
            
            shared_memory_capacity_11488 = ctx->max_shared_memory;
            if (suff_outer_par_9513 && sle64((int64_t) 0, shared_memory_capacity_11488)) {
                if (memblock_alloc_device(ctx, &mem_10715, bytes_10714, "mem_10715")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10715.mem, (int64_t) 0, (int64_t []) {(int64_t) 128, (int64_t) 1, (int64_t) 128 * m_6642}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 16384, (int64_t) 128, (int64_t) 1}, (int64_t []) {m_6642, (int64_t) 128, (int64_t) 128})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10725, bytes_10588, "mem_10725")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10725.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 128, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, (int64_t) 128})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10756, bytes_10755, "mem_10756")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &color_10859, total_sizze_10997, "color_10859")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_11111 = sext_i64_i32(sdiv_up64(m_6642 * (int64_t) 128, segmap_tblock_sizze_9508));
                
                {
                    err = gpu_kernel_run128zisegmap_9531(ctx, num_tblocks_9509, 1, 1, *ctx->tuning_params.run128zisegmap_tblock_sizze_9148, 1, 1, (int64_t) 0, m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, num_tblocks_9509, num_threads_10996, virt_num_tblocks_11111, K_mem_10473.mem, mem_10715.mem, mem_10725.mem, mem_10756.mem, color_10859.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_10715, "mem_10715") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_10725, "mem_10725") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_10761, &mem_10756, "mem_10756") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_11487;
                
                shared_memory_capacity_11487 = ctx->max_shared_memory;
                if (intra_suff_and_fits_9526 && sle64((int64_t) 256 + sdiv_up64(bytes_10693, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11487)) {
                    if (memblock_alloc_device(ctx, &mem_10699, bytes_10593, "mem_10699")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_11130 = sext_i64_i32(sdiv_up64((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9514));
                    int32_t num_chunks_11131 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128, one_intra_par_min_9514));
                    int32_t virt_num_tblocks_11132 = sext_i64_i32(m_6642 * (int64_t) 128);
                    
                    {
                        err = gpu_kernel_run128zisegmap_intrablock_9555(ctx, arg_6655, 1, 1, one_intra_par_min_9514, 1, 1, (int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 128), (int64_t) 8), (int64_t) 8)) + (bytes_10693 + srem64((int64_t) 8 - srem64(bytes_10693, (int64_t) 8), (int64_t) 8)) + (int64_t) 256, m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9514, bytes_10693, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10699.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_10700, &mem_10699, "mem_10699") != 0)
                        return 1;
                } else {
                    int64_t shared_memory_capacity_11350;
                    
                    shared_memory_capacity_11350 = ctx->max_shared_memory;
                    if (suff_outer_par_9588 && sle64(sdiv_up64(bytes_10513, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_10511, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11350)) {
                        if (memblock_alloc_device(ctx, &mem_10575, bytes_10478, "mem_10575")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11195 = sext_i64_i32(sdiv_up64(Ty_9680 * Ty_9680, tblock_sizze_9697));
                        int32_t virt_num_tblocks_11196 = sext_i64_i32(m_6642 * gridDim_y_9694 * gridDim_x_9693);
                        
                        {
                            err = gpu_kernel_run128zisegmap_intrablock_9700(ctx, grid_sizze_9696, 1, 1, *ctx->tuning_params.run128ziTy_9678 * *ctx->tuning_params.run128ziTy_9678, 1, 1, bytes_10511 + srem64((int64_t) 8 - srem64(bytes_10511, (int64_t) 8), (int64_t) 8) + (bytes_10513 + srem64((int64_t) 8 - srem64(bytes_10513, (int64_t) 8), (int64_t) 8)), m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, gridDim_x_9693, Q_mem_10472.mem, K_mem_10473.mem, mem_10575.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10579, &mem_10575, "mem_10575") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10479, bytes_10478, "mem_10479")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11250 = (int64_t) 1;
                        
                        if (slt64((int64_t) 256, segred_tblock_sizze_9608 * chunk_sizze_11250)) {
                            int64_t segment_sizze_nonzzero_11251 = smax64((int64_t) 1, (int64_t) 128);
                            int64_t num_threads_11252 = segred_tblock_sizze_9608 * segred_tblock_sizze_9608;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 128, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, squot64(segred_tblock_sizze_9608, segment_sizze_nonzzero_11251))), '\n');
                            {
                                err = gpu_kernel_run128zisegred_small_9616(ctx, num_tblocks_9609, 1, 1, *ctx->tuning_params.run128zisegred_tblock_sizze_9366, 1, 1, (int64_t) 2 * segred_tblock_sizze_9608 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9608, (int64_t) 8), (int64_t) 8), m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, num_tblocks_9609, segment_sizze_nonzzero_11251, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11283 = sdiv_up64(num_tblocks_9609, smax64((int64_t) 1, m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643));
                            int64_t q_11284 = sdiv_up64((int64_t) 128, segred_tblock_sizze_9608 * blocks_per_segment_11283 * chunk_sizze_11250);
                            int64_t num_virtblocks_11285 = blocks_per_segment_11283 * (m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);
                            int64_t threads_per_segment_11286 = blocks_per_segment_11283 * segred_tblock_sizze_9608;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6642 * (int64_t) 128 * dzlz7bUZLztZRz20Umz20U128z7dUzg_6643), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 128, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11285, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_9609, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_9608, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11284, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11283, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11287, (int64_t) 2 * num_virtblocks_11285, "segred_tmp_mem_11287")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run128zisegred_large_9616(ctx, num_tblocks_9609, 1, 1, *ctx->tuning_params.run128zisegred_tblock_sizze_9366, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_9608 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9608, (int64_t) 8), (int64_t) 8)), m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, num_tblocks_9609, blocks_per_segment_11283, q_11284, num_virtblocks_11285, threads_per_segment_11286, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem, segred_tmp_mem_11287.mem, counters_mem_11289.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10579, &mem_10479, "mem_10479") != 0)
                            return 1;
                    }
                    
                    int64_t shared_memory_capacity_11486;
                    
                    shared_memory_capacity_11486 = ctx->max_shared_memory;
                    if (suff_outer_par_9635 && sle64(sdiv_up64(bytes_10626, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_10626, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11486)) {
                        int64_t tk_div_tx_10063 = sdiv_up64(Tk_10062, Ty_10060);
                        int64_t gridDim_x_10071 = sdiv_up64((int64_t) 128, TxRx_10065);
                        int64_t binop_y_10073 = gridDim_x_10071 * gridDim_x_10071;
                        int64_t grid_sizze_10074 = m_6642 * binop_y_10073;
                        int64_t full_tiles_10106 = squot64(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, Tk_10062);
                        int64_t kk_10264 = Tk_10062 * full_tiles_10106;
                        
                        if (memblock_alloc_device(ctx, &mem_10690, bytes_10593, "mem_10690")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11351 = sext_i64_i32(sdiv_up64(Ty_10060 * Ty_10060, tblock_sizze_10075));
                        int32_t virt_num_tblocks_11352 = sext_i64_i32(m_6642 * gridDim_x_10071 * gridDim_x_10071);
                        
                        {
                            err = gpu_kernel_run128zisegmap_intrablock_10078(ctx, grid_sizze_10074, 1, 1, *ctx->tuning_params.run128ziTy_10058 * *ctx->tuning_params.run128ziTy_10058, 1, 1, bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8) + (bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8)), m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9514, full_tiles_10106, kk_10264, V_mem_10474.mem, ext_mem_10579.mem, mem_10690.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10691, &mem_10690, "mem_10690") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10589, bytes_10588, "mem_10589")) {
                            err = 1;
                            goto cleanup;
                        }
                        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10589.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 128, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, (int64_t) 128})) != 0)
                            goto cleanup;
                        if (memblock_alloc_device(ctx, &mem_10594, bytes_10593, "mem_10594")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11406 = (int64_t) 1;
                        
                        if (slt64(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 * (int64_t) 2, segred_tblock_sizze_9655 * chunk_sizze_11406)) {
                            int64_t segment_sizze_nonzzero_11407 = smax64((int64_t) 1, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);
                            int64_t num_threads_11408 = segred_tblock_sizze_9655 * segred_tblock_sizze_9655;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6642 * (int64_t) 128 * (int64_t) 128), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6642 * (int64_t) 128 * (int64_t) 128, squot64(segred_tblock_sizze_9655, segment_sizze_nonzzero_11407))), '\n');
                            {
                                err = gpu_kernel_run128zisegred_small_9663(ctx, num_tblocks_9656, 1, 1, *ctx->tuning_params.run128zisegred_tblock_sizze_9287, 1, 1, (int64_t) 2 * segred_tblock_sizze_9655 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9655, (int64_t) 8), (int64_t) 8), m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9514, num_tblocks_9656, segment_sizze_nonzzero_11407, ext_mem_10579.mem, mem_10589.mem, mem_10594.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11439 = sdiv_up64(num_tblocks_9656, smax64((int64_t) 1, m_6642 * (int64_t) 128 * (int64_t) 128));
                            int64_t q_11440 = sdiv_up64(dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, segred_tblock_sizze_9655 * blocks_per_segment_11439 * chunk_sizze_11406);
                            int64_t num_virtblocks_11441 = blocks_per_segment_11439 * (m_6642 * (int64_t) 128 * (int64_t) 128);
                            int64_t threads_per_segment_11442 = blocks_per_segment_11439 * segred_tblock_sizze_9655;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6642 * (int64_t) 128 * (int64_t) 128), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11441, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_9656, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_9655, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11440, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11439, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11443, (int64_t) 2 * num_virtblocks_11441, "segred_tmp_mem_11443")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run128zisegred_large_9663(ctx, num_tblocks_9656, 1, 1, *ctx->tuning_params.run128zisegred_tblock_sizze_9287, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_9655 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_9655, (int64_t) 8), (int64_t) 8)), m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643, one_intra_par_min_9514, num_tblocks_9656, blocks_per_segment_11439, q_11440, num_virtblocks_11441, threads_per_segment_11442, ext_mem_10579.mem, mem_10589.mem, mem_10594.mem, segred_tmp_mem_11443.mem, counters_mem_11445.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_10589, "mem_10589") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_10691, &mem_10594, "mem_10594") != 0)
                            return 1;
                    }
                    if (memblock_unref_device(ctx, &ext_mem_10579, "ext_mem_10579") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_10700, &ext_mem_10691, "ext_mem_10691") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_10761, &ext_mem_10700, "ext_mem_10700") != 0)
                    return 1;
            }
            if (memblock_set_device(ctx, &ext_mem_10773, &ext_mem_10761, "ext_mem_10761") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_10845, &ext_mem_10773, "ext_mem_10773") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_10849, bytes_10593, "mem_10849")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10849.mem, (int64_t) 0, (int64_t []) {(int64_t) 16384, (int64_t) 128, (int64_t) 1}, ext_mem_10845.mem, (int64_t) 0, (int64_t []) {ext_10844, ext_10843, ext_10842}, (int64_t []) {m_6642, (int64_t) 128, (int64_t) 128})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_10845, "ext_mem_10845") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_11010, &mem_10849, "mem_10849") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_11495, &mem_out_11010, "mem_out_11010") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_10849, "mem_10849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11443, "segred_tmp_mem_11443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10594, "mem_10594") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10589, "mem_10589") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10690, "mem_10690") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10691, "ext_mem_10691") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11287, "segred_tmp_mem_11287") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10479, "mem_10479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10575, "mem_10575") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10579, "ext_mem_10579") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10699, "mem_10699") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10700, "ext_mem_10700") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10756, "mem_10756") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10725, "mem_10725") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10715, "mem_10715") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10761, "ext_mem_10761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10769, "mem_10769") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10773, "ext_mem_10773") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10840, "mem_10840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10798, "mem_10798") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10788, "mem_10788") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10845, "ext_mem_10845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11010, "mem_out_11010") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_run16(struct futhark_context *ctx, struct memblock_device *mem_out_p_11496, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6594, int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_10829;
    
    mem_10829.references = NULL;
    
    struct memblock_device segred_tmp_mem_11443;
    
    segred_tmp_mem_11443.references = NULL;
    
    struct memblock_device mem_10584;
    
    mem_10584.references = NULL;
    
    struct memblock_device mem_10579;
    
    mem_10579.references = NULL;
    
    struct memblock_device mem_10670;
    
    mem_10670.references = NULL;
    
    struct memblock_device ext_mem_10671;
    
    ext_mem_10671.references = NULL;
    
    struct memblock_device segred_tmp_mem_11287;
    
    segred_tmp_mem_11287.references = NULL;
    
    struct memblock_device mem_10479;
    
    mem_10479.references = NULL;
    
    struct memblock_device mem_10565;
    
    mem_10565.references = NULL;
    
    struct memblock_device ext_mem_10569;
    
    ext_mem_10569.references = NULL;
    
    struct memblock_device mem_10679;
    
    mem_10679.references = NULL;
    
    struct memblock_device ext_mem_10680;
    
    ext_mem_10680.references = NULL;
    
    struct memblock_device color_10859;
    
    color_10859.references = NULL;
    
    struct memblock_device mem_10736;
    
    mem_10736.references = NULL;
    
    struct memblock_device mem_10705;
    
    mem_10705.references = NULL;
    
    struct memblock_device mem_10695;
    
    mem_10695.references = NULL;
    
    struct memblock_device ext_mem_10741;
    
    ext_mem_10741.references = NULL;
    
    struct memblock_device mem_10749;
    
    mem_10749.references = NULL;
    
    struct memblock_device ext_mem_10753;
    
    ext_mem_10753.references = NULL;
    
    struct memblock_device color_10856;
    
    color_10856.references = NULL;
    
    struct memblock_device mem_10820;
    
    mem_10820.references = NULL;
    
    struct memblock_device mem_10778;
    
    mem_10778.references = NULL;
    
    struct memblock_device mem_10768;
    
    mem_10768.references = NULL;
    
    struct memblock_device ext_mem_10825;
    
    ext_mem_10825.references = NULL;
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t arg_6655 = mul64((int64_t) 16, m_6594);
    bool assert_cond_6656 = arg_6655 == dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;
    bool assert_c_6657;
    
    if (!assert_cond_6656) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "Assertion is false: entry point arguments have invalid sizes.", "-> #0  ./custom_attention_like_expanded.fut:48:3-23\n   #1  ./custom_attention_like_expanded.fut:47:1-48:23\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_10583 = (int64_t) 512 * m_6594;
    bool suff_outer_par_7013;
    
    suff_outer_par_7013 = *ctx->tuning_params.run16zisuff_outer_par_0 <= m_6594;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run16.suff_outer_par_0", (long) m_6594, suff_outer_par_7013 ? "true" : "false");
    
    int64_t one_intra_par_min_7002 = (int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;
    int64_t intra_avail_par_7009 = smin64(one_intra_par_min_7002, one_intra_par_min_7002);
    int64_t max_tblock_sizze_7075;
    
    max_tblock_sizze_7075 = ctx->max_thread_block_size;
    
    bool fits_7076 = sle64(one_intra_par_min_7002, max_tblock_sizze_7075);
    bool suff_intra_par_7074;
    
    suff_intra_par_7074 = *ctx->tuning_params.run16zisuff_intra_par_1 <= intra_avail_par_7009;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run16.suff_intra_par_1", (long) intra_avail_par_7009, suff_intra_par_7074 ? "true" : "false");
    
    bool intra_suff_and_fits_7077 = suff_intra_par_7074 && fits_7076;
    int64_t segmap_tblock_sizze_7474;
    
    segmap_tblock_sizze_7474 = *ctx->tuning_params.run16zisegmap_tblock_sizze_7114;
    
    int64_t num_tblocks_7475;
    int64_t max_num_tblocks_11011;
    
    max_num_tblocks_11011 = *ctx->tuning_params.run16zisegmap_num_tblocks_7116;
    num_tblocks_7475 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_6655, segmap_tblock_sizze_7474), max_num_tblocks_11011)));
    
    bool suff_outer_par_7479;
    
    suff_outer_par_7479 = *ctx->tuning_params.run16zisuff_outer_par_2 <= arg_6655;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run16.suff_outer_par_2", (long) arg_6655, suff_outer_par_7479 ? "true" : "false");
    
    int64_t one_intra_par_min_7480 = (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;
    int64_t intra_avail_par_7484 = smin64(one_intra_par_min_7480, one_intra_par_min_7480);
    bool fits_7489 = sle64(one_intra_par_min_7480, max_tblock_sizze_7075);
    bool suff_intra_par_7491;
    
    suff_intra_par_7491 = *ctx->tuning_params.run16zisuff_intra_par_3 <= intra_avail_par_7484;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run16.suff_intra_par_3", (long) intra_avail_par_7484, suff_intra_par_7491 ? "true" : "false");
    
    bool intra_suff_and_fits_7492 = fits_7489 && suff_intra_par_7491;
    int64_t comparatee_7553 = m_6594 * one_intra_par_min_7480;
    bool suff_outer_par_7554;
    
    suff_outer_par_7554 = *ctx->tuning_params.run16zisuff_outer_par_5 <= comparatee_7553;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run16.suff_outer_par_5", (long) comparatee_7553, suff_outer_par_7554 ? "true" : "false");
    
    int64_t nest_sizze_7573 = (int64_t) 16 * comparatee_7553;
    int64_t segred_tblock_sizze_7574;
    
    segred_tblock_sizze_7574 = *ctx->tuning_params.run16zisegred_tblock_sizze_7332;
    
    int64_t num_tblocks_7575;
    int64_t max_num_tblocks_11012;
    
    max_num_tblocks_11012 = *ctx->tuning_params.run16zisegred_num_tblocks_7334;
    num_tblocks_7575 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_7573, segred_tblock_sizze_7574), max_num_tblocks_11012)));
    
    int64_t comparatee_7600 = (int64_t) 256 * m_6594;
    bool suff_outer_par_7601;
    
    suff_outer_par_7601 = *ctx->tuning_params.run16zisuff_outer_par_4 <= comparatee_7600;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run16.suff_outer_par_4", (long) comparatee_7600, suff_outer_par_7601 ? "true" : "false");
    
    int64_t nest_sizze_7620 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * comparatee_7600;
    int64_t segred_tblock_sizze_7621;
    
    segred_tblock_sizze_7621 = *ctx->tuning_params.run16zisegred_tblock_sizze_7253;
    
    int64_t num_tblocks_7622;
    int64_t max_num_tblocks_11013;
    
    max_num_tblocks_11013 = *ctx->tuning_params.run16zisegred_num_tblocks_7255;
    num_tblocks_7622 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_7620, segred_tblock_sizze_7621), max_num_tblocks_11013)));
    
    int64_t segmap_tblock_sizze_7046;
    
    segmap_tblock_sizze_7046 = *ctx->tuning_params.run16zisegmap_tblock_sizze_7017;
    
    int64_t num_tblocks_7047;
    int64_t max_num_tblocks_11014;
    
    max_num_tblocks_11014 = *ctx->tuning_params.run16zisegmap_num_tblocks_7019;
    num_tblocks_7047 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_6594, segmap_tblock_sizze_7046), max_num_tblocks_11014)));
    
    int64_t gridDim_x_9682 = sdiv_up64(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, (int64_t) 16);
    int64_t grid_sizze_9685 = m_6594 * gridDim_x_9682;
    int64_t full_tiles_10076 = squot64(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, (int64_t) 8);
    int64_t kk_10234 = (int64_t) 8 * full_tiles_10076;
    int64_t ext_10740;
    int64_t shared_memory_capacity_11015;
    
    shared_memory_capacity_11015 = ctx->max_shared_memory;
    if (suff_outer_par_7479) {
        ext_10740 = (int64_t) 16;
    } else {
        ext_10740 = (int64_t) 256;
    }
    
    int64_t ext_10739;
    int64_t shared_memory_capacity_11016;
    
    shared_memory_capacity_11016 = ctx->max_shared_memory;
    if (suff_outer_par_7479) {
        ext_10739 = (int64_t) 1;
    } else {
        ext_10739 = (int64_t) 16;
    }
    
    int64_t binop_x_10477 = (int64_t) 32 * m_6594;
    int64_t bytes_10478 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * binop_x_10477;
    int64_t binop_y_10570 = dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 - (int64_t) 1;
    int64_t binop_x_10572 = smax64((int64_t) 0, binop_y_10570);
    int64_t binop_y_10574 = (int64_t) 15 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;
    int64_t binop_y_10575 = smax64((int64_t) 0, binop_y_10574);
    int64_t binop_y_10576 = binop_x_10572 + binop_y_10575;
    int64_t binop_y_10577 = (int64_t) 1 + binop_y_10576;
    int64_t bytes_10578 = (int64_t) 2 * binop_y_10577;
    int64_t bytes_10673 = (int64_t) 2 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;
    int64_t binop_y_10681 = m_6594 - (int64_t) 1;
    int64_t binop_x_10682 = smax64((int64_t) 0, binop_y_10681);
    int64_t binop_y_10683 = (int64_t) 16 * binop_x_10682;
    int64_t binop_x_10684 = smax64((int64_t) 0, binop_y_10683);
    int64_t binop_x_10687 = (int64_t) 15 + binop_x_10684;
    int64_t binop_y_10690 = (int64_t) 240 * m_6594;
    int64_t binop_y_10691 = smax64((int64_t) 0, binop_y_10690);
    int64_t binop_y_10692 = binop_x_10687 + binop_y_10691;
    int64_t binop_y_10693 = (int64_t) 1 + binop_y_10692;
    int64_t bytes_10694 = (int64_t) 2 * binop_y_10693;
    int64_t binop_x_10728 = (int64_t) 15 + binop_x_10684;
    int64_t binop_y_10733 = binop_y_10691 + binop_x_10728;
    int64_t binop_y_10734 = (int64_t) 1 + binop_y_10733;
    int64_t bytes_10735 = (int64_t) 2 * binop_y_10734;
    int64_t bytes_10743 = (int64_t) 32 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595;
    int64_t binop_x_10761 = binop_x_10682 + binop_y_10691;
    int64_t binop_y_10763 = (int64_t) 15 * m_6594;
    int64_t binop_y_10764 = smax64((int64_t) 0, binop_y_10763);
    int64_t binop_y_10765 = binop_x_10761 + binop_y_10764;
    int64_t binop_y_10766 = (int64_t) 1 + binop_y_10765;
    int64_t bytes_10767 = (int64_t) 2 * binop_y_10766;
    int64_t binop_y_10818 = (int64_t) 1 + binop_y_10765;
    int64_t bytes_10819 = (int64_t) 2 * binop_y_10818;
    int64_t ext_10752;
    int64_t shared_memory_capacity_11017;
    
    shared_memory_capacity_11017 = ctx->max_shared_memory;
    if (intra_suff_and_fits_7077) {
        ext_10752 = (int64_t) 256;
    } else {
        ext_10752 = ext_10740;
    }
    
    int64_t ext_10751;
    int64_t shared_memory_capacity_11018;
    
    shared_memory_capacity_11018 = ctx->max_shared_memory;
    if (intra_suff_and_fits_7077) {
        ext_10751 = (int64_t) 16;
    } else {
        ext_10751 = ext_10739;
    }
    
    int64_t ext_10738;
    int64_t shared_memory_capacity_11019;
    
    shared_memory_capacity_11019 = ctx->max_shared_memory;
    if (suff_outer_par_7479) {
        ext_10738 = arg_6655;
    } else {
        ext_10738 = (int64_t) 1;
    }
    
    int64_t ext_10824;
    int64_t shared_memory_capacity_11020;
    
    shared_memory_capacity_11020 = ctx->max_shared_memory;
    if (suff_outer_par_7013) {
        ext_10824 = (int64_t) 1;
    } else {
        ext_10824 = ext_10752;
    }
    
    int64_t ext_10823;
    int64_t shared_memory_capacity_11021;
    
    shared_memory_capacity_11021 = ctx->max_shared_memory;
    if (suff_outer_par_7013) {
        ext_10823 = arg_6655;
    } else {
        ext_10823 = ext_10751;
    }
    
    int64_t ext_10750;
    int64_t shared_memory_capacity_11022;
    
    shared_memory_capacity_11022 = ctx->max_shared_memory;
    if (intra_suff_and_fits_7077) {
        ext_10750 = (int64_t) 1;
    } else {
        ext_10750 = ext_10738;
    }
    
    int64_t ext_10822;
    int64_t shared_memory_capacity_11023;
    
    shared_memory_capacity_11023 = ctx->max_shared_memory;
    if (suff_outer_par_7013) {
        ext_10822 = m_6594;
    } else {
        ext_10822 = ext_10750;
    }
    
    int64_t num_threads_10888 = segmap_tblock_sizze_7474 * num_tblocks_7475;
    int64_t total_sizze_10889 = bytes_10673 * num_threads_10888;
    int64_t num_threads_10866 = segmap_tblock_sizze_7046 * num_tblocks_7047;
    int64_t total_sizze_10867 = bytes_10673 * num_threads_10866;
    int64_t shared_memory_capacity_11490;
    
    shared_memory_capacity_11490 = ctx->max_shared_memory;
    if (suff_outer_par_7013 && sle64((int64_t) 0, shared_memory_capacity_11490)) {
        if (memblock_alloc_device(ctx, &mem_10768, bytes_10767, "mem_10768")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10768.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_6594 * (int64_t) 16, m_6594}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 256, (int64_t) 16, (int64_t) 1}, (int64_t []) {m_6594, (int64_t) 16, (int64_t) 16})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10778, bytes_10578, "mem_10778")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10778.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 16, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, (int64_t) 16})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10820, bytes_10819, "mem_10820")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &color_10856, total_sizze_10867, "color_10856")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_11024 = sext_i64_i32(sdiv_up64(m_6594, segmap_tblock_sizze_7046));
        
        {
            err = gpu_kernel_run16zisegmap_7051(ctx, num_tblocks_7047, 1, 1, *ctx->tuning_params.run16zisegmap_tblock_sizze_7017, 1, 1, (int64_t) 0, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, num_tblocks_7047, num_threads_10866, virt_num_tblocks_11024, K_mem_10473.mem, mem_10768.mem, mem_10778.mem, mem_10820.mem, color_10856.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_10768, "mem_10768") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10778, "mem_10778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_10825, &mem_10820, "mem_10820") != 0)
            return 1;
    } else {
        int64_t shared_memory_capacity_11489;
        
        shared_memory_capacity_11489 = ctx->max_shared_memory;
        if (intra_suff_and_fits_7077 && sle64((int64_t) 512 + sdiv_up64(bytes_10743, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11489)) {
            if (memblock_alloc_device(ctx, &mem_10749, bytes_10583, "mem_10749")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t num_chunks_11042 = sext_i64_i32(sdiv_up64((int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7002));
            int32_t num_chunks_11043 = sext_i64_i32(sdiv_up64((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16, one_intra_par_min_7002));
            int32_t virt_num_tblocks_11044 = sext_i64_i32(m_6594);
            
            {
                err = gpu_kernel_run16zisegmap_intrablock_7080(ctx, m_6594, 1, 1, one_intra_par_min_7002, 1, 1, (int64_t) 2 * ((int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 256 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16), (int64_t) 8), (int64_t) 8)) + (bytes_10743 + srem64((int64_t) 8 - srem64(bytes_10743, (int64_t) 8), (int64_t) 8)) + (int64_t) 512, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7002, bytes_10743, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10749.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_set_device(ctx, &ext_mem_10753, &mem_10749, "mem_10749") != 0)
                return 1;
        } else {
            int64_t shared_memory_capacity_11488;
            
            shared_memory_capacity_11488 = ctx->max_shared_memory;
            if (suff_outer_par_7479 && sle64((int64_t) 0, shared_memory_capacity_11488)) {
                if (memblock_alloc_device(ctx, &mem_10695, bytes_10694, "mem_10695")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10695.mem, (int64_t) 0, (int64_t []) {(int64_t) 16, (int64_t) 1, (int64_t) 16 * m_6594}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 256, (int64_t) 16, (int64_t) 1}, (int64_t []) {m_6594, (int64_t) 16, (int64_t) 16})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10705, bytes_10578, "mem_10705")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10705.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 16, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, (int64_t) 16})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10736, bytes_10735, "mem_10736")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &color_10859, total_sizze_10889, "color_10859")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_11111 = sext_i64_i32(sdiv_up64(m_6594 * (int64_t) 16, segmap_tblock_sizze_7474));
                
                {
                    err = gpu_kernel_run16zisegmap_7497(ctx, num_tblocks_7475, 1, 1, *ctx->tuning_params.run16zisegmap_tblock_sizze_7114, 1, 1, (int64_t) 0, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, num_tblocks_7475, num_threads_10888, virt_num_tblocks_11111, K_mem_10473.mem, mem_10695.mem, mem_10705.mem, mem_10736.mem, color_10859.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_10695, "mem_10695") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_10705, "mem_10705") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_10741, &mem_10736, "mem_10736") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_11487;
                
                shared_memory_capacity_11487 = ctx->max_shared_memory;
                if (intra_suff_and_fits_7492 && sle64((int64_t) 32 + sdiv_up64(bytes_10673, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11487)) {
                    if (memblock_alloc_device(ctx, &mem_10679, bytes_10583, "mem_10679")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_11130 = sext_i64_i32(sdiv_up64((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7480));
                    int32_t num_chunks_11131 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16, one_intra_par_min_7480));
                    int32_t virt_num_tblocks_11132 = sext_i64_i32(m_6594 * (int64_t) 16);
                    
                    {
                        err = gpu_kernel_run16zisegmap_intrablock_7521(ctx, arg_6655, 1, 1, one_intra_par_min_7480, 1, 1, (int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 16), (int64_t) 8), (int64_t) 8)) + (bytes_10673 + srem64((int64_t) 8 - srem64(bytes_10673, (int64_t) 8), (int64_t) 8)) + (int64_t) 32, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7480, bytes_10673, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10679.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_10680, &mem_10679, "mem_10679") != 0)
                        return 1;
                } else {
                    int64_t shared_memory_capacity_11350;
                    
                    shared_memory_capacity_11350 = ctx->max_shared_memory;
                    if (suff_outer_par_7554 && sle64((int64_t) 544, shared_memory_capacity_11350)) {
                        if (memblock_alloc_device(ctx, &mem_10565, bytes_10478, "mem_10565")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11195 = 1;
                        int32_t virt_num_tblocks_11196 = sext_i64_i32(m_6594 * gridDim_x_9682);
                        
                        {
                            err = gpu_kernel_run16zisegmap_intrablock_9688(ctx, grid_sizze_9685, 1, 1, (int64_t) 64, 1, 1, (int64_t) 544, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, gridDim_x_9682, Q_mem_10472.mem, K_mem_10473.mem, mem_10565.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10569, &mem_10565, "mem_10565") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10479, bytes_10478, "mem_10479")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11250 = (int64_t) 1;
                        
                        if (slt64((int64_t) 32, segred_tblock_sizze_7574 * chunk_sizze_11250)) {
                            int64_t segment_sizze_nonzzero_11251 = smax64((int64_t) 1, (int64_t) 16);
                            int64_t num_threads_11252 = segred_tblock_sizze_7574 * segred_tblock_sizze_7574;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 16, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, squot64(segred_tblock_sizze_7574, segment_sizze_nonzzero_11251))), '\n');
                            {
                                err = gpu_kernel_run16zisegred_small_7582(ctx, num_tblocks_7575, 1, 1, *ctx->tuning_params.run16zisegred_tblock_sizze_7332, 1, 1, (int64_t) 2 * segred_tblock_sizze_7574 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7574, (int64_t) 8), (int64_t) 8), m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, num_tblocks_7575, segment_sizze_nonzzero_11251, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11283 = sdiv_up64(num_tblocks_7575, smax64((int64_t) 1, m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595));
                            int64_t q_11284 = sdiv_up64((int64_t) 16, segred_tblock_sizze_7574 * blocks_per_segment_11283 * chunk_sizze_11250);
                            int64_t num_virtblocks_11285 = blocks_per_segment_11283 * (m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);
                            int64_t threads_per_segment_11286 = blocks_per_segment_11283 * segred_tblock_sizze_7574;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6594 * (int64_t) 16 * dzlz7bUZLztZRz20Umz20U16z7dUzg_6595), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 16, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11285, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_7575, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_7574, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11284, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11283, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11287, (int64_t) 2 * num_virtblocks_11285, "segred_tmp_mem_11287")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run16zisegred_large_7582(ctx, num_tblocks_7575, 1, 1, *ctx->tuning_params.run16zisegred_tblock_sizze_7332, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_7574 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7574, (int64_t) 8), (int64_t) 8)), m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, num_tblocks_7575, blocks_per_segment_11283, q_11284, num_virtblocks_11285, threads_per_segment_11286, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem, segred_tmp_mem_11287.mem, counters_mem_11289.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10569, &mem_10479, "mem_10479") != 0)
                            return 1;
                    }
                    
                    int64_t shared_memory_capacity_11486;
                    
                    shared_memory_capacity_11486 = ctx->max_shared_memory;
                    if (suff_outer_par_7601 && sle64((int64_t) 512, shared_memory_capacity_11486)) {
                        if (memblock_alloc_device(ctx, &mem_10670, bytes_10583, "mem_10670")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11351 = 1;
                        int32_t virt_num_tblocks_11352 = sext_i64_i32(m_6594);
                        
                        {
                            err = gpu_kernel_run16zisegmap_intrablock_10048(ctx, m_6594, 1, 1, (int64_t) 64, 1, 1, (int64_t) 512, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7480, full_tiles_10076, kk_10234, V_mem_10474.mem, ext_mem_10569.mem, mem_10670.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10671, &mem_10670, "mem_10670") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10579, bytes_10578, "mem_10579")) {
                            err = 1;
                            goto cleanup;
                        }
                        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10579.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 16, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, (int64_t) 16})) != 0)
                            goto cleanup;
                        if (memblock_alloc_device(ctx, &mem_10584, bytes_10583, "mem_10584")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11406 = (int64_t) 1;
                        
                        if (slt64(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 * (int64_t) 2, segred_tblock_sizze_7621 * chunk_sizze_11406)) {
                            int64_t segment_sizze_nonzzero_11407 = smax64((int64_t) 1, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);
                            int64_t num_threads_11408 = segred_tblock_sizze_7621 * segred_tblock_sizze_7621;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6594 * (int64_t) 16 * (int64_t) 16), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6594 * (int64_t) 16 * (int64_t) 16, squot64(segred_tblock_sizze_7621, segment_sizze_nonzzero_11407))), '\n');
                            {
                                err = gpu_kernel_run16zisegred_small_7629(ctx, num_tblocks_7622, 1, 1, *ctx->tuning_params.run16zisegred_tblock_sizze_7253, 1, 1, (int64_t) 2 * segred_tblock_sizze_7621 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7621, (int64_t) 8), (int64_t) 8), m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7480, num_tblocks_7622, segment_sizze_nonzzero_11407, ext_mem_10569.mem, mem_10579.mem, mem_10584.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11439 = sdiv_up64(num_tblocks_7622, smax64((int64_t) 1, m_6594 * (int64_t) 16 * (int64_t) 16));
                            int64_t q_11440 = sdiv_up64(dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, segred_tblock_sizze_7621 * blocks_per_segment_11439 * chunk_sizze_11406);
                            int64_t num_virtblocks_11441 = blocks_per_segment_11439 * (m_6594 * (int64_t) 16 * (int64_t) 16);
                            int64_t threads_per_segment_11442 = blocks_per_segment_11439 * segred_tblock_sizze_7621;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6594 * (int64_t) 16 * (int64_t) 16), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11441, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_7622, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_7621, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11440, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11439, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11443, (int64_t) 2 * num_virtblocks_11441, "segred_tmp_mem_11443")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run16zisegred_large_7629(ctx, num_tblocks_7622, 1, 1, *ctx->tuning_params.run16zisegred_tblock_sizze_7253, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_7621 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_7621, (int64_t) 8), (int64_t) 8)), m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595, one_intra_par_min_7480, num_tblocks_7622, blocks_per_segment_11439, q_11440, num_virtblocks_11441, threads_per_segment_11442, ext_mem_10569.mem, mem_10579.mem, mem_10584.mem, segred_tmp_mem_11443.mem, counters_mem_11445.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_10579, "mem_10579") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_10671, &mem_10584, "mem_10584") != 0)
                            return 1;
                    }
                    if (memblock_unref_device(ctx, &ext_mem_10569, "ext_mem_10569") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_10680, &ext_mem_10671, "ext_mem_10671") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_10741, &ext_mem_10680, "ext_mem_10680") != 0)
                    return 1;
            }
            if (memblock_set_device(ctx, &ext_mem_10753, &ext_mem_10741, "ext_mem_10741") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_10825, &ext_mem_10753, "ext_mem_10753") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_10829, bytes_10583, "mem_10829")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10829.mem, (int64_t) 0, (int64_t []) {(int64_t) 256, (int64_t) 16, (int64_t) 1}, ext_mem_10825.mem, (int64_t) 0, (int64_t []) {ext_10824, ext_10823, ext_10822}, (int64_t []) {m_6594, (int64_t) 16, (int64_t) 16})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_10825, "ext_mem_10825") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_11010, &mem_10829, "mem_10829") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_11496, &mem_out_11010, "mem_out_11010") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_10829, "mem_10829") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11443, "segred_tmp_mem_11443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10584, "mem_10584") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10579, "mem_10579") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10670, "mem_10670") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10671, "ext_mem_10671") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11287, "segred_tmp_mem_11287") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10479, "mem_10479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10565, "mem_10565") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10569, "ext_mem_10569") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10679, "mem_10679") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10680, "ext_mem_10680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10736, "mem_10736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10705, "mem_10705") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10695, "mem_10695") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10741, "ext_mem_10741") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10749, "mem_10749") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10753, "ext_mem_10753") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10820, "mem_10820") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10778, "mem_10778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10768, "mem_10768") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10825, "ext_mem_10825") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11010, "mem_out_11010") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_run32(struct futhark_context *ctx, struct memblock_device *mem_out_p_11497, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6610, int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_10829;
    
    mem_10829.references = NULL;
    
    struct memblock_device segred_tmp_mem_11443;
    
    segred_tmp_mem_11443.references = NULL;
    
    struct memblock_device mem_10584;
    
    mem_10584.references = NULL;
    
    struct memblock_device mem_10579;
    
    mem_10579.references = NULL;
    
    struct memblock_device mem_10670;
    
    mem_10670.references = NULL;
    
    struct memblock_device ext_mem_10671;
    
    ext_mem_10671.references = NULL;
    
    struct memblock_device segred_tmp_mem_11287;
    
    segred_tmp_mem_11287.references = NULL;
    
    struct memblock_device mem_10479;
    
    mem_10479.references = NULL;
    
    struct memblock_device mem_10565;
    
    mem_10565.references = NULL;
    
    struct memblock_device ext_mem_10569;
    
    ext_mem_10569.references = NULL;
    
    struct memblock_device mem_10679;
    
    mem_10679.references = NULL;
    
    struct memblock_device ext_mem_10680;
    
    ext_mem_10680.references = NULL;
    
    struct memblock_device color_10859;
    
    color_10859.references = NULL;
    
    struct memblock_device mem_10736;
    
    mem_10736.references = NULL;
    
    struct memblock_device mem_10705;
    
    mem_10705.references = NULL;
    
    struct memblock_device mem_10695;
    
    mem_10695.references = NULL;
    
    struct memblock_device ext_mem_10741;
    
    ext_mem_10741.references = NULL;
    
    struct memblock_device mem_10749;
    
    mem_10749.references = NULL;
    
    struct memblock_device ext_mem_10753;
    
    ext_mem_10753.references = NULL;
    
    struct memblock_device color_10856;
    
    color_10856.references = NULL;
    
    struct memblock_device mem_10820;
    
    mem_10820.references = NULL;
    
    struct memblock_device mem_10778;
    
    mem_10778.references = NULL;
    
    struct memblock_device mem_10768;
    
    mem_10768.references = NULL;
    
    struct memblock_device ext_mem_10825;
    
    ext_mem_10825.references = NULL;
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t arg_6655 = mul64((int64_t) 32, m_6610);
    bool assert_cond_6656 = arg_6655 == dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;
    bool assert_c_6657;
    
    if (!assert_cond_6656) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "Assertion is false: entry point arguments have invalid sizes.", "-> #0  ./custom_attention_like_expanded.fut:51:3-23\n   #1  ./custom_attention_like_expanded.fut:50:1-51:23\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_10583 = (int64_t) 2048 * m_6610;
    bool suff_outer_par_7691;
    
    suff_outer_par_7691 = *ctx->tuning_params.run32zisuff_outer_par_0 <= m_6610;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run32.suff_outer_par_0", (long) m_6610, suff_outer_par_7691 ? "true" : "false");
    
    int64_t one_intra_par_min_7680 = (int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;
    int64_t intra_avail_par_7687 = smin64(one_intra_par_min_7680, one_intra_par_min_7680);
    int64_t max_tblock_sizze_7753;
    
    max_tblock_sizze_7753 = ctx->max_thread_block_size;
    
    bool fits_7754 = sle64(one_intra_par_min_7680, max_tblock_sizze_7753);
    bool suff_intra_par_7752;
    
    suff_intra_par_7752 = *ctx->tuning_params.run32zisuff_intra_par_1 <= intra_avail_par_7687;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run32.suff_intra_par_1", (long) intra_avail_par_7687, suff_intra_par_7752 ? "true" : "false");
    
    bool intra_suff_and_fits_7755 = suff_intra_par_7752 && fits_7754;
    int64_t segmap_tblock_sizze_8152;
    
    segmap_tblock_sizze_8152 = *ctx->tuning_params.run32zisegmap_tblock_sizze_7792;
    
    int64_t num_tblocks_8153;
    int64_t max_num_tblocks_11011;
    
    max_num_tblocks_11011 = *ctx->tuning_params.run32zisegmap_num_tblocks_7794;
    num_tblocks_8153 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_6655, segmap_tblock_sizze_8152), max_num_tblocks_11011)));
    
    bool suff_outer_par_8157;
    
    suff_outer_par_8157 = *ctx->tuning_params.run32zisuff_outer_par_2 <= arg_6655;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run32.suff_outer_par_2", (long) arg_6655, suff_outer_par_8157 ? "true" : "false");
    
    int64_t one_intra_par_min_8158 = (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;
    int64_t intra_avail_par_8162 = smin64(one_intra_par_min_8158, one_intra_par_min_8158);
    bool fits_8167 = sle64(one_intra_par_min_8158, max_tblock_sizze_7753);
    bool suff_intra_par_8169;
    
    suff_intra_par_8169 = *ctx->tuning_params.run32zisuff_intra_par_3 <= intra_avail_par_8162;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run32.suff_intra_par_3", (long) intra_avail_par_8162, suff_intra_par_8169 ? "true" : "false");
    
    bool intra_suff_and_fits_8170 = fits_8167 && suff_intra_par_8169;
    int64_t comparatee_8231 = m_6610 * one_intra_par_min_8158;
    bool suff_outer_par_8232;
    
    suff_outer_par_8232 = *ctx->tuning_params.run32zisuff_outer_par_5 <= comparatee_8231;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run32.suff_outer_par_5", (long) comparatee_8231, suff_outer_par_8232 ? "true" : "false");
    
    int64_t nest_sizze_8251 = (int64_t) 32 * comparatee_8231;
    int64_t segred_tblock_sizze_8252;
    
    segred_tblock_sizze_8252 = *ctx->tuning_params.run32zisegred_tblock_sizze_8010;
    
    int64_t num_tblocks_8253;
    int64_t max_num_tblocks_11012;
    
    max_num_tblocks_11012 = *ctx->tuning_params.run32zisegred_num_tblocks_8012;
    num_tblocks_8253 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_8251, segred_tblock_sizze_8252), max_num_tblocks_11012)));
    
    int64_t comparatee_8278 = (int64_t) 1024 * m_6610;
    bool suff_outer_par_8279;
    
    suff_outer_par_8279 = *ctx->tuning_params.run32zisuff_outer_par_4 <= comparatee_8278;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run32.suff_outer_par_4", (long) comparatee_8278, suff_outer_par_8279 ? "true" : "false");
    
    int64_t nest_sizze_8298 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * comparatee_8278;
    int64_t segred_tblock_sizze_8299;
    
    segred_tblock_sizze_8299 = *ctx->tuning_params.run32zisegred_tblock_sizze_7931;
    
    int64_t num_tblocks_8300;
    int64_t max_num_tblocks_11013;
    
    max_num_tblocks_11013 = *ctx->tuning_params.run32zisegred_num_tblocks_7933;
    num_tblocks_8300 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_8298, segred_tblock_sizze_8299), max_num_tblocks_11013)));
    
    int64_t segmap_tblock_sizze_7724;
    
    segmap_tblock_sizze_7724 = *ctx->tuning_params.run32zisegmap_tblock_sizze_7695;
    
    int64_t num_tblocks_7725;
    int64_t max_num_tblocks_11014;
    
    max_num_tblocks_11014 = *ctx->tuning_params.run32zisegmap_num_tblocks_7697;
    num_tblocks_7725 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_6610, segmap_tblock_sizze_7724), max_num_tblocks_11014)));
    
    int64_t gridDim_x_9682 = sdiv_up64(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, (int64_t) 32);
    int64_t grid_sizze_9685 = m_6610 * gridDim_x_9682;
    int64_t full_tiles_10076 = squot64(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, (int64_t) 8);
    int64_t kk_10234 = (int64_t) 8 * full_tiles_10076;
    int64_t ext_10740;
    int64_t shared_memory_capacity_11015;
    
    shared_memory_capacity_11015 = ctx->max_shared_memory;
    if (suff_outer_par_8157) {
        ext_10740 = (int64_t) 32;
    } else {
        ext_10740 = (int64_t) 1024;
    }
    
    int64_t ext_10739;
    int64_t shared_memory_capacity_11016;
    
    shared_memory_capacity_11016 = ctx->max_shared_memory;
    if (suff_outer_par_8157) {
        ext_10739 = (int64_t) 1;
    } else {
        ext_10739 = (int64_t) 32;
    }
    
    int64_t binop_x_10477 = (int64_t) 64 * m_6610;
    int64_t bytes_10478 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * binop_x_10477;
    int64_t binop_y_10570 = dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 - (int64_t) 1;
    int64_t binop_x_10572 = smax64((int64_t) 0, binop_y_10570);
    int64_t binop_y_10574 = (int64_t) 31 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;
    int64_t binop_y_10575 = smax64((int64_t) 0, binop_y_10574);
    int64_t binop_y_10576 = binop_x_10572 + binop_y_10575;
    int64_t binop_y_10577 = (int64_t) 1 + binop_y_10576;
    int64_t bytes_10578 = (int64_t) 2 * binop_y_10577;
    int64_t bytes_10673 = (int64_t) 2 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;
    int64_t binop_y_10681 = m_6610 - (int64_t) 1;
    int64_t binop_x_10682 = smax64((int64_t) 0, binop_y_10681);
    int64_t binop_y_10683 = (int64_t) 32 * binop_x_10682;
    int64_t binop_x_10684 = smax64((int64_t) 0, binop_y_10683);
    int64_t binop_x_10687 = (int64_t) 31 + binop_x_10684;
    int64_t binop_y_10690 = (int64_t) 992 * m_6610;
    int64_t binop_y_10691 = smax64((int64_t) 0, binop_y_10690);
    int64_t binop_y_10692 = binop_x_10687 + binop_y_10691;
    int64_t binop_y_10693 = (int64_t) 1 + binop_y_10692;
    int64_t bytes_10694 = (int64_t) 2 * binop_y_10693;
    int64_t binop_x_10728 = (int64_t) 31 + binop_x_10684;
    int64_t binop_y_10733 = binop_y_10691 + binop_x_10728;
    int64_t binop_y_10734 = (int64_t) 1 + binop_y_10733;
    int64_t bytes_10735 = (int64_t) 2 * binop_y_10734;
    int64_t bytes_10743 = (int64_t) 64 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611;
    int64_t binop_x_10761 = binop_x_10682 + binop_y_10691;
    int64_t binop_y_10763 = (int64_t) 31 * m_6610;
    int64_t binop_y_10764 = smax64((int64_t) 0, binop_y_10763);
    int64_t binop_y_10765 = binop_x_10761 + binop_y_10764;
    int64_t binop_y_10766 = (int64_t) 1 + binop_y_10765;
    int64_t bytes_10767 = (int64_t) 2 * binop_y_10766;
    int64_t binop_y_10818 = (int64_t) 1 + binop_y_10765;
    int64_t bytes_10819 = (int64_t) 2 * binop_y_10818;
    int64_t ext_10752;
    int64_t shared_memory_capacity_11017;
    
    shared_memory_capacity_11017 = ctx->max_shared_memory;
    if (intra_suff_and_fits_7755) {
        ext_10752 = (int64_t) 1024;
    } else {
        ext_10752 = ext_10740;
    }
    
    int64_t ext_10751;
    int64_t shared_memory_capacity_11018;
    
    shared_memory_capacity_11018 = ctx->max_shared_memory;
    if (intra_suff_and_fits_7755) {
        ext_10751 = (int64_t) 32;
    } else {
        ext_10751 = ext_10739;
    }
    
    int64_t ext_10738;
    int64_t shared_memory_capacity_11019;
    
    shared_memory_capacity_11019 = ctx->max_shared_memory;
    if (suff_outer_par_8157) {
        ext_10738 = arg_6655;
    } else {
        ext_10738 = (int64_t) 1;
    }
    
    int64_t ext_10824;
    int64_t shared_memory_capacity_11020;
    
    shared_memory_capacity_11020 = ctx->max_shared_memory;
    if (suff_outer_par_7691) {
        ext_10824 = (int64_t) 1;
    } else {
        ext_10824 = ext_10752;
    }
    
    int64_t ext_10823;
    int64_t shared_memory_capacity_11021;
    
    shared_memory_capacity_11021 = ctx->max_shared_memory;
    if (suff_outer_par_7691) {
        ext_10823 = arg_6655;
    } else {
        ext_10823 = ext_10751;
    }
    
    int64_t ext_10750;
    int64_t shared_memory_capacity_11022;
    
    shared_memory_capacity_11022 = ctx->max_shared_memory;
    if (intra_suff_and_fits_7755) {
        ext_10750 = (int64_t) 1;
    } else {
        ext_10750 = ext_10738;
    }
    
    int64_t ext_10822;
    int64_t shared_memory_capacity_11023;
    
    shared_memory_capacity_11023 = ctx->max_shared_memory;
    if (suff_outer_par_7691) {
        ext_10822 = m_6610;
    } else {
        ext_10822 = ext_10750;
    }
    
    int64_t num_threads_10924 = segmap_tblock_sizze_8152 * num_tblocks_8153;
    int64_t total_sizze_10925 = bytes_10673 * num_threads_10924;
    int64_t num_threads_10902 = segmap_tblock_sizze_7724 * num_tblocks_7725;
    int64_t total_sizze_10903 = bytes_10673 * num_threads_10902;
    int64_t shared_memory_capacity_11490;
    
    shared_memory_capacity_11490 = ctx->max_shared_memory;
    if (suff_outer_par_7691 && sle64((int64_t) 0, shared_memory_capacity_11490)) {
        if (memblock_alloc_device(ctx, &mem_10768, bytes_10767, "mem_10768")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10768.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_6610 * (int64_t) 32, m_6610}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 1024, (int64_t) 32, (int64_t) 1}, (int64_t []) {m_6610, (int64_t) 32, (int64_t) 32})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10778, bytes_10578, "mem_10778")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10778.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 32, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, (int64_t) 32})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10820, bytes_10819, "mem_10820")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &color_10856, total_sizze_10903, "color_10856")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_11024 = sext_i64_i32(sdiv_up64(m_6610, segmap_tblock_sizze_7724));
        
        {
            err = gpu_kernel_run32zisegmap_7729(ctx, num_tblocks_7725, 1, 1, *ctx->tuning_params.run32zisegmap_tblock_sizze_7695, 1, 1, (int64_t) 0, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, num_tblocks_7725, num_threads_10902, virt_num_tblocks_11024, K_mem_10473.mem, mem_10768.mem, mem_10778.mem, mem_10820.mem, color_10856.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_10768, "mem_10768") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10778, "mem_10778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_10825, &mem_10820, "mem_10820") != 0)
            return 1;
    } else {
        int64_t shared_memory_capacity_11489;
        
        shared_memory_capacity_11489 = ctx->max_shared_memory;
        if (intra_suff_and_fits_7755 && sle64((int64_t) 2048 + sdiv_up64(bytes_10743, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11489)) {
            if (memblock_alloc_device(ctx, &mem_10749, bytes_10583, "mem_10749")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t num_chunks_11042 = sext_i64_i32(sdiv_up64((int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_7680));
            int32_t num_chunks_11043 = sext_i64_i32(sdiv_up64((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32, one_intra_par_min_7680));
            int32_t virt_num_tblocks_11044 = sext_i64_i32(m_6610);
            
            {
                err = gpu_kernel_run32zisegmap_intrablock_7758(ctx, m_6610, 1, 1, one_intra_par_min_7680, 1, 1, (int64_t) 2 * ((int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 1024 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32), (int64_t) 8), (int64_t) 8)) + (bytes_10743 + srem64((int64_t) 8 - srem64(bytes_10743, (int64_t) 8), (int64_t) 8)) + (int64_t) 2048, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_7680, bytes_10743, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10749.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_set_device(ctx, &ext_mem_10753, &mem_10749, "mem_10749") != 0)
                return 1;
        } else {
            int64_t shared_memory_capacity_11488;
            
            shared_memory_capacity_11488 = ctx->max_shared_memory;
            if (suff_outer_par_8157 && sle64((int64_t) 0, shared_memory_capacity_11488)) {
                if (memblock_alloc_device(ctx, &mem_10695, bytes_10694, "mem_10695")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10695.mem, (int64_t) 0, (int64_t []) {(int64_t) 32, (int64_t) 1, (int64_t) 32 * m_6610}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 1024, (int64_t) 32, (int64_t) 1}, (int64_t []) {m_6610, (int64_t) 32, (int64_t) 32})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10705, bytes_10578, "mem_10705")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10705.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 32, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, (int64_t) 32})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10736, bytes_10735, "mem_10736")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &color_10859, total_sizze_10925, "color_10859")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_11111 = sext_i64_i32(sdiv_up64(m_6610 * (int64_t) 32, segmap_tblock_sizze_8152));
                
                {
                    err = gpu_kernel_run32zisegmap_8175(ctx, num_tblocks_8153, 1, 1, *ctx->tuning_params.run32zisegmap_tblock_sizze_7792, 1, 1, (int64_t) 0, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, num_tblocks_8153, num_threads_10924, virt_num_tblocks_11111, K_mem_10473.mem, mem_10695.mem, mem_10705.mem, mem_10736.mem, color_10859.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_10695, "mem_10695") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_10705, "mem_10705") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_10741, &mem_10736, "mem_10736") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_11487;
                
                shared_memory_capacity_11487 = ctx->max_shared_memory;
                if (intra_suff_and_fits_8170 && sle64((int64_t) 64 + sdiv_up64(bytes_10673, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11487)) {
                    if (memblock_alloc_device(ctx, &mem_10679, bytes_10583, "mem_10679")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_11130 = sext_i64_i32(sdiv_up64((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_8158));
                    int32_t num_chunks_11131 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32, one_intra_par_min_8158));
                    int32_t virt_num_tblocks_11132 = sext_i64_i32(m_6610 * (int64_t) 32);
                    
                    {
                        err = gpu_kernel_run32zisegmap_intrablock_8199(ctx, arg_6655, 1, 1, one_intra_par_min_8158, 1, 1, (int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 32), (int64_t) 8), (int64_t) 8)) + (bytes_10673 + srem64((int64_t) 8 - srem64(bytes_10673, (int64_t) 8), (int64_t) 8)) + (int64_t) 64, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_8158, bytes_10673, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10679.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_10680, &mem_10679, "mem_10679") != 0)
                        return 1;
                } else {
                    int64_t shared_memory_capacity_11350;
                    
                    shared_memory_capacity_11350 = ctx->max_shared_memory;
                    if (suff_outer_par_8232 && sle64((int64_t) 1088, shared_memory_capacity_11350)) {
                        if (memblock_alloc_device(ctx, &mem_10565, bytes_10478, "mem_10565")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11195 = 1;
                        int32_t virt_num_tblocks_11196 = sext_i64_i32(m_6610 * gridDim_x_9682);
                        
                        {
                            err = gpu_kernel_run32zisegmap_intrablock_9688(ctx, grid_sizze_9685, 1, 1, (int64_t) 64, 1, 1, (int64_t) 1088, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, gridDim_x_9682, Q_mem_10472.mem, K_mem_10473.mem, mem_10565.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10569, &mem_10565, "mem_10565") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10479, bytes_10478, "mem_10479")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11250 = (int64_t) 1;
                        
                        if (slt64((int64_t) 64, segred_tblock_sizze_8252 * chunk_sizze_11250)) {
                            int64_t segment_sizze_nonzzero_11251 = smax64((int64_t) 1, (int64_t) 32);
                            int64_t num_threads_11252 = segred_tblock_sizze_8252 * segred_tblock_sizze_8252;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 32, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, squot64(segred_tblock_sizze_8252, segment_sizze_nonzzero_11251))), '\n');
                            {
                                err = gpu_kernel_run32zisegred_small_8260(ctx, num_tblocks_8253, 1, 1, *ctx->tuning_params.run32zisegred_tblock_sizze_8010, 1, 1, (int64_t) 2 * segred_tblock_sizze_8252 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8252, (int64_t) 8), (int64_t) 8), m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, num_tblocks_8253, segment_sizze_nonzzero_11251, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11283 = sdiv_up64(num_tblocks_8253, smax64((int64_t) 1, m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611));
                            int64_t q_11284 = sdiv_up64((int64_t) 32, segred_tblock_sizze_8252 * blocks_per_segment_11283 * chunk_sizze_11250);
                            int64_t num_virtblocks_11285 = blocks_per_segment_11283 * (m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);
                            int64_t threads_per_segment_11286 = blocks_per_segment_11283 * segred_tblock_sizze_8252;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6610 * (int64_t) 32 * dzlz7bUZLztZRz20Umz20U32z7dUzg_6611), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 32, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11285, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_8253, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_8252, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11284, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11283, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11287, (int64_t) 2 * num_virtblocks_11285, "segred_tmp_mem_11287")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run32zisegred_large_8260(ctx, num_tblocks_8253, 1, 1, *ctx->tuning_params.run32zisegred_tblock_sizze_8010, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_8252 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8252, (int64_t) 8), (int64_t) 8)), m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, num_tblocks_8253, blocks_per_segment_11283, q_11284, num_virtblocks_11285, threads_per_segment_11286, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem, segred_tmp_mem_11287.mem, counters_mem_11289.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10569, &mem_10479, "mem_10479") != 0)
                            return 1;
                    }
                    
                    int64_t shared_memory_capacity_11486;
                    
                    shared_memory_capacity_11486 = ctx->max_shared_memory;
                    if (suff_outer_par_8279 && sle64((int64_t) 1024, shared_memory_capacity_11486)) {
                        if (memblock_alloc_device(ctx, &mem_10670, bytes_10583, "mem_10670")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11351 = 1;
                        int32_t virt_num_tblocks_11352 = sext_i64_i32(m_6610);
                        
                        {
                            err = gpu_kernel_run32zisegmap_intrablock_10048(ctx, m_6610, 1, 1, (int64_t) 64, 1, 1, (int64_t) 1024, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_8158, full_tiles_10076, kk_10234, V_mem_10474.mem, ext_mem_10569.mem, mem_10670.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10671, &mem_10670, "mem_10670") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10579, bytes_10578, "mem_10579")) {
                            err = 1;
                            goto cleanup;
                        }
                        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10579.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 32, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, (int64_t) 32})) != 0)
                            goto cleanup;
                        if (memblock_alloc_device(ctx, &mem_10584, bytes_10583, "mem_10584")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11406 = (int64_t) 1;
                        
                        if (slt64(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 * (int64_t) 2, segred_tblock_sizze_8299 * chunk_sizze_11406)) {
                            int64_t segment_sizze_nonzzero_11407 = smax64((int64_t) 1, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);
                            int64_t num_threads_11408 = segred_tblock_sizze_8299 * segred_tblock_sizze_8299;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6610 * (int64_t) 32 * (int64_t) 32), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6610 * (int64_t) 32 * (int64_t) 32, squot64(segred_tblock_sizze_8299, segment_sizze_nonzzero_11407))), '\n');
                            {
                                err = gpu_kernel_run32zisegred_small_8307(ctx, num_tblocks_8300, 1, 1, *ctx->tuning_params.run32zisegred_tblock_sizze_7931, 1, 1, (int64_t) 2 * segred_tblock_sizze_8299 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8299, (int64_t) 8), (int64_t) 8), m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_8158, num_tblocks_8300, segment_sizze_nonzzero_11407, ext_mem_10569.mem, mem_10579.mem, mem_10584.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11439 = sdiv_up64(num_tblocks_8300, smax64((int64_t) 1, m_6610 * (int64_t) 32 * (int64_t) 32));
                            int64_t q_11440 = sdiv_up64(dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, segred_tblock_sizze_8299 * blocks_per_segment_11439 * chunk_sizze_11406);
                            int64_t num_virtblocks_11441 = blocks_per_segment_11439 * (m_6610 * (int64_t) 32 * (int64_t) 32);
                            int64_t threads_per_segment_11442 = blocks_per_segment_11439 * segred_tblock_sizze_8299;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6610 * (int64_t) 32 * (int64_t) 32), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11441, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_8300, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_8299, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11440, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11439, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11443, (int64_t) 2 * num_virtblocks_11441, "segred_tmp_mem_11443")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run32zisegred_large_8307(ctx, num_tblocks_8300, 1, 1, *ctx->tuning_params.run32zisegred_tblock_sizze_7931, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_8299 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8299, (int64_t) 8), (int64_t) 8)), m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611, one_intra_par_min_8158, num_tblocks_8300, blocks_per_segment_11439, q_11440, num_virtblocks_11441, threads_per_segment_11442, ext_mem_10569.mem, mem_10579.mem, mem_10584.mem, segred_tmp_mem_11443.mem, counters_mem_11445.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_10579, "mem_10579") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_10671, &mem_10584, "mem_10584") != 0)
                            return 1;
                    }
                    if (memblock_unref_device(ctx, &ext_mem_10569, "ext_mem_10569") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_10680, &ext_mem_10671, "ext_mem_10671") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_10741, &ext_mem_10680, "ext_mem_10680") != 0)
                    return 1;
            }
            if (memblock_set_device(ctx, &ext_mem_10753, &ext_mem_10741, "ext_mem_10741") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_10825, &ext_mem_10753, "ext_mem_10753") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_10829, bytes_10583, "mem_10829")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10829.mem, (int64_t) 0, (int64_t []) {(int64_t) 1024, (int64_t) 32, (int64_t) 1}, ext_mem_10825.mem, (int64_t) 0, (int64_t []) {ext_10824, ext_10823, ext_10822}, (int64_t []) {m_6610, (int64_t) 32, (int64_t) 32})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_10825, "ext_mem_10825") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_11010, &mem_10829, "mem_10829") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_11497, &mem_out_11010, "mem_out_11010") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_10829, "mem_10829") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11443, "segred_tmp_mem_11443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10584, "mem_10584") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10579, "mem_10579") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10670, "mem_10670") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10671, "ext_mem_10671") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11287, "segred_tmp_mem_11287") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10479, "mem_10479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10565, "mem_10565") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10569, "ext_mem_10569") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10679, "mem_10679") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10680, "ext_mem_10680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10736, "mem_10736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10705, "mem_10705") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10695, "mem_10695") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10741, "ext_mem_10741") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10749, "mem_10749") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10753, "ext_mem_10753") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10820, "mem_10820") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10778, "mem_10778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10768, "mem_10768") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10825, "ext_mem_10825") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11010, "mem_out_11010") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_run64(struct futhark_context *ctx, struct memblock_device *mem_out_p_11498, struct memblock_device Q_mem_10472, struct memblock_device K_mem_10473, struct memblock_device V_mem_10474, int64_t m_6626, int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_10849;
    
    mem_10849.references = NULL;
    
    struct memblock_device segred_tmp_mem_11443;
    
    segred_tmp_mem_11443.references = NULL;
    
    struct memblock_device mem_10594;
    
    mem_10594.references = NULL;
    
    struct memblock_device mem_10589;
    
    mem_10589.references = NULL;
    
    struct memblock_device mem_10690;
    
    mem_10690.references = NULL;
    
    struct memblock_device ext_mem_10691;
    
    ext_mem_10691.references = NULL;
    
    struct memblock_device segred_tmp_mem_11287;
    
    segred_tmp_mem_11287.references = NULL;
    
    struct memblock_device mem_10479;
    
    mem_10479.references = NULL;
    
    struct memblock_device mem_10575;
    
    mem_10575.references = NULL;
    
    struct memblock_device ext_mem_10579;
    
    ext_mem_10579.references = NULL;
    
    struct memblock_device mem_10699;
    
    mem_10699.references = NULL;
    
    struct memblock_device ext_mem_10700;
    
    ext_mem_10700.references = NULL;
    
    struct memblock_device color_10859;
    
    color_10859.references = NULL;
    
    struct memblock_device mem_10756;
    
    mem_10756.references = NULL;
    
    struct memblock_device mem_10725;
    
    mem_10725.references = NULL;
    
    struct memblock_device mem_10715;
    
    mem_10715.references = NULL;
    
    struct memblock_device ext_mem_10761;
    
    ext_mem_10761.references = NULL;
    
    struct memblock_device mem_10769;
    
    mem_10769.references = NULL;
    
    struct memblock_device ext_mem_10773;
    
    ext_mem_10773.references = NULL;
    
    struct memblock_device color_10856;
    
    color_10856.references = NULL;
    
    struct memblock_device mem_10840;
    
    mem_10840.references = NULL;
    
    struct memblock_device mem_10798;
    
    mem_10798.references = NULL;
    
    struct memblock_device mem_10788;
    
    mem_10788.references = NULL;
    
    struct memblock_device ext_mem_10845;
    
    ext_mem_10845.references = NULL;
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
    struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
    int64_t arg_6655 = mul64((int64_t) 64, m_6626);
    bool assert_cond_6656 = arg_6655 == dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;
    bool assert_c_6657;
    
    if (!assert_cond_6656) {
        set_error(ctx, msgprintf("Error: %s\n\nBacktrace:\n%s", "Assertion is false: entry point arguments have invalid sizes.", "-> #0  ./custom_attention_like_expanded.fut:54:3-23\n   #1  ./custom_attention_like_expanded.fut:53:1-54:23\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_10593 = (int64_t) 8192 * m_6626;
    bool suff_outer_par_8369;
    
    suff_outer_par_8369 = *ctx->tuning_params.run64zisuff_outer_par_0 <= m_6626;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run64.suff_outer_par_0", (long) m_6626, suff_outer_par_8369 ? "true" : "false");
    
    int64_t one_intra_par_min_8358 = (int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;
    int64_t intra_avail_par_8365 = smin64(one_intra_par_min_8358, one_intra_par_min_8358);
    int64_t max_tblock_sizze_8431;
    
    max_tblock_sizze_8431 = ctx->max_thread_block_size;
    
    bool fits_8432 = sle64(one_intra_par_min_8358, max_tblock_sizze_8431);
    bool suff_intra_par_8430;
    
    suff_intra_par_8430 = *ctx->tuning_params.run64zisuff_intra_par_1 <= intra_avail_par_8365;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run64.suff_intra_par_1", (long) intra_avail_par_8365, suff_intra_par_8430 ? "true" : "false");
    
    bool intra_suff_and_fits_8433 = suff_intra_par_8430 && fits_8432;
    int64_t segmap_tblock_sizze_8830;
    
    segmap_tblock_sizze_8830 = *ctx->tuning_params.run64zisegmap_tblock_sizze_8470;
    
    int64_t num_tblocks_8831;
    int64_t max_num_tblocks_11011;
    
    max_num_tblocks_11011 = *ctx->tuning_params.run64zisegmap_num_tblocks_8472;
    num_tblocks_8831 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(arg_6655, segmap_tblock_sizze_8830), max_num_tblocks_11011)));
    
    bool suff_outer_par_8835;
    
    suff_outer_par_8835 = *ctx->tuning_params.run64zisuff_outer_par_2 <= arg_6655;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run64.suff_outer_par_2", (long) arg_6655, suff_outer_par_8835 ? "true" : "false");
    
    int64_t one_intra_par_min_8836 = (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;
    int64_t intra_avail_par_8840 = smin64(one_intra_par_min_8836, one_intra_par_min_8836);
    bool fits_8845 = sle64(one_intra_par_min_8836, max_tblock_sizze_8431);
    bool suff_intra_par_8847;
    
    suff_intra_par_8847 = *ctx->tuning_params.run64zisuff_intra_par_3 <= intra_avail_par_8840;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run64.suff_intra_par_3", (long) intra_avail_par_8840, suff_intra_par_8847 ? "true" : "false");
    
    bool intra_suff_and_fits_8848 = fits_8845 && suff_intra_par_8847;
    int64_t comparatee_8909 = m_6626 * one_intra_par_min_8836;
    bool suff_outer_par_8910;
    
    suff_outer_par_8910 = *ctx->tuning_params.run64zisuff_outer_par_5 <= comparatee_8909;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run64.suff_outer_par_5", (long) comparatee_8909, suff_outer_par_8910 ? "true" : "false");
    
    int64_t nest_sizze_8929 = (int64_t) 64 * comparatee_8909;
    int64_t segred_tblock_sizze_8930;
    
    segred_tblock_sizze_8930 = *ctx->tuning_params.run64zisegred_tblock_sizze_8688;
    
    int64_t num_tblocks_8931;
    int64_t max_num_tblocks_11012;
    
    max_num_tblocks_11012 = *ctx->tuning_params.run64zisegred_num_tblocks_8690;
    num_tblocks_8931 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_8929, segred_tblock_sizze_8930), max_num_tblocks_11012)));
    
    int64_t comparatee_8956 = (int64_t) 4096 * m_6626;
    bool suff_outer_par_8957;
    
    suff_outer_par_8957 = *ctx->tuning_params.run64zisuff_outer_par_4 <= comparatee_8956;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "run64.suff_outer_par_4", (long) comparatee_8956, suff_outer_par_8957 ? "true" : "false");
    
    int64_t nest_sizze_8976 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * comparatee_8956;
    int64_t segred_tblock_sizze_8977;
    
    segred_tblock_sizze_8977 = *ctx->tuning_params.run64zisegred_tblock_sizze_8609;
    
    int64_t num_tblocks_8978;
    int64_t max_num_tblocks_11013;
    
    max_num_tblocks_11013 = *ctx->tuning_params.run64zisegred_num_tblocks_8611;
    num_tblocks_8978 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nest_sizze_8976, segred_tblock_sizze_8977), max_num_tblocks_11013)));
    
    int64_t segmap_tblock_sizze_8402;
    
    segmap_tblock_sizze_8402 = *ctx->tuning_params.run64zisegmap_tblock_sizze_8373;
    
    int64_t num_tblocks_8403;
    int64_t max_num_tblocks_11014;
    
    max_num_tblocks_11014 = *ctx->tuning_params.run64zisegmap_num_tblocks_8375;
    num_tblocks_8403 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_6626, segmap_tblock_sizze_8402), max_num_tblocks_11014)));
    
    int64_t Ty_9680;
    
    Ty_9680 = *ctx->tuning_params.run64ziTy_9678;
    
    int64_t Ry_9681;
    
    Ry_9681 = *ctx->tuning_params.run64ziRy_9679;
    
    int64_t Tk_9682;
    
    Tk_9682 = *ctx->tuning_params.run64ziTk_9677;
    
    int64_t TxRx_9685 = Ty_9680 * Ry_9681;
    int64_t a_loc_szz_9688 = Tk_9682 * TxRx_9685;
    int64_t b_loc_szz_9692 = TxRx_9685 + a_loc_szz_9688;
    int64_t tblock_sizze_9697 = Ty_9680 * Ty_9680;
    bool loop_nonempty_10436 = slt64((int64_t) 0, Ry_9681);
    int64_t binop_y_9874 = (int64_t) 1 + Tk_9682;
    int64_t Ty_10060;
    
    Ty_10060 = *ctx->tuning_params.run64ziTy_10058;
    
    int64_t Ry_10061;
    
    Ry_10061 = *ctx->tuning_params.run64ziRy_10059;
    
    int64_t Tk_10062;
    
    Tk_10062 = *ctx->tuning_params.run64ziTk_10057;
    
    int64_t TxRx_10065 = Ty_10060 * Ry_10061;
    int64_t a_loc_szz_10068 = Tk_10062 * TxRx_10065;
    int64_t tblock_sizze_10075 = Ty_10060 * Ty_10060;
    bool loop_nonempty_10430 = slt64((int64_t) 0, Ry_10061);
    int64_t ext_10760;
    int64_t shared_memory_capacity_11015;
    
    shared_memory_capacity_11015 = ctx->max_shared_memory;
    if (suff_outer_par_8835) {
        ext_10760 = (int64_t) 64;
    } else {
        ext_10760 = (int64_t) 4096;
    }
    
    int64_t ext_10759;
    int64_t shared_memory_capacity_11016;
    
    shared_memory_capacity_11016 = ctx->max_shared_memory;
    if (suff_outer_par_8835) {
        ext_10759 = (int64_t) 1;
    } else {
        ext_10759 = (int64_t) 64;
    }
    
    int64_t binop_x_10477 = (int64_t) 128 * m_6626;
    int64_t bytes_10478 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * binop_x_10477;
    int64_t tk_div_tx_9683 = sdiv_up_safe64(Tk_9682, Ty_9680);
    int64_t gridDim_x_9693 = sdiv_up_safe64(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, TxRx_9685);
    int64_t gridDim_y_9694 = sdiv_up_safe64((int64_t) 64, TxRx_9685);
    int64_t binop_y_9695 = gridDim_x_9693 * gridDim_y_9694;
    int64_t grid_sizze_9696 = m_6626 * binop_y_9695;
    int64_t full_tiles_9728 = squot_safe64((int64_t) 64, Tk_9682);
    int64_t kk_9890 = Tk_9682 * full_tiles_9728;
    int64_t binop_y_10499 = Ry_9681 - (int64_t) 1;
    int64_t binop_x_10500 = smax64((int64_t) 0, binop_y_10499);
    int64_t binop_y_10501 = Ry_9681 * binop_x_10500;
    int64_t binop_y_10502 = smax64((int64_t) 0, binop_y_10501);
    int64_t binop_y_10507 = binop_x_10500 + binop_y_10502;
    int64_t binop_y_10508 = (int64_t) 1 + binop_y_10507;
    int64_t bytes_10509 = (int64_t) 2 * binop_y_10508;
    int64_t bytes_10511 = (int64_t) 2 * a_loc_szz_9688;
    int64_t bytes_10513 = (int64_t) 2 * b_loc_szz_9692;
    int64_t binop_y_10580 = dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 - (int64_t) 1;
    int64_t binop_x_10582 = smax64((int64_t) 0, binop_y_10580);
    int64_t binop_y_10584 = (int64_t) 63 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;
    int64_t binop_y_10585 = smax64((int64_t) 0, binop_y_10584);
    int64_t binop_y_10586 = binop_x_10582 + binop_y_10585;
    int64_t binop_y_10587 = (int64_t) 1 + binop_y_10586;
    int64_t bytes_10588 = (int64_t) 2 * binop_y_10587;
    int64_t binop_y_10614 = Ry_10061 - (int64_t) 1;
    int64_t binop_x_10615 = smax64((int64_t) 0, binop_y_10614);
    int64_t binop_y_10616 = Ry_10061 * binop_x_10615;
    int64_t binop_y_10617 = smax64((int64_t) 0, binop_y_10616);
    int64_t binop_y_10622 = binop_x_10615 + binop_y_10617;
    int64_t binop_y_10623 = (int64_t) 1 + binop_y_10622;
    int64_t bytes_10624 = (int64_t) 2 * binop_y_10623;
    int64_t bytes_10626 = (int64_t) 2 * a_loc_szz_10068;
    int64_t bytes_10693 = (int64_t) 2 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;
    int64_t binop_y_10701 = m_6626 - (int64_t) 1;
    int64_t binop_x_10702 = smax64((int64_t) 0, binop_y_10701);
    int64_t binop_y_10703 = (int64_t) 64 * binop_x_10702;
    int64_t binop_x_10704 = smax64((int64_t) 0, binop_y_10703);
    int64_t binop_x_10707 = (int64_t) 63 + binop_x_10704;
    int64_t binop_y_10710 = (int64_t) 4032 * m_6626;
    int64_t binop_y_10711 = smax64((int64_t) 0, binop_y_10710);
    int64_t binop_y_10712 = binop_x_10707 + binop_y_10711;
    int64_t binop_y_10713 = (int64_t) 1 + binop_y_10712;
    int64_t bytes_10714 = (int64_t) 2 * binop_y_10713;
    int64_t binop_x_10748 = (int64_t) 63 + binop_x_10704;
    int64_t binop_y_10753 = binop_y_10711 + binop_x_10748;
    int64_t binop_y_10754 = (int64_t) 1 + binop_y_10753;
    int64_t bytes_10755 = (int64_t) 2 * binop_y_10754;
    int64_t bytes_10763 = (int64_t) 128 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627;
    int64_t binop_x_10781 = binop_x_10702 + binop_y_10711;
    int64_t binop_y_10783 = (int64_t) 63 * m_6626;
    int64_t binop_y_10784 = smax64((int64_t) 0, binop_y_10783);
    int64_t binop_y_10785 = binop_x_10781 + binop_y_10784;
    int64_t binop_y_10786 = (int64_t) 1 + binop_y_10785;
    int64_t bytes_10787 = (int64_t) 2 * binop_y_10786;
    int64_t binop_y_10838 = (int64_t) 1 + binop_y_10785;
    int64_t bytes_10839 = (int64_t) 2 * binop_y_10838;
    int64_t ext_10772;
    int64_t shared_memory_capacity_11017;
    
    shared_memory_capacity_11017 = ctx->max_shared_memory;
    if (intra_suff_and_fits_8433) {
        ext_10772 = (int64_t) 4096;
    } else {
        ext_10772 = ext_10760;
    }
    
    int64_t ext_10771;
    int64_t shared_memory_capacity_11018;
    
    shared_memory_capacity_11018 = ctx->max_shared_memory;
    if (intra_suff_and_fits_8433) {
        ext_10771 = (int64_t) 64;
    } else {
        ext_10771 = ext_10759;
    }
    
    int64_t ext_10758;
    int64_t shared_memory_capacity_11019;
    
    shared_memory_capacity_11019 = ctx->max_shared_memory;
    if (suff_outer_par_8835) {
        ext_10758 = arg_6655;
    } else {
        ext_10758 = (int64_t) 1;
    }
    
    int64_t ext_10844;
    int64_t shared_memory_capacity_11020;
    
    shared_memory_capacity_11020 = ctx->max_shared_memory;
    if (suff_outer_par_8369) {
        ext_10844 = (int64_t) 1;
    } else {
        ext_10844 = ext_10772;
    }
    
    int64_t ext_10843;
    int64_t shared_memory_capacity_11021;
    
    shared_memory_capacity_11021 = ctx->max_shared_memory;
    if (suff_outer_par_8369) {
        ext_10843 = arg_6655;
    } else {
        ext_10843 = ext_10771;
    }
    
    int64_t ext_10770;
    int64_t shared_memory_capacity_11022;
    
    shared_memory_capacity_11022 = ctx->max_shared_memory;
    if (intra_suff_and_fits_8433) {
        ext_10770 = (int64_t) 1;
    } else {
        ext_10770 = ext_10758;
    }
    
    int64_t ext_10842;
    int64_t shared_memory_capacity_11023;
    
    shared_memory_capacity_11023 = ctx->max_shared_memory;
    if (suff_outer_par_8369) {
        ext_10842 = m_6626;
    } else {
        ext_10842 = ext_10770;
    }
    
    int64_t num_threads_10960 = segmap_tblock_sizze_8830 * num_tblocks_8831;
    int64_t total_sizze_10961 = bytes_10693 * num_threads_10960;
    int64_t num_threads_10938 = segmap_tblock_sizze_8402 * num_tblocks_8403;
    int64_t total_sizze_10939 = bytes_10693 * num_threads_10938;
    int64_t shared_memory_capacity_11490;
    
    shared_memory_capacity_11490 = ctx->max_shared_memory;
    if (suff_outer_par_8369 && sle64((int64_t) 0, shared_memory_capacity_11490)) {
        if (memblock_alloc_device(ctx, &mem_10788, bytes_10787, "mem_10788")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10788.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, m_6626 * (int64_t) 64, m_6626}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 4096, (int64_t) 64, (int64_t) 1}, (int64_t []) {m_6626, (int64_t) 64, (int64_t) 64})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10798, bytes_10588, "mem_10798")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10798.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 64, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, (int64_t) 64})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_10840, bytes_10839, "mem_10840")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &color_10856, total_sizze_10939, "color_10856")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_11024 = sext_i64_i32(sdiv_up64(m_6626, segmap_tblock_sizze_8402));
        
        {
            err = gpu_kernel_run64zisegmap_8407(ctx, num_tblocks_8403, 1, 1, *ctx->tuning_params.run64zisegmap_tblock_sizze_8373, 1, 1, (int64_t) 0, m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, num_tblocks_8403, num_threads_10938, virt_num_tblocks_11024, K_mem_10473.mem, mem_10788.mem, mem_10798.mem, mem_10840.mem, color_10856.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_10788, "mem_10788") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10798, "mem_10798") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_10845, &mem_10840, "mem_10840") != 0)
            return 1;
    } else {
        int64_t shared_memory_capacity_11489;
        
        shared_memory_capacity_11489 = ctx->max_shared_memory;
        if (intra_suff_and_fits_8433 && sle64((int64_t) 8192 + sdiv_up64(bytes_10763, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11489)) {
            if (memblock_alloc_device(ctx, &mem_10769, bytes_10593, "mem_10769")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t num_chunks_11042 = sext_i64_i32(sdiv_up64((int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8358));
            int32_t num_chunks_11043 = sext_i64_i32(sdiv_up64((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64, one_intra_par_min_8358));
            int32_t virt_num_tblocks_11044 = sext_i64_i32(m_6626);
            
            {
                err = gpu_kernel_run64zisegmap_intrablock_8436(ctx, m_6626, 1, 1, one_intra_par_min_8358, 1, 1, (int64_t) 2 * ((int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 4096 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64), (int64_t) 8), (int64_t) 8)) + (bytes_10763 + srem64((int64_t) 8 - srem64(bytes_10763, (int64_t) 8), (int64_t) 8)) + (int64_t) 8192, m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8358, bytes_10763, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10769.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_set_device(ctx, &ext_mem_10773, &mem_10769, "mem_10769") != 0)
                return 1;
        } else {
            int64_t shared_memory_capacity_11488;
            
            shared_memory_capacity_11488 = ctx->max_shared_memory;
            if (suff_outer_par_8835 && sle64((int64_t) 0, shared_memory_capacity_11488)) {
                if (memblock_alloc_device(ctx, &mem_10715, bytes_10714, "mem_10715")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10715.mem, (int64_t) 0, (int64_t []) {(int64_t) 64, (int64_t) 1, (int64_t) 64 * m_6626}, Q_mem_10472.mem, (int64_t) 0, (int64_t []) {(int64_t) 4096, (int64_t) 64, (int64_t) 1}, (int64_t []) {m_6626, (int64_t) 64, (int64_t) 64})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10725, bytes_10588, "mem_10725")) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10725.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 64, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, (int64_t) 64})) != 0)
                    goto cleanup;
                if (memblock_alloc_device(ctx, &mem_10756, bytes_10755, "mem_10756")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &color_10859, total_sizze_10961, "color_10859")) {
                    err = 1;
                    goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                
                int32_t virt_num_tblocks_11111 = sext_i64_i32(sdiv_up64(m_6626 * (int64_t) 64, segmap_tblock_sizze_8830));
                
                {
                    err = gpu_kernel_run64zisegmap_8853(ctx, num_tblocks_8831, 1, 1, *ctx->tuning_params.run64zisegmap_tblock_sizze_8470, 1, 1, (int64_t) 0, m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, num_tblocks_8831, num_threads_10960, virt_num_tblocks_11111, K_mem_10473.mem, mem_10715.mem, mem_10725.mem, mem_10756.mem, color_10859.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
                if (memblock_unref_device(ctx, &mem_10715, "mem_10715") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &mem_10725, "mem_10725") != 0)
                    return 1;
                if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_10761, &mem_10756, "mem_10756") != 0)
                    return 1;
            } else {
                int64_t shared_memory_capacity_11487;
                
                shared_memory_capacity_11487 = ctx->max_shared_memory;
                if (intra_suff_and_fits_8848 && sle64((int64_t) 128 + sdiv_up64(bytes_10693, (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64), (int64_t) 8) * (int64_t) 8 + sdiv_up64((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11487)) {
                    if (memblock_alloc_device(ctx, &mem_10699, bytes_10593, "mem_10699")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                    
                    int32_t num_chunks_11130 = sext_i64_i32(sdiv_up64((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8836));
                    int32_t num_chunks_11131 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64, one_intra_par_min_8836));
                    int32_t virt_num_tblocks_11132 = sext_i64_i32(m_6626 * (int64_t) 64);
                    
                    {
                        err = gpu_kernel_run64zisegmap_intrablock_8877(ctx, arg_6655, 1, 1, one_intra_par_min_8836, 1, 1, (int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627) + srem64((int64_t) 8 - srem64((int64_t) 2 * ((int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), (int64_t) 8), (int64_t) 8) + ((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64) + srem64((int64_t) 8 - srem64((int64_t) 2 * (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 64), (int64_t) 8), (int64_t) 8)) + (bytes_10693 + srem64((int64_t) 8 - srem64(bytes_10693, (int64_t) 8), (int64_t) 8)) + (int64_t) 128, m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8836, bytes_10693, Q_mem_10472.mem, K_mem_10473.mem, V_mem_10474.mem, mem_10699.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_set_device(ctx, &ext_mem_10700, &mem_10699, "mem_10699") != 0)
                        return 1;
                } else {
                    int64_t shared_memory_capacity_11350;
                    
                    shared_memory_capacity_11350 = ctx->max_shared_memory;
                    if (suff_outer_par_8910 && sle64(sdiv_up64(bytes_10513, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_10511, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11350)) {
                        if (memblock_alloc_device(ctx, &mem_10575, bytes_10478, "mem_10575")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11195 = sext_i64_i32(sdiv_up64(Ty_9680 * Ty_9680, tblock_sizze_9697));
                        int32_t virt_num_tblocks_11196 = sext_i64_i32(m_6626 * gridDim_y_9694 * gridDim_x_9693);
                        
                        {
                            err = gpu_kernel_run64zisegmap_intrablock_9700(ctx, grid_sizze_9696, 1, 1, *ctx->tuning_params.run64ziTy_9678 * *ctx->tuning_params.run64ziTy_9678, 1, 1, bytes_10511 + srem64((int64_t) 8 - srem64(bytes_10511, (int64_t) 8), (int64_t) 8) + (bytes_10513 + srem64((int64_t) 8 - srem64(bytes_10513, (int64_t) 8), (int64_t) 8)), m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, gridDim_x_9693, Q_mem_10472.mem, K_mem_10473.mem, mem_10575.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10579, &mem_10575, "mem_10575") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10479, bytes_10478, "mem_10479")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11250 = (int64_t) 1;
                        
                        if (slt64((int64_t) 128, segred_tblock_sizze_8930 * chunk_sizze_11250)) {
                            int64_t segment_sizze_nonzzero_11251 = smax64((int64_t) 1, (int64_t) 64);
                            int64_t num_threads_11252 = segred_tblock_sizze_8930 * segred_tblock_sizze_8930;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 64, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, squot64(segred_tblock_sizze_8930, segment_sizze_nonzzero_11251))), '\n');
                            {
                                err = gpu_kernel_run64zisegred_small_8938(ctx, num_tblocks_8931, 1, 1, *ctx->tuning_params.run64zisegred_tblock_sizze_8688, 1, 1, (int64_t) 2 * segred_tblock_sizze_8930 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8930, (int64_t) 8), (int64_t) 8), m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, num_tblocks_8931, segment_sizze_nonzzero_11251, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11283 = sdiv_up64(num_tblocks_8931, smax64((int64_t) 1, m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627));
                            int64_t q_11284 = sdiv_up64((int64_t) 64, segred_tblock_sizze_8930 * blocks_per_segment_11283 * chunk_sizze_11250);
                            int64_t num_virtblocks_11285 = blocks_per_segment_11283 * (m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);
                            int64_t threads_per_segment_11286 = blocks_per_segment_11283 * segred_tblock_sizze_8930;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6626 * (int64_t) 64 * dzlz7bUZLztZRz20Umz20U64z7dUzg_6627), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 64, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11285, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_8931, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_8930, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11284, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11283, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11287, (int64_t) 2 * num_virtblocks_11285, "segred_tmp_mem_11287")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run64zisegred_large_8938(ctx, num_tblocks_8931, 1, 1, *ctx->tuning_params.run64zisegred_tblock_sizze_8688, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_8930 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8930, (int64_t) 8), (int64_t) 8)), m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, num_tblocks_8931, blocks_per_segment_11283, q_11284, num_virtblocks_11285, threads_per_segment_11286, Q_mem_10472.mem, K_mem_10473.mem, mem_10479.mem, segred_tmp_mem_11287.mem, counters_mem_11289.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10579, &mem_10479, "mem_10479") != 0)
                            return 1;
                    }
                    
                    int64_t shared_memory_capacity_11486;
                    
                    shared_memory_capacity_11486 = ctx->max_shared_memory;
                    if (suff_outer_par_8957 && sle64(sdiv_up64(bytes_10626, (int64_t) 8) * (int64_t) 8 + sdiv_up64(bytes_10626, (int64_t) 8) * (int64_t) 8, shared_memory_capacity_11486)) {
                        int64_t tk_div_tx_10063 = sdiv_up64(Tk_10062, Ty_10060);
                        int64_t gridDim_x_10071 = sdiv_up64((int64_t) 64, TxRx_10065);
                        int64_t binop_y_10073 = gridDim_x_10071 * gridDim_x_10071;
                        int64_t grid_sizze_10074 = m_6626 * binop_y_10073;
                        int64_t full_tiles_10106 = squot64(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, Tk_10062);
                        int64_t kk_10264 = Tk_10062 * full_tiles_10106;
                        
                        if (memblock_alloc_device(ctx, &mem_10690, bytes_10593, "mem_10690")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t num_chunks_11351 = sext_i64_i32(sdiv_up64(Ty_10060 * Ty_10060, tblock_sizze_10075));
                        int32_t virt_num_tblocks_11352 = sext_i64_i32(m_6626 * gridDim_x_10071 * gridDim_x_10071);
                        
                        {
                            err = gpu_kernel_run64zisegmap_intrablock_10078(ctx, grid_sizze_10074, 1, 1, *ctx->tuning_params.run64ziTy_10058 * *ctx->tuning_params.run64ziTy_10058, 1, 1, bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8) + (bytes_10626 + srem64((int64_t) 8 - srem64(bytes_10626, (int64_t) 8), (int64_t) 8)), m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8836, full_tiles_10106, kk_10264, V_mem_10474.mem, ext_mem_10579.mem, mem_10690.mem);
                            if (err != FUTHARK_SUCCESS)
                                goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_set_device(ctx, &ext_mem_10691, &mem_10690, "mem_10690") != 0)
                            return 1;
                    } else {
                        if (memblock_alloc_device(ctx, &mem_10589, bytes_10588, "mem_10589")) {
                            err = 1;
                            goto cleanup;
                        }
                        if ((err = lmad_copy_gpu2gpu_2b(ctx, 2, mem_10589.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627}, V_mem_10474.mem, (int64_t) 0, (int64_t []) {(int64_t) 64, (int64_t) 1}, (int64_t []) {dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, (int64_t) 64})) != 0)
                            goto cleanup;
                        if (memblock_alloc_device(ctx, &mem_10594, bytes_10593, "mem_10594")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegRed");
                        
                        int64_t chunk_sizze_11406 = (int64_t) 1;
                        
                        if (slt64(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 * (int64_t) 2, segred_tblock_sizze_8977 * chunk_sizze_11406)) {
                            int64_t segment_sizze_nonzzero_11407 = smax64((int64_t) 1, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);
                            int64_t num_threads_11408 = segred_tblock_sizze_8977 * segred_tblock_sizze_8977;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-small");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6626 * (int64_t) 64 * (int64_t) 64), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(m_6626 * (int64_t) 64 * (int64_t) 64, squot64(segred_tblock_sizze_8977, segment_sizze_nonzzero_11407))), '\n');
                            {
                                err = gpu_kernel_run64zisegred_small_8985(ctx, num_tblocks_8978, 1, 1, *ctx->tuning_params.run64zisegred_tblock_sizze_8609, 1, 1, (int64_t) 2 * segred_tblock_sizze_8977 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8977, (int64_t) 8), (int64_t) 8), m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8836, num_tblocks_8978, segment_sizze_nonzzero_11407, ext_mem_10579.mem, mem_10589.mem, mem_10594.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        } else {
                            int64_t blocks_per_segment_11439 = sdiv_up64(num_tblocks_8978, smax64((int64_t) 1, m_6626 * (int64_t) 64 * (int64_t) 64));
                            int64_t q_11440 = sdiv_up64(dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, segred_tblock_sizze_8977 * blocks_per_segment_11439 * chunk_sizze_11406);
                            int64_t num_virtblocks_11441 = blocks_per_segment_11439 * (m_6626 * (int64_t) 64 * (int64_t) 64);
                            int64_t threads_per_segment_11442 = blocks_per_segment_11439 * segred_tblock_sizze_8977;
                            
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "# SegRed-large");
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (m_6626 * (int64_t) 64 * (int64_t) 64), '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_11441, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_8978, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) segred_tblock_sizze_8977, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_11440, '\n');
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_11439, '\n');
                            if (memblock_alloc_device(ctx, &segred_tmp_mem_11443, (int64_t) 2 * num_virtblocks_11441, "segred_tmp_mem_11443")) {
                                err = 1;
                                goto cleanup;
                            }
                            {
                                err = gpu_kernel_run64zisegred_large_8985(ctx, num_tblocks_8978, 1, 1, *ctx->tuning_params.run64zisegred_tblock_sizze_8609, 1, 1, 8 + ((int64_t) 2 * segred_tblock_sizze_8977 + srem64((int64_t) 8 - srem64((int64_t) 2 * segred_tblock_sizze_8977, (int64_t) 8), (int64_t) 8)), m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627, one_intra_par_min_8836, num_tblocks_8978, blocks_per_segment_11439, q_11440, num_virtblocks_11441, threads_per_segment_11442, ext_mem_10579.mem, mem_10589.mem, mem_10594.mem, segred_tmp_mem_11443.mem, counters_mem_11445.mem);
                                if (err != FUTHARK_SUCCESS)
                                    goto cleanup;
                            }
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_unref_device(ctx, &mem_10589, "mem_10589") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_10691, &mem_10594, "mem_10594") != 0)
                            return 1;
                    }
                    if (memblock_unref_device(ctx, &ext_mem_10579, "ext_mem_10579") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &ext_mem_10700, &ext_mem_10691, "ext_mem_10691") != 0)
                        return 1;
                }
                if (memblock_set_device(ctx, &ext_mem_10761, &ext_mem_10700, "ext_mem_10700") != 0)
                    return 1;
            }
            if (memblock_set_device(ctx, &ext_mem_10773, &ext_mem_10761, "ext_mem_10761") != 0)
                return 1;
        }
        if (memblock_set_device(ctx, &ext_mem_10845, &ext_mem_10773, "ext_mem_10773") != 0)
            return 1;
    }
    if (memblock_alloc_device(ctx, &mem_10849, bytes_10593, "mem_10849")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_2b(ctx, 3, mem_10849.mem, (int64_t) 0, (int64_t []) {(int64_t) 4096, (int64_t) 64, (int64_t) 1}, ext_mem_10845.mem, (int64_t) 0, (int64_t []) {ext_10844, ext_10843, ext_10842}, (int64_t []) {m_6626, (int64_t) 64, (int64_t) 64})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &ext_mem_10845, "ext_mem_10845") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_11010, &mem_10849, "mem_10849") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_11498, &mem_out_11010, "mem_out_11010") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_10849, "mem_10849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11443, "segred_tmp_mem_11443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10594, "mem_10594") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10589, "mem_10589") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10690, "mem_10690") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10691, "ext_mem_10691") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_11287, "segred_tmp_mem_11287") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10479, "mem_10479") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10575, "mem_10575") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10579, "ext_mem_10579") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10699, "mem_10699") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10700, "ext_mem_10700") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10859, "color_10859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10756, "mem_10756") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10725, "mem_10725") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10715, "mem_10715") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10761, "ext_mem_10761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10769, "mem_10769") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10773, "ext_mem_10773") != 0)
            return 1;
        if (memblock_unref_device(ctx, &color_10856, "color_10856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10840, "mem_10840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10798, "mem_10798") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_10788, "mem_10788") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_10845, "ext_mem_10845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_11010, "mem_out_11010") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_mk_input(struct futhark_context *ctx, struct futhark_f16_3d **out0, struct futhark_f16_2d **out1, struct futhark_f16_2d **out2, const int64_t in0, const int64_t in1)
{
    int64_t m_6250 = (int64_t) 0;
    int64_t d_6251 = (int64_t) 0;
    int64_t prim_out_11013 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_11012;
    
    mem_out_11012.references = NULL;
    
    struct memblock_device mem_out_11011;
    
    mem_out_11011.references = NULL;
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    m_6250 = in0;
    d_6251 = in1;
    if (ret == 0) {
        ret = futrts_entry_mk_input(ctx, &mem_out_11010, &mem_out_11011, &mem_out_11012, &prim_out_11013, m_6250, d_6251);
        if (ret == 0) {
            struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
            struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
            
            assert((*out0 = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d))) != NULL);
            (*out0)->mem = mem_out_11010;
            (*out0)->shape[0] = m_6250;
            (*out0)->shape[1] = d_6251;
            (*out0)->shape[2] = d_6251;
            assert((*out1 = (struct futhark_f16_2d *) malloc(sizeof(struct futhark_f16_2d))) != NULL);
            (*out1)->mem = mem_out_11011;
            (*out1)->shape[0] = prim_out_11013;
            (*out1)->shape[1] = d_6251;
            assert((*out2 = (struct futhark_f16_2d *) malloc(sizeof(struct futhark_f16_2d))) != NULL);
            (*out2)->mem = mem_out_11012;
            (*out2)->shape[0] = prim_out_11013;
            (*out2)->shape[1] = d_6251;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_run128(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2)
{
    int64_t m_6642 = (int64_t) 0;
    int64_t dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device V_mem_10474;
    
    V_mem_10474.references = NULL;
    
    struct memblock_device K_mem_10473;
    
    K_mem_10473.references = NULL;
    
    struct memblock_device Q_mem_10472;
    
    Q_mem_10472.references = NULL;
    Q_mem_10472 = in0->mem;
    m_6642 = in0->shape[0];
    K_mem_10473 = in1->mem;
    dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 = in1->shape[0];
    V_mem_10474 = in2->mem;
    dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 = in2->shape[0];
    if (!((m_6642 == in0->shape[0] && ((int64_t) 128 == in0->shape[1] && (int64_t) 128 == in0->shape[2])) && ((dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 == in1->shape[0] && (int64_t) 128 == in1->shape[1]) && (dzlz7bUZLztZRz20Umz20U128z7dUzg_6643 == in2->shape[0] && (int64_t) 128 == in2->shape[1])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_run128(ctx, &mem_out_11010, Q_mem_10472, K_mem_10473, V_mem_10474, m_6642, dzlz7bUZLztZRz20Umz20U128z7dUzg_6643);
        if (ret == 0) {
            struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
            struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
            
            assert((*out0 = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d))) != NULL);
            (*out0)->mem = mem_out_11010;
            (*out0)->shape[0] = m_6642;
            (*out0)->shape[1] = (int64_t) 128;
            (*out0)->shape[2] = (int64_t) 128;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_run16(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2)
{
    int64_t m_6594 = (int64_t) 0;
    int64_t dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device V_mem_10474;
    
    V_mem_10474.references = NULL;
    
    struct memblock_device K_mem_10473;
    
    K_mem_10473.references = NULL;
    
    struct memblock_device Q_mem_10472;
    
    Q_mem_10472.references = NULL;
    Q_mem_10472 = in0->mem;
    m_6594 = in0->shape[0];
    K_mem_10473 = in1->mem;
    dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 = in1->shape[0];
    V_mem_10474 = in2->mem;
    dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 = in2->shape[0];
    if (!((m_6594 == in0->shape[0] && ((int64_t) 16 == in0->shape[1] && (int64_t) 16 == in0->shape[2])) && ((dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 == in1->shape[0] && (int64_t) 16 == in1->shape[1]) && (dzlz7bUZLztZRz20Umz20U16z7dUzg_6595 == in2->shape[0] && (int64_t) 16 == in2->shape[1])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_run16(ctx, &mem_out_11010, Q_mem_10472, K_mem_10473, V_mem_10474, m_6594, dzlz7bUZLztZRz20Umz20U16z7dUzg_6595);
        if (ret == 0) {
            struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
            struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
            
            assert((*out0 = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d))) != NULL);
            (*out0)->mem = mem_out_11010;
            (*out0)->shape[0] = m_6594;
            (*out0)->shape[1] = (int64_t) 16;
            (*out0)->shape[2] = (int64_t) 16;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_run32(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2)
{
    int64_t m_6610 = (int64_t) 0;
    int64_t dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device V_mem_10474;
    
    V_mem_10474.references = NULL;
    
    struct memblock_device K_mem_10473;
    
    K_mem_10473.references = NULL;
    
    struct memblock_device Q_mem_10472;
    
    Q_mem_10472.references = NULL;
    Q_mem_10472 = in0->mem;
    m_6610 = in0->shape[0];
    K_mem_10473 = in1->mem;
    dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 = in1->shape[0];
    V_mem_10474 = in2->mem;
    dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 = in2->shape[0];
    if (!((m_6610 == in0->shape[0] && ((int64_t) 32 == in0->shape[1] && (int64_t) 32 == in0->shape[2])) && ((dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 == in1->shape[0] && (int64_t) 32 == in1->shape[1]) && (dzlz7bUZLztZRz20Umz20U32z7dUzg_6611 == in2->shape[0] && (int64_t) 32 == in2->shape[1])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_run32(ctx, &mem_out_11010, Q_mem_10472, K_mem_10473, V_mem_10474, m_6610, dzlz7bUZLztZRz20Umz20U32z7dUzg_6611);
        if (ret == 0) {
            struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
            struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
            
            assert((*out0 = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d))) != NULL);
            (*out0)->mem = mem_out_11010;
            (*out0)->shape[0] = m_6610;
            (*out0)->shape[1] = (int64_t) 32;
            (*out0)->shape[2] = (int64_t) 32;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_run64(struct futhark_context *ctx, struct futhark_f16_3d **out0, const struct futhark_f16_3d *in0, const struct futhark_f16_2d *in1, const struct futhark_f16_2d *in2)
{
    int64_t m_6626 = (int64_t) 0;
    int64_t dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_11010;
    
    mem_out_11010.references = NULL;
    
    struct memblock_device V_mem_10474;
    
    V_mem_10474.references = NULL;
    
    struct memblock_device K_mem_10473;
    
    K_mem_10473.references = NULL;
    
    struct memblock_device Q_mem_10472;
    
    Q_mem_10472.references = NULL;
    Q_mem_10472 = in0->mem;
    m_6626 = in0->shape[0];
    K_mem_10473 = in1->mem;
    dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 = in1->shape[0];
    V_mem_10474 = in2->mem;
    dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 = in2->shape[0];
    if (!((m_6626 == in0->shape[0] && ((int64_t) 64 == in0->shape[1] && (int64_t) 64 == in0->shape[2])) && ((dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 == in1->shape[0] && (int64_t) 64 == in1->shape[1]) && (dzlz7bUZLztZRz20Umz20U64z7dUzg_6627 == in2->shape[0] && (int64_t) 64 == in2->shape[1])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_run64(ctx, &mem_out_11010, Q_mem_10472, K_mem_10473, V_mem_10474, m_6626, dzlz7bUZLztZRz20Umz20U64z7dUzg_6627);
        if (ret == 0) {
            struct memblock_device counters_mem_11289 = ctx->constants->counters_mem_11289;
            struct memblock_device counters_mem_11445 = ctx->constants->counters_mem_11445;
            
            assert((*out0 = (struct futhark_f16_3d *) malloc(sizeof(struct futhark_f16_3d))) != NULL);
            (*out0)->mem = mem_out_11010;
            (*out0)->shape[0] = m_6626;
            (*out0)->shape[1] = (int64_t) 64;
            (*out0)->shape[2] = (int64_t) 64;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
